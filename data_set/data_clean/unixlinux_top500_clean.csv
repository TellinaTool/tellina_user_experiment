,Link,Title,Text,Code
0,https://unix.stackexchange.com/questions/26047/,How to correctly add a path to PATH?,"['or', 'depending on whether you want to add ~/opt/bin at the end (to be searched after all other directories, in case there is a program by the same name in multiple directories) or at the beginning (to be searched before all other directories).', ""You can add multiple entries at the same time. PATH=$PATH:~/opt/bin:~/opt/node/bin or variations on the ordering work just fine. Don't put export at the beginning of the line as it has additional complications (see below under “Notes on shells other than bash”)."", 'If your PATH gets built by many different components, you might end up with duplicate entries. See How to add home directory path to be discovered by Unix which command? and Remove duplicate $PATH entries with awk command to avoid adding duplicates or remove them.', 'Some distributions automatically put ~/bin in your PATH if it exists, by the way.', ""Put the line to modify PATH in ~/.profile, or in ~/.bash_profile if that's what you have."", ""Note that ~/.bash_rc is not read by any program, and ~/.bashrc is the configuration file of interactive instances of bash. You should not define environment variables in ~/.bashrc. The right place to define environment variables such as PATH is ~/.profile (or ~/.bash_profile if you don't care about shells other than bash). See What's the difference between them and which one should I use?"", ""Don't put it in /etc/environment or ~/.pam_environment: these are not shell files, you can't use substitutions like $PATH in there. In these files, you can only override a variable, not add to it."", ""You don't need export if the variable is already in the environment: any change of the value of the variable is reflected in the environment.¹ PATH is pretty much always in the environment; all unix systems set it very early on (usually in the very first process, in fact)."", ""At login time, you can rely on PATH being already in the environment, and already containing some system directories. If you're writing a script that may be executed early while setting up some kind of virtual environment, you may need to ensure that PATH is non-empty and exported: if PATH is still unset, then something like PATH=$PATH:/some/directory would set PATH to :/some/directory, and the empty component at the beginning means the current directory (like .:/some/directory)."", 'In bash, ksh and zsh, export is special syntax, and both PATH=~/opt/bin:$PATH and export PATH=~/opt/bin:$PATH do the right thing even. In other Bourne/POSIX-style shells such as dash (which is /bin/sh on many systems), export is parsed as an ordinary command, which implies two differences:', 'So in shells like dash, export PATH=~/opt/bin:$PATH sets PATH to the literal string ~/opt/bin/: followed by the value of PATH up to the first space.\nPATH=~/opt/bin:$PATH (a bare assignment) doesn\'t require quotes and does the right thing. If you want to use export in a portable script, you need to write export PATH=""$HOME/opt/bin:$PATH"", or PATH=~/opt/bin:$PATH; export PATH (or PATH=$HOME/opt/bin:$PATH; export PATH for portability to even the Bourne shell that didn\'t accept export var=value and didn\'t do tilde expansion).', ""¹  This wasn't true in Bourne shells (as in the actual Bourne shell, not modern POSIX-style shells), but you're highly unlikely to encounter such old shells these days.  ""]","[<code>PATH=$PATH:~/opt/bin
</code>, <code>PATH=~/opt/bin:$PATH
</code>, <code>~/opt/bin</code>, <code>PATH=$PATH:~/opt/bin:~/opt/node/bin</code>, <code>export</code>, <code>PATH</code>, <code>~/bin</code>, <code>PATH</code>, <code>~/.profile</code>, <code>~/.bash_profile</code>, <code>~/.bash_rc</code>, <code>~/.bashrc</code>, <code>~/.bashrc</code>, <code>PATH</code>, <code>~/.profile</code>, <code>~/.bash_profile</code>, <code>/etc/environment</code>, <code>~/.pam_environment</code>, <code>$PATH</code>, <code>export</code>, <code>PATH</code>, <code>PATH</code>, <code>PATH</code>, <code>PATH</code>, <code>PATH=$PATH:/some/directory</code>, <code>PATH</code>, <code>:/some/directory</code>, <code>.:/some/directory</code>, <code>if [ -z ""${PATH-}"" ]; then export PATH=/usr/local/bin:/usr/bin:/bin; fi
</code>, <code>export</code>, <code>PATH=~/opt/bin:$PATH</code>, <code>export PATH=~/opt/bin:$PATH</code>, <code>/bin/sh</code>, <code>export</code>, <code>~</code>, <code>$PATH</code>, <code>PATH</code>, <code>\[*?</code>, <code>export PATH=~/opt/bin:$PATH</code>, <code>PATH</code>, <code>~/opt/bin/:</code>, <code>PATH</code>, <code>PATH=~/opt/bin:$PATH</code>, <code>export</code>, <code>export PATH=""$HOME/opt/bin:$PATH""</code>, <code>PATH=~/opt/bin:$PATH; export PATH</code>, <code>PATH=$HOME/opt/bin:$PATH; export PATH</code>, <code>export var=value</code>]"
1,https://unix.stackexchange.com/questions/1288/,Preserve bash history in multiple terminal windows,['Add the following to your ~/.bashrc:'],"[<code>~/.bashrc</code>, <code># Avoid duplicates
HISTCONTROL=ignoredups:erasedups
# When the shell exits, append to the history file instead of overwriting it
shopt -s histappend

# After each command, append to the history file and reread it
PROMPT_COMMAND=""${PROMPT_COMMAND:+$PROMPT_COMMAND$'\n'}history -a; history -c; history -r""
</code>]"
2,https://unix.stackexchange.com/questions/73498/,How to cycle through reverse-i-search in BASH?,"['If I understand the question correctly you should be able to cycle through\nalternatives by repeatedly hitting Ctrl+R.', 'E.g.:', 'Ctrl+R\ngrep\nCtrl+R\nCtrl+R\n...', 'That searches backwards through your history.  To search forward instead, use Ctrl+S, but you may need to have set: stty -ixon (either by .bash_profile or manually) prior to that to disable the XON/XOFF feature which takes over Ctrl+s.  (More details here.)']","[<code>grep</code>, <code>stty -ixon</code>, <code>.bash_profile</code>]"
3,https://unix.stackexchange.com/questions/122845/,"Using ""${a:-b}"" for variable assignment in scripts","['This technique allows for a variable to be assigned a value if another variable is either empty or is undefined. NOTE: This ""other variable"" can be the same or another variable.', 'excerpt', 'NOTE: This form also works, ${parameter-word}. If you\'d like to see a full list of all forms of parameter expansion available within Bash then I highly suggest you take a look at this topic in the Bash Hacker\'s wiki titled: ""Parameter expansion"".', 'The same thing can be done by evaluating other variables, or running commands within the default value portion of the notation.', ""You can also use a slightly different notation where it's just VARX=${VARX-<def. value>}."", 'In the above $VAR1 & $VAR2 were already defined with the string ""has another value"" but $VAR3 was undefined, so the default value was used instead, 0.', ""Lastly I'll mention the handy operator, :=. This will do a check and assign a value if the variable under test is empty or undefined."", 'Notice that $VAR1 is now set. The operator := did the test and the assignment in a single operation.', ""However if the value is set prior, then it's left alone."", '\xa0\xa0\xa0\xa0']","[<code>${parameter:-word}
    If parameter is unset or null, the expansion of word is substituted. 
    Otherwise, the value of parameter is substituted.
</code>, <code>${parameter-word}</code>, <code>$ echo ""$VAR1""

$ VAR1=""${VAR1:-default value}""
$ echo ""$VAR1""
default value
</code>, <code>$ VAR1=""has value""
$ echo ""$VAR1""
has value

$ VAR1=""${VAR1:-default value}""
$ echo ""$VAR1""
has value
</code>, <code>$ VAR2=""has another value""
$ echo ""$VAR2""
has another value
$ echo ""$VAR1""

$

$ VAR1=""${VAR1:-$VAR2}""
$ echo ""$VAR1""
has another value
</code>, <code>VARX=${VARX-&lt;def. value&gt;}</code>, <code>$ echo ""${VAR1-0}""
has another value
$ echo ""${VAR2-0}""
has another value
$ echo ""${VAR3-0}""
0
</code>, <code>$VAR1</code>, <code>$VAR2</code>, <code>$VAR3</code>, <code>0</code>, <code>$ VARX=""${VAR3-0}""
$ echo ""$VARX""
0
</code>, <code>:=</code>, <code>:=</code>, <code>$VAR1</code>, <code>:=</code>, <code>$ unset VAR1
$ echo ""$VAR1""

$ echo ""${VAR1:=default}""
default
$ echo ""$VAR1""
default
</code>, <code>$ VAR1=""some value""
$ echo ""${VAR1:=default}""
some value
$ echo ""$VAR1""
some value
</code>]"
4,https://unix.stackexchange.com/questions/20784/,How can I resolve a hostname to an IP address in a Bash script?,"['You can use getent, which comes with glibc (so you almost certainly have it on Linux). This resolves using gethostbyaddr/gethostbyname2, and so also will check /etc/hosts/NIS/etc:', 'Or, as Heinzi said below, you can use dig with the +short argument (queries DNS servers directly, does not look at /etc/hosts/NSS/etc) :', 'If dig +short is unavailable, any one of the following should work. All of these query DNS directly and ignore other means of resolution:', ""If you want to only print one IP, then add the exit command to awk's workflow.""]","[<code>getent</code>, <code>glibc</code>, <code>/etc/hosts</code>, <code>getent hosts unix.stackexchange.com | awk '{ print $1 }'
</code>, <code>dig</code>, <code>+short</code>, <code>/etc/hosts</code>, <code>dig +short unix.stackexchange.com
</code>, <code>dig +short</code>, <code>host unix.stackexchange.com | awk '/has address/ { print $4 }'
nslookup unix.stackexchange.com | awk '/^Address: / { print $2 }'
dig unix.stackexchange.com | awk '/^;; ANSWER SECTION:$/ { getline ; print $5 }'
</code>, <code>exit</code>, <code>awk</code>, <code>dig +short unix.stackexchange.com | awk '{ print ; exit }'
getent hosts unix.stackexchange.com | awk '{ print $1 ; exit }'
host unix.stackexchange.com | awk '/has address/ { print $4 ; exit }'
nslookup unix.stackexchange.com | awk '/^Address: / { print $2 ; exit }'
dig unix.stackexchange.com | awk '/^;; ANSWER SECTION:$/ { getline ; print $5 ; exit }'
</code>]"
5,https://unix.stackexchange.com/questions/52313/,How to get execution time of a script effectively?,['Just use time when you call the script:'],"[<code>time</code>, <code>time yourscript.sh
</code>]"
6,https://unix.stackexchange.com/questions/30925/,"In Bash, when to alias, when to script, and when to write a function?","[""An alias should effectively not (in general) do more than change the default options of a command. It is nothing more than simple text replacement on the command name.  It can't do anything with arguments but pass them to the command it actually runs. So if you simply need to add an argument at the front of a single command, an alias will work.  Common examples are"", ""A function should be used when you need to do something more complex than an alias but that wouldn't be of use on its own.  For example, take this answer on a question I asked about changing grep's default behavior depending on whether it's in a pipeline:"", ""It's a perfect example of a function because it is too complex for an alias (requiring different defaults based on a condition), but it's not something you'll need in a non-interactive script.  "", 'If you get too many functions or functions too big, put them into separate files in a hidden directory, and source them in your ~/.bashrc:', 'A script should stand on its own. It should have value as something that can be re-used, or used for more than one purpose.']","[<code># Make ls output in color by default.
alias ls=""ls --color=auto""
# make mv ask before overwriting a file by default
alias mv=""mv -i""
</code>, <code>grep</code>, <code>grep() { 
    if [[ -t 1 ]]; then 
        command grep -n ""$@""
    else 
        command grep ""$@""
    fi
}
</code>, <code>~/.bashrc</code>, <code>if [ -d ~/.bash_functions ]; then
    for file in ~/.bash_functions/*; do
        . ""$file""
    done
fi
</code>]"
7,https://unix.stackexchange.com/questions/86722/,How do I loop through only directories in bash?,"['If you need to select more specific files than only directories use find and pass it to while read:', 'Use shopt -u dotglob to exclude hidden directories (or setopt dotglob/unsetopt dotglob in zsh).', ""IFS= to avoid splitting filenames containing one of the $IFS, for example: 'a b'"", 'see AsymLabs answer below for more find options', 'edit:\nIn case you need to create an exit value from within the while loop, you can circumvent the extra subshell by this trick:']","[<code>find</code>, <code>while read</code>, <code>shopt -s dotglob
find * -prune -type d | while IFS= read -r d; do 
    echo ""$d""
done
</code>, <code>shopt -u dotglob</code>, <code>setopt dotglob</code>, <code>unsetopt dotglob</code>, <code>IFS=</code>, <code>$IFS</code>, <code>'a b'</code>, <code>find</code>, <code>while IFS= read -r d; do 
    if [ ""$d"" == ""something"" ]; then exit 1; fi
done &lt; &lt;(find * -prune -type d)
</code>]"
8,https://unix.stackexchange.com/questions/131766/,Why does my shell script choke on whitespace or other special characters?,"['If you use $foo unquoted, your script will choke on input or parameters (or command output, with $(foo)) containing whitespace or \\[*?.', 'There, you can stop reading. Well, ok, here are a few more:', ""This answer applies to Bourne/POSIX-style shells (sh, ash, dash, bash, ksh, mksh, yash…). Zsh users should skip it and read the end of When is double-quoting necessary? instead. If you want the whole nitty-gritty, read the standard or your shell's manual."", 'Note that the explanations below contains a few approximations (statements that are true in most conditions but can be affected by the surrounding context or by configuration).', '$foo does not mean “take the value of the variable foo”. It means something much more complex:', 'Note that the result is a list of strings. There are two contexts in shell syntax: list context and string context. Field splitting and filename generation only happen in list context, but that\'s most of the time. Double quotes delimit a string context: the whole double-quoted string is a single string, not to be split. (Exception: ""$@"" to expand to the list of positional parameters, e.g. ""$@"" is equivalent to ""$1"" ""$2"" ""$3"" if there are three positional parameters. See What is the difference between $* and $@?)', ""The same happens to command substitution with $(foo) or with `foo`. On a side note, don't use `foo`: its quoting rules are weird and non-portable, and all modern shells support $(foo) which is absolutely equivalent except for having intuitive quoting rules."", ""The output of arithmetic substitution also undergoes the same expansions, but that isn't normally a concern as it only contains non-expandable characters (assuming IFS doesn't contain digits or -)."", 'See When is double-quoting necessary? for more details about the cases when you can leave out the quotes.', 'Unless you mean for all this rigmarole to happen, just remember to always use double quotes around variable and command substitutions. Do take care: leaving out the quotes can lead not just to errors but to security holes.', 'If you write myfiles=""file1 file2"", with spaces to separate the files, this can\'t work with file names containing spaces. Unix file names can contain any character other than / (which is always a directory separator) and null bytes (which you can\'t use in shell scripts with most shells).', 'Same problem with myfiles=*.txt; … process $myfiles. When you do this, the variable myfiles contains the 5-character string *.txt, and it\'s when you write $myfiles that the wildcard is expanded. This example will actually work, until you change your script to be myfiles=""$someprefix*.txt""; … process $myfiles. If someprefix is set to final report, this won\'t work.', ""To process a list of any kind (such as file names), put it in an array. This requires mksh, ksh93, yash or bash (or zsh, which doesn't have all these quoting issues); a plain POSIX shell (such as ash or dash) doesn't have array variables."", 'Ksh88 has array variables with a different assignment syntax set -A myfiles ""someprefix""*.txt (see assignation variable under different ksh environment if you need ksh88/bash portability). Bourne/POSIX-style shells have a single one array, the array of positional parameters ""$@"" which you set with set and which is local to a function:', 'On a related note, keep in mind that file names can begin with a - (dash/minus), which most commands interpret as denoting an option. Some commands (like sh, set or sort) also accept options that start with +. If you have a file name that begins with a variable part, be sure to pass -- before it, as in the snippet above. This indicates to the command that it has reached the end of options, so anything after that is a file name even if it starts with - or +.', ""Alternatively, you can make sure that your file names begin with a character other than -. Absolute file names begin with /, and you can add ./ at the beginning of relative names. The following snippet turns the content of the variable f into a “safe” way of referring to the same file that's guaranteed not to start with - nor +."", 'On a final note on this topic, beware that some commands interpret - as meaning standard input or standard output, even after --. If you need to refer to an actual file named -, or if you\'re calling such a program and you don\'t want it to read from stdin or write to stdout, make sure to rewrite - as above. See What is the difference between ""du -sh *"" and ""du -sh ./*""? for further discussion.', '“Command” can mean three things: a command name (the name as an executable, with or without full path, or the name of a function, builtin or alias), a command name with arguments, or a piece of shell code. There are accordingly different ways of storing them in a variable.', 'If you have a command name, just store it and use the variable with double quotes as usual.', ""If you have a command with arguments, the problem is the same as with a list of file names above: this is a list of strings, not a string. You can't just stuff the arguments into a single string with spaces in between, because if you do that you can't tell the difference between spaces that are part of arguments and spaces that separate arguments. If your shell has arrays, you can use them."", ""What if you're using a shell without arrays? You can still use the positional parameters, if you don't mind modifying them."", ""What if you need to store a complex shell command, e.g. with redirections, pipes, etc.? Or if you don't want to modify the positional parameters? Then you can build a string containing the command, and use the eval builtin."", 'Note the nested quotes in the definition of code: the single quotes \'…\' delimit a string literal, so that the value of the variable code is the string /path/to/executable --option --message=""hello world"" -- /path/to/file1. The eval builtin tells the shell to parse the string passed as an argument as if it appeared in the script, so at that point the quotes and pipe are parsed, etc.', 'Using eval is tricky. Think carefully about what gets parsed when. In particular, you can\'t just stuff a file name into the code: you need to quote it, just like you would if it was in a source code file. There\'s no direct way to do that. Something like code=""$code $filename"" breaks if the file name contains any shell special character (spaces, $, ;, |, <, >, etc.). code=""$code \\""$filename\\"""" still breaks on ""$\\`. Even code=""$code \'$filename\'"" breaks if the file name contains a \'. There are two solutions.', ""Add a layer of quotes around the file name. The easiest way to do that is to add single quotes around it, and replace single quotes by '\\''."", ""Keep the variable expansion inside the code, so that it's looked up when the code is evaluated, not when the code fragment is built. This is simpler but only works if the variable is still around with the same value at the time the code is executed, not e.g. if the code is built in a loop."", 'Finally, do you really need a variable containing code? The most natural way to give a name to a code block is to define a function.', 'Without -r, read allows continuation lines — this is a single logical line of input:', ""read splits the input line into fields delimited by characters in $IFS (without -r, backslash also escapes those). For example, if the input is a line containing three words, then read first second third sets first to the first word of input, second to the second word and third to the third word. If there are more words, the last variable contains everything that's left after setting the preceding ones. Leading and trailing whitespace are trimmed."", 'Setting IFS to the empty string avoids any trimming. See Why is `while IFS= read` used so often, instead of `IFS=; while read..`? for a longer explanation.', 'The input format of xargs is whitespace-separated strings which can optionally be single- or double-quoted. No standard tool outputs this format.', 'The input to xargs -L1 or xargs -l is almost a list of lines, but not quite —\xa0if there is a space at the end of a line, the following line is a continuation line.', ""You can use xargs -0 where applicable (and where available: GNU (Linux, Cygwin), BusyBox, BSD, OSX, but it isn't in POSIX). That's safe, because null bytes can't appear in most data, in particular in file names. To produce a null-separated list of file names, use find … -print0 (or you can use find … -exec … as explained below)."", ""some_command needs to be an external command, it can't be a shell function or alias. If you need to invoke a shell to process the files, call sh explicitly."", ""Browse the quoting tag on this site, or shell or shell-script. (Click on “learn more…” to see some general tips and a hand-selected list of common questions.) If you've searched and you can't find an answer, ask away.""]","[<code>""$foo""</code>, <code>""$(foo)""</code>, <code>$foo</code>, <code>$(foo)</code>, <code>\[*?</code>, <code>read</code>, <code>read</code>, <code>while IFS= read -r line; do …</code>, <code>read</code>, <code>xargs</code>, <code>xargs</code>, <code>xargs</code>, <code>xargs -0</code>, <code>find … | xargs</code>, <code>find … -exec …</code>, <code>xargs</code>, <code>\""'</code>, <code>sh</code>, <code>ash</code>, <code>dash</code>, <code>bash</code>, <code>ksh</code>, <code>mksh</code>, <code>yash</code>, <code>""$foo""</code>, <code>$foo</code>, <code>foo</code>, <code>foo *  bar ​</code>, <code>foo</code>, <code>*</code>, <code>bar</code>, <code>foo</code>, <code>bar</code>, <code>foo</code>, <code>*</code>, <code>bar</code>, <code>""$@""</code>, <code>""$@""</code>, <code>""$1"" ""$2"" ""$3""</code>, <code>$(foo)</code>, <code>`foo`</code>, <code>`foo`</code>, <code>$(foo)</code>, <code>IFS</code>, <code>-</code>, <code>myfiles=""file1 file2""</code>, <code>/</code>, <code>myfiles=*.txt; … process $myfiles</code>, <code>myfiles</code>, <code>*.txt</code>, <code>$myfiles</code>, <code>myfiles=""$someprefix*.txt""; … process $myfiles</code>, <code>someprefix</code>, <code>final report</code>, <code>myfiles=(""$someprefix""*.txt)
process ""${myfiles[@]}""
</code>, <code>set -A myfiles ""someprefix""*.txt</code>, <code>""$@""</code>, <code>set</code>, <code>set -- ""$someprefix""*.txt
process -- ""$@""
</code>, <code>-</code>, <code>-</code>, <code>sh</code>, <code>set</code>, <code>sort</code>, <code>+</code>, <code>--</code>, <code>-</code>, <code>+</code>, <code>-</code>, <code>/</code>, <code>./</code>, <code>f</code>, <code>-</code>, <code>+</code>, <code>case ""$f"" in -* | +*) ""f=./$f"";; esac
</code>, <code>-</code>, <code>--</code>, <code>-</code>, <code>-</code>, <code>command_path=""$1""
…
""$command_path"" --option --message=""hello world""
</code>, <code>cmd=(/path/to/executable --option --message=""hello world"" --)
cmd=(""${cmd[@]}"" ""$file1"" ""$file2"")
""${cmd[@]}""
</code>, <code>set -- /path/to/executable --option --message=""hello world"" --
set -- ""$@"" ""$file1"" ""$file2""
""$@""
</code>, <code>eval</code>, <code>code='/path/to/executable --option --message=""hello world"" -- /path/to/file1 | grep ""interesting stuff""'
eval ""$code""
</code>, <code>code</code>, <code>'…'</code>, <code>code</code>, <code>/path/to/executable --option --message=""hello world"" -- /path/to/file1</code>, <code>eval</code>, <code>eval</code>, <code>code=""$code $filename""</code>, <code>$</code>, <code>;</code>, <code>|</code>, <code>&lt;</code>, <code>&gt;</code>, <code>code=""$code \""$filename\""""</code>, <code>""$\`</code>, <code>code=""$code '$filename'""</code>, <code>'</code>, <code>'\''</code>, <code>quoted_filename=$(printf %s. ""$filename"" | sed ""s/'/'\\\\''/g"")
code=""$code '${quoted_filename%.}'""
</code>, <code>code=""$code \""\$filename\""""
</code>, <code>read</code>, <code>-r</code>, <code>read</code>, <code>hello \
world
</code>, <code>read</code>, <code>$IFS</code>, <code>-r</code>, <code>read first second third</code>, <code>first</code>, <code>second</code>, <code>third</code>, <code>IFS</code>, <code>xargs</code>, <code>xargs</code>, <code>xargs -L1</code>, <code>xargs -l</code>, <code>xargs -0</code>, <code>find … -print0</code>, <code>find … -exec …</code>, <code>find</code>, <code>find … -exec some_command a_parameter another_parameter {} +
</code>, <code>some_command</code>, <code>sh</code>, <code>find … -exec sh -c '
  for x do
    … # process the file ""$x""
  done
' find-sh {} +
</code>]"
9,https://unix.stackexchange.com/questions/16640/,How can I get the size of a file in a bash script?,"['Your best bet if on a GNU system:', 'From man stat:', '%s total size, in bytes', 'In a bash script : ', ""NOTE: see @chbrown's answer for how to use stat in terminal on Mac OS X.""]","[<code>stat --printf=""%s"" file.any
</code>, <code>#!/bin/bash
FILENAME=/home/heiko/dummy/packages.txt
FILESIZE=$(stat -c%s ""$FILENAME"")
echo ""Size of $FILENAME = $FILESIZE bytes.""
</code>]"
10,https://unix.stackexchange.com/questions/3467/,"What does ""rc"" in .bashrc stand for?","['As is often the case with obscure terms, the Jargon File has an answer:', '[Unix: from runcom files on the CTSS system 1962-63, via the startup script /etc/rc] Script file containing startup instructions for an application program (or an entire operating system), usually a text file containing commands of the sort that might have been invoked manually once the system was running but are to be executed automatically each time the system starts up.', 'Thus, it would seem that the ""rc"" part stands for ""runcom"", which I believe can be expanded to ""run commands"".  In fact, this is exactly what the file contains, commands that bash should run.']",[]
11,https://unix.stackexchange.com/questions/5609/,How do I clear Bash's cache of paths to executables?,"['bash does cache the full path to a command.  You can verify that the command you are trying to execute is hashed with the type command:', 'To clear the entire cache:', 'Or just one entry:', 'For additional information, consult help hash and man bash.']","[<code>bash</code>, <code>type</code>, <code>$ type svnsync
svnsync is hashed (/usr/local/bin/svnsync)
</code>, <code>$ hash -r
</code>, <code>$ hash -d svnsync
</code>, <code>help hash</code>, <code>man bash</code>]"
12,https://unix.stackexchange.com/questions/44266/,How to colorize output of git?,"['You can create a section [color] in your ~/.gitconfig with e.g. the following content', 'You can also fine control what you want to have coloured in what way, e.g.', 'I hope this gets you started. And of course, you need a terminal which supports colour.']","[<code>[color]</code>, <code>~/.gitconfig</code>, <code>[color]
  diff = auto
  status = auto
  branch = auto
  interactive = auto
  ui = true
  pager = true
</code>, <code>[color ""status""]
  added = green
  changed = red bold
  untracked = magenta bold

[color ""branch""]
  remote = yellow
</code>]"
13,https://unix.stackexchange.com/questions/30370/,How to get the pid of the last executed command in shell script?,['The PID of the last executed command is in the $! shell variable:'],"[<code>$!</code>, <code>my-app &amp;
echo $!
</code>]"
14,https://unix.stackexchange.com/questions/146942/,How can I test if a variable is empty or contains only spaces?,"['First, note that the -z test is explicitly for:', 'the length of string is zero', 'That is, a string containing only spaces should not be true under -z, because it has a non-zero length.', 'What you want is to remove the spaces from the variable using the pattern replacement parameter expansion:', 'This expands the param variable and replaces all matches of the pattern  (a single space) with nothing, so a string that has only spaces in it will be expanded to an empty string.', 'The nitty-gritty of how that works is that ${var/pattern/string} replaces the first longest match of pattern with string. When pattern starts with / (as above) then it replaces all the matches. Because the replacement is empty, we can omit the final / and the string value:', '${parameter/pattern/string}', 'The pattern is expanded to produce a pattern just as in filename expansion. Parameter is expanded and the longest match of pattern against its value is replaced with string. If pattern begins with ‘/’, all matches of pattern are replaced with string. Normally only the first match is replaced. ... If string is null, matches of pattern are deleted and the / following pattern may be omitted.', 'After all that, we end up with ${param// } to delete all spaces.', 'Note that though present in ksh (where it originated), zsh and bash, that syntax is not POSIX and should not be used in sh scripts.']","[<code>-z</code>, <code>-z</code>, <code>[[ -z ""${param// }"" ]]
</code>, <code>param</code>, <code></code>, <code>${var/pattern/string}</code>, <code>pattern</code>, <code>string</code>, <code>pattern</code>, <code>/</code>, <code>/</code>, <code>string</code>, <code>${param// }</code>, <code>ksh</code>, <code>zsh</code>, <code>bash</code>, <code>sh</code>]"
15,https://unix.stackexchange.com/questions/35369/,How to define 'tab' delimiter with 'cut' in BASH?,"['Two ways:', 'Press Ctrl+V and then Tab to use ""verbatim"" quoted insert.', 'or write it like this to use ANSI-C quoting:']","[<code>cut -f2 -d'   ' infile
</code>, <code>cut -f2 -d$'\t' infile
</code>]"
16,https://unix.stackexchange.com/questions/148/,Colorizing your terminal and shell environment?,"['Here are a couple of things you can do:', 'Editors + Code\nA lot of editors have syntax highlighting support. vim and emacs have it on by default. You can also enable it under nano.', 'You can also syntax highlight code on the terminal by using Pygments as a command-line tool.', ""grep\ngrep --color=auto highlights all matches. You can also use export GREP_OPTIONS='--color=auto' to make it persistent without an alias. If you use --color=always, it'll use colour even when piping, which confuses things."", 'ls', 'ls --color=always', 'Colors specified by:', '(hint: dircolors can be helpful)', 'PS1\nYou can set your PS1 (shell prompt) to use colours. For example:', 'Will produce a PS1 like:', '[yellow]lucas@ubuntu: [red]~[normal]$ ', 'You can get really creative with this. As an idea:', 'Puts a bar at the top of your terminal with some random info. (For best results, also use alias clear=""echo -e \'\\e[2J\\n\\n\'"".)', 'Getting Rid of Escape Sequences', ""If something is stuck outputting colour when you don't want it to, I use this sed line to strip the escape sequences:"", 'If you want a more authentic experience, you can also get rid of lines starting with \\e[8m, which instructs the terminal to hide the text. (Not widely supported.)', 'Also note that those ^[s should be actual, literal ^[s. You can type them by pressing ^V^[ in bash, that is Ctrl + V, Ctrl + [. ']","[<code>vim</code>, <code>emacs</code>, <code>nano</code>, <code>grep --color=auto</code>, <code>export GREP_OPTIONS='--color=auto'</code>, <code>--color=always</code>, <code>ls --color=always</code>, <code>export LS_COLORS='rs=0:di=01;34:ln=01;36:mh=00:pi=40;33'
</code>, <code>dircolors</code>, <code>PS1='\e[33;1m\u@\h: \e[31m\W\e[0m\$ '
</code>, <code>PS1='\e[s\e[0;0H\e[1;33m\h    \t\n\e[1;32mThis is my computer\e[u[\u@\h:  \w]\$ '
</code>, <code>alias clear=""echo -e '\e[2J\n\n'""</code>, <code>sed</code>, <code>sed ""s/\[^[[0-9;]*[a-zA-Z]//gi""
</code>, <code>\e[8m</code>, <code>sed ""s/^\[^[8m.*$//gi""
</code>]"
17,https://unix.stackexchange.com/questions/47584/,"In a bash script, using the conditional ""or"" in an ""if"" statement","['If you want to say OR use double pipe (||).', '(The original OP code using | was simply piping the output of the left side to the right side, in the same way any ordinary pipe works.)', 'After many years of comments and misunderstanding, allow me to clarify.', 'To do OR you use ||.', ""Whether you use [ or [[ or test or (( all depends on what you need on a case by case basis. It's wrong to say that one of those is preferred in all cases. Sometimes [ is right and [[ is wrong. But that's not what the question was. OP asked why | didn't work. The answer is because it should be || instead.""]","[<code>OR</code>, <code>||</code>, <code>if [ ""$fname"" = ""a.txt"" ] || [ ""$fname"" = ""c.txt"" ]
</code>, <code>|</code>, <code>OR</code>, <code>||</code>, <code>[</code>, <code>[[</code>, <code>test</code>, <code>((</code>, <code>[</code>, <code>[[</code>, <code>|</code>, <code>||</code>]"
18,https://unix.stackexchange.com/questions/49214/,How to remove a single line from history?,"['If you want to run a command without saving it in history, prepend it with an extra space', 'For this to work you need either ignorespace or ignoreboth in HISTCONTROL.  For example, run', 'To make this setting persistent, put it in your .bashrc.', ""If you've already run the command, and want to remove it from history, first use"", 'to display the list of commands in your history.  Find the number next to the one you want to delete (e.g. 1234) and run ', 'Additionally, if the line you want to delete has already been written to your $HISTFILE (which typically happens when you end a session by default), you will need to write back to $HISTFILE, or the line will reappear when you open a new session:']","[<code>prompt$ echo saved
prompt$  echo not saved \
&gt; #     ^ extra space
</code>, <code>ignorespace</code>, <code>ignoreboth</code>, <code>HISTCONTROL</code>, <code>HISTCONTROL=ignorespace
</code>, <code>.bashrc</code>, <code>history
</code>, <code>history -d 1234
</code>, <code>history -w
</code>]"
19,https://unix.stackexchange.com/questions/1496/,Why doesn't my Bash script recognize aliases?,"['First of all, as ddeimeke said, aliases by default are not expanded in non-interactive shells.', 'Second, .bashrc is not read by non-interactive shells unless you set the BASH_ENV environment variable.', ""But most importantly: don't do that! Please? One day you will move that script somewhere where the necessary aliases are not set and it will break again."", 'Instead set and use variables as shortcuts in your script:']","[<code>.bashrc</code>, <code>BASH_ENV</code>, <code>#!/bin/bash

CMDA=/path/to/gizmo
CMDB=/path/to/huzzah.sh

for file in ""$@""
do
    $CMDA ""$file""
    $CMDB ""$file""
done
</code>]"
20,https://unix.stackexchange.com/questions/157329/,What does env x='() { :;}; command' bash do and why is it insecure?,"['bash stores exported function definitions as environment variables. Exported functions look like this:', 'That is, the environment variable foo has the literal contents:', 'When a new instance of bash launches, it looks for these specially crafted environment variables, and interprets them as function definitions. You can even write one yourself, and see that it still works:', 'Unfortunately, the parsing of function definitions from strings (the environment variables) can have wider effects than intended. In unpatched versions, it also interprets arbitrary commands that occur after the termination of the function definition. This is due to insufficient constraints in the determination of acceptable function-like strings in the environment. For example:', 'Note that the echo outside the function definition has been unexpectedly executed during bash startup. The function definition is just a step to get the evaluation and exploit to happen, the function definition itself and the environment variable used are arbitrary. The shell looks at the environment variables, sees foo, which looks like it meets the constraints it knows about what a function definition looks like, and it evaluates the line, unintentionally also executing the echo (which could be any command, malicious or not).', 'This is considered insecure because variables are not typically allowed or expected, by themselves, to directly cause the invocation of arbitrary code contained in them. Perhaps your program sets environment variables from untrusted user input. It would be highly unexpected that those environment variables could be manipulated in such a way that the user could run arbitrary commands without your explicit intent to do so using that environment variable for such a reason declared in the code.', ""Here is an example of a viable attack. You run a web server that runs a vulnerable shell, somewhere, as part of its lifetime. This web server passes environment variables to a bash script, for example, if you are using CGI, information about the HTTP request is often included as environment variables from the web server. For example, HTTP_USER_AGENT might be set to the contents of your user agent. This means that if you spoof your user agent to be something like '() { :; }; echo foo', when that shell script runs, echo foo will be executed. Again, echo foo could be anything, malicious or not.""]","[<code>$ foo() { bar; }
$ export -f foo
$ env | grep -A1 foo
foo=() {  bar
}
</code>, <code>foo</code>, <code>() {  bar
}
</code>, <code>$ export foo='() { echo ""Inside function""; }'
$ bash -c 'foo'
Inside function
</code>, <code>$ export foo='() { echo ""Inside function"" ; }; echo ""Executed echo""'
$ bash -c 'foo'
Executed echo
Inside function
</code>, <code>foo</code>, <code>HTTP_USER_AGENT</code>, <code>echo foo</code>, <code>echo foo</code>]"
21,https://unix.stackexchange.com/questions/19654/,How do I change the extension of multiple files?,"[""Straight from Greg's Wiki:"", ""Also see the entry on why you shouldn't parse ls."", 'Edit: if you have to use basename, your syntax would be:']","[<code>ls</code>, <code>basename</code>]"
22,https://unix.stackexchange.com/questions/23111/,"What is the ""eval"" command in bash?","['eval is part of POSIX. Its an interface which can be a shell built-in.', 'Its described in the ""POSIX Programmer\'s Manual"": http://www.unix.com/man-page/posix/1posix/eval/', 'It will take an argument and construct a command of it, which will be executed by the shell. This is the example of the manpage:', 'This is a common function in many languages, e.g. Perl and JavaScript.\nHave a look at perldoc eval for more examples: http://perldoc.perl.org/functions/eval.html']","[<code>eval</code>, <code>eval - construct command by concatenating arguments
</code>, <code>1) foo=10 x=foo
2) y='$'$x
3) echo $y
4) $foo
5) eval y='$'$x
6) echo $y
7) 10
</code>, <code>$foo</code>, <code>'10'</code>, <code>$x</code>, <code>'foo'</code>, <code>$y</code>, <code>'$foo'</code>, <code>'$'</code>, <code>echo $y</code>, <code>'$foo'</code>, <code>eval</code>, <code>$x</code>, <code>'foo'</code>, <code>y=$foo</code>, <code>y=10</code>, <code>echo $y</code>, <code>'10'</code>]"
23,https://unix.stackexchange.com/questions/293940/,"How can I make ""Press any key to continue""","['You can use the read command:', 'As mentioned in the comments above, this command does actually require the user to press enter; a solution that works with any key would be:', '-n defines the required character count to stop reading', ""-s hides the user's input"", '-r causes the string to be interpreted ""raw"" (without considering backslash escapes)']","[<code>read</code>, <code>read -p ""Press enter to continue""
</code>, <code>read -n 1 -s -r -p ""Press any key to continue""
</code>, <code>-n</code>, <code>-s</code>, <code>-r</code>]"
24,https://unix.stackexchange.com/questions/188182/,How can I get the current working directory?,"[""There's no need to do that, it's already in a variable:"", 'The PWD variable is defined by POSIX and will work on all POSIX-compliant shells:', 'PWD ', 'Set by the shell and by the cd utility. In the shell the value\n  shall be initialized from the environment as follows. If a value for\n  PWD is passed to the shell in the environment when it is executed, the\n  value is an absolute pathname of the current working directory that is\n  no longer than {PATH_MAX} bytes including the terminating null byte,\n  and the value does not contain any components that are dot or dot-dot,\n  then the shell shall set PWD to the value from the environment.\n  Otherwise, if a value for PWD is passed to the shell in the\n  environment when it is executed, the value is an absolute pathname of\n  the current working directory, and the value does not contain any\n  components that are dot or dot-dot, then it is unspecified whether the\n  shell sets PWD to the value from the environment or sets PWD to the\n  pathname that would be output by pwd -P. Otherwise, the sh utility\n  sets PWD to the pathname that would be output by pwd -P. In cases\n  where PWD is set to the value from the environment, the value can\n  contain components that refer to files of type symbolic link. In cases\n  where PWD is set to the pathname that would be output by pwd -P, if\n  there is insufficient permission on the current working directory, or\n  on any parent of that directory, to determine what that pathname would\n  be, the value of PWD is unspecified. Assignments to this variable may\n  be ignored. If an application sets or unsets the value of PWD, the\n  behaviors of the cd and pwd utilities are unspecified.', 'For the more general answer, the way to save the output of a command in a variable is to enclose the command in $() or ` ` (backticks):', 'or', 'Of the two, the $() is preferred since it is easier to build complex commands like command0 $(command1 $(command2 $(command3))).']","[<code>$ echo $PWD
/home/terdon
</code>, <code>PWD</code>, <code>$()</code>, <code>` `</code>, <code>var=$(command)
</code>, <code>var=`command`
</code>, <code>$()</code>, <code>command0 $(command1 $(command2 $(command3)))</code>]"
25,https://unix.stackexchange.com/questions/171346/,Security implications of forgetting to quote a variable in bash/POSIX shells,"['First, I\'d say it\'s not the right way to address the problem.\nIt\'s a bit like saying ""you should not murder people because\notherwise you\'ll go to jail"".', ""Similarly, you don't quote your variable because otherwise\nyou're introducing security vulnerabilities. You quote your\nvariables because it is wrong not to (but if the fear of the jail can help, why not)."", ""A little summary for those who've just jumped on the train."", 'In most shells, leaving a variable expansion unquoted (though\nthat (and the rest of this answer) also applies to command\nsubstitution (`...` or $(...)) and arithmetic expansion ($((...)) or $[...])) has a very special\nmeaning. The best way to describe it is that it is like\ninvoking some sort of implicit split+glob operator¹.', 'in another language would be written something like:', '$var is first split into a list of words according to complex\nrules involving the $IFS special parameter (the split part)\nand then each word resulting of that splitting is considered as\na pattern which is expanded to a list of files that match it\n(the glob part).', 'As an example, if $var contains *.txt,/var/*.xml and $IFS\ncontains ,, cmd would be called with a number of arguments,\nthe first one being cmd and the next ones being the txt\nfiles in the current directory and the xml files in /var.', ""If you wanted to call cmd with just the two literal arguments cmd\nand *.txt,/var/*.xml, you'd write:"", 'which would be in your other more familiar language:', ""After all, it's been known since the dawn of time that shell\nscripts should not be used in security-sensitive contexts.\nSurely,  OK, leaving a variable unquoted is a bug but that can't\ndo that much harm, can it?"", ""Well, despite the fact that anybody would tell you that shell\nscripts should never be used for web CGIs, or that thankfully\nmost systems don't allow setuid/setgid shell scripts nowadays,\none thing that shellshock (the remotely exploitable bash bug\nthat made the headlines in September 2014) revealed is that\nshells are still extensively used where they probably shouldn't:\nin CGIs, in DHCP client hook scripts, in sudoers commands,\ninvoked by (if not as) setuid commands..."", ""Sometimes unknowingly. For instance system('cmd $PATH_INFO')\nin a php/perl/python CGI script does invoke a shell to interpret that command line (not to\nmention the fact that cmd itself may be a shell script and its\nauthor may have never expected it to be called from a CGI)."", ""You've got a vulnerability when there's a path for privilege\nescalation, that is when someone (let's call him the attacker)\nis able to do something he is not meant to."", ""Invariably that means the attacker providing data, that data\nbeing processed by a privileged user/process which inadvertently\ndoes something it shouldn't be doing, in most of the cases because\nof a bug."", ""Basically, you've got a problem when your buggy code processes\ndata under the control of the attacker."", ""Now, it's not always obvious where that data may come from,\nand it's often hard to tell if your code will ever get to\nprocess untrusted data."", ""As far as variables are concerned, In the case of a CGI script,\nit's quite obvious, the data are the CGI GET/POST parameters and\nthings like cookies, path, host... parameters."", ""For a setuid script (running as one user when invoked by\nanother), it's the arguments or environment variables."", ""Another very common vector is file names. If you're getting a\nfile list from a directory, it's possible that files have been\nplanted there by the attacker."", 'In that regard, even at the prompt of an interactive shell, you\ncould be vulnerable (when processing files in /tmp or ~/tmp\nfor instance).', 'Even a ~/.bashrc can be vulnerable (for instance, bash will\ninterpret it when invoked over ssh to run a ForcedCommand\nlike in git server deployments with some variables under the\ncontrol of the client).', ""Now, a script may not be called directly to process untrusted\ndata, but it may be called by another command that does. Or your\nincorrect code may be copy-pasted into scripts that do (by you 3\nyears down the line or one of your colleagues). One place where it's\nparticularly critical is in answers in Q&A sites as you'll\nnever know where copies of your code may end up."", ""Leaving a variable (or command substitution) unquoted is by far\nthe number one source of security vulnerabilities associated\nwith shell code. Partly because those bugs often translate to\nvulnerabilities but also because it's so common to see unquoted\nvariables."", ""Actually, when looking for vulnerabilities in shell code, the\nfirst thing to do is look for unquoted variables. It's easy to\nspot, often a good candidate, generally easy to track back to\nattacker-controlled data."", ""There's an infinite number of ways an unquoted variable can turn\ninto a vulnerability. I'll just give a few common trends here."", ""Most people will bump into bugs associated with unquoted\nvariables because of the split part (for instance, it's\ncommon for files to have spaces in their names nowadays and space\nis in the default value of IFS). Many people will overlook the\nglob part. The glob part is at least as dangerous as the\nsplit part."", 'Globbing done upon unsanitised external input means the\nattacker can make you read the content of any directory.', 'In:', 'if $unsanitised_external_input contains /*, that means the\nattacker can see the content of /. No big deal. It becomes\nmore interesting though with /home/* which gives you a list of\nuser names on the machine, /tmp/*,  /home/*/.forward for\nhints at other dangerous practises, /etc/rc*/* for enabled\nservices... No need to name them individually. A value of /* /*/* /*/*/*... will just list the whole file system.', ""Taking the previous case a bit too far and we've got a DoS."", 'Actually, any unquoted variable in list context with unsanitized\ninput is at least a DoS vulnerability.', 'Even expert shell scripters commonly forget to quote things\nlike:', ': is the no-op command. What could possibly go wrong?', ""That's meant to assign $1 to $QUERYSTRING if $QUERYSTRING\nwas unset. That's a quick way to make a CGI script callable from\nthe command line as well."", ""That $QUERYSTRING is still expanded though and because it's\nnot quoted, the split+glob operator is invoked."", 'Now, there are some globs that are particularly expensive to\nexpand. The /*/*/*/* one is bad enough as it means listing\ndirectories up to 4 levels down. In addition to the disk and CPU\nactivity, that means storing tens of thousands of file paths\n(40k here on a minimal server VM, 10k of which directories).', 'Now /*/*/*/*/../../../../*/*/*/* means 40k x 10k and\n/*/*/*/*/../../../../*/*/*/*/../../../../*/*/*/* is enough to\nbring even the mightiest machine to its knees.', 'Try it for yourself (though be prepared for your machine to\ncrash or hang):', 'Of course, if the code is:', 'Then you can fill up the disk.', ""Just do a google search on shell\ncgi or bash\ncgi or ksh\ncgi, and you'll find\na few pages that show you how to write CGIs in shells. Notice\nhow half of those that process parameters are vulnerable."", ""Even David Korn's\nown\none\nis vulnerable (look at the cookie handling)."", ""Arbitrary code execution is the worst type of vulnerability,\nsince if the attacker can run any command, there's no limit on\nwhat he may do."", ""That's generally the split part that leads to those. That\nsplitting results in several arguments to be passed to commands\nwhen only one is expected. While the first of those will be used\nin the expected context, the others will be in a different context\nso potentially interpreted differently. Better with an example:"", 'Here, the intention was to assign the content of the\n$external_input shell variable to the foo awk variable.', 'Now:', 'The second word resulting of the splitting of $external_input\nis not assigned to foo but considered as awk code (here that\nexecutes an arbitrary command: uname).', ""That's especially a problem for commands that can execute other\ncommands (awk, env, sed (GNU one), perl, find...) especially\nwith the GNU variants (which accept options after arguments).\nSometimes, you wouldn't suspect commands to be able to execute\nothers like ksh, bash or zsh's [ or printf..."", ""If we create a directory called x -o yes, then the test\nbecomes positive, because it's a completely different\nconditional expression we're evaluating."", 'Worse, if we create a file called x -a a[0$(uname>&2)] -gt 1,\nwith all ksh implementations at least (which includes the sh\nof most commercial Unices and some BSDs), that executes uname\nbecause those shells perform arithmetic evaluation on the\nnumerical comparison operators of the [ command.', 'Same with bash for a filename like x -a -v a[0$(uname>&2)].', ""Of course, if they can't get arbitrary execution, the attacker may\nsettle for lesser damage (which may help to get arbitrary\nexecution). Any command that can write files or change\npermissions, ownership or have any main or side effect could be exploited."", 'All sorts of things can be done with file names.', 'And you end up making .. writeable (recursively with GNU\nchmod).', 'Scripts doing automatic processing of files in publicly writable areas like /tmp are to be written very carefully.', ""That's something I find exasperating. Some people go down all\nthe trouble of wondering whether a particular expansion may be\nproblematic to decide if they can omit the quotes."", ""It's like saying. Hey, it looks like $# cannot be subject to\nthe split+glob operator, let's ask the shell to split+glob it.\nOr Hey, let's write incorrect code just because the bug is\nunlikely to be hit."", 'Now how unlikely is it? OK, $# (or $!, $? or any\narithmetic substitution) may only contain digits (or - for\nsome²) so the glob part is out. For the split part to do\nsomething though, all we need is for $IFS to contain digits (or -).', ""With some shells, $IFS may be inherited from the environment,\nbut if the environment is not safe, it's game over anyway."", 'Now if you write a function like:', 'What that means is that the behaviour of your function depends\non the context in which it is called. Or in other words, $IFS\nbecomes one of the inputs to it. Strictly speaking, when you\nwrite the API documentation for your function, it should be\nsomething like:', ""And code calling your function needs to make sure $IFS doesn't\ncontain digits. All that because you didn't feel like typing\nthose 2 double-quote characters."", ""Now, for that [ $# -eq 2 ] bug to become a vulnerability,\nyou'd need somehow for the value of $IFS to become under\ncontrol of the attacker. Conceivably, that would not normally\nhappen unless the attacker managed to exploit another bug."", ""That's not unheard of though. A common case is when people\nforget to sanitize data before using it in arithmetic\nexpression. We've already seen above that it can allow\narbitrary code execution in some shells, but in all of them, it allows\nthe attacker to give any variable an integer value."", 'For instance:', 'And with a $1 with value (IFS=-1234567890), that arithmetic\nevaluation has the side effect of settings IFS and the next [\ncommand fails which means the check for too many args is\nbypassed.', ""There's another case where quotes are needed around variables and other expansions: when it's used as a pattern."", 'do not test whether $a and $b are the same (except with zsh) but if $a matches the pattern in $b. And you need to quote $b if you want to compare as strings (same thing in ""${a#$b}"" or ""${a%$b}"" or ""${a##*$b*}"" where $b should be quoted if it\'s not to be taken as a pattern).', 'What that means is that [[ $a = $b ]] may return true in cases where $a is different from $b (for instance when $a is anything and $b is *) or may return false when they are identical (for instance when both $a and $b are [a]).', ""Can that make for a security vulnerability? Yes, like any bug. Here, the attacker can alter your script's logical code flow and/or break the assumptions that your script are making. For instance, with a code like:"", ""The attacker can bypass the check by passing '[a]' '[a]'."", ""Now, if neither that pattern matching nor the split+glob operator apply, what's the danger of leaving a variable unquoted?"", 'I have to admit that I do write:', ""There, quoting doesn't harm but is not strictly necessary."", 'However, one side effect of omitting quotes in those cases (for instance in Q&A answers) is that it can send a wrong message to beginners: that it may be all right not to quote variables.', ""For instance, they may start thinking that if a=$b is OK, then export a=$b would be as well (which it's not in many shells as it's in arguments to the export command so in list context) or env a=$b."", 'zsh did fix most of those design awkwardnesses. In zsh (at least when not in sh/ksh emulation mode), if you want splitting, or globbing, or pattern matching, you have to request it explicitly: $=var to split, and $~var to glob or for the content of the variable to be treated as a pattern.', 'However, splitting (but not globbing) is still done implicitly upon unquoted command substitution (as in echo $(cmd)).', ""Also, a sometimes unwanted side effect of not quoting variable is the empties removal. The zsh behaviour is similar to what you can achieve in other shells by disabling globbing altogether (with set -f) and splitting (with IFS=''). Still, in:"", 'There will be no split+glob, but if $var is empty, instead of receiving one empty argument, cmd will receive no argument at all.', ""That can cause bugs (like the obvious [ -n $var ]). That can possibly break a script's expectations and assumptions and cause vulnerabilities."", 'As the empty variable can cause an argument to be just removed, that means the  next argument could be interpreted in the wrong context.', 'As an example,', 'If $attacker_supplied1 is empty,  then $attacker_supplied2 will be interpreted as an arithmetic expression (for %d) instead of a string (for %s) and any unsanitized data used in an arithmetic expression is a command injection vulnerability in Korn-like shells such as zsh.', 'fine, but:', 'The uname arbitrary command was run.', ""Yes, that's typically when you do want to leave your variable unquoted. But then you need to make sure you tune your split and glob operators correctly before using it. If you only want the split part and not the glob part (which is the case most of the time), then you do need to disable globbing (set -o noglob/set -f) and fix $IFS. Otherwise you'll cause vulnerabilities as well (like David Korn's CGI example mentioned above)."", ""In short, leaving a variable (or command substitution or\narithmetic expansion) unquoted in shells can be very dangerous\nindeed especially when done in the wrong contexts, and it's very\nhard to know which are those wrong contexts."", ""That's one of the reasons why it is considered bad practice."", ""Thanks for reading so far. If it goes over your head, don't\nworry. One can't expect everyone to understand all the implications of\nwriting their code the way they write it. That's why we have\ngood practice recommendations, so they can be followed without\nnecessarily understanding why."", ""(and in case that's not obvious yet, please avoid writing\nsecurity sensitive code in shells)."", 'And please quote your variables on your answers on this site!', '¹In ksh93 and pdksh and derivatives, brace expansion is also performed unless globbing is disabled (in the case of ksh93 versions up to ksh93u+, even when the braceexpand option is disabled).', '² In ksh93 and yash, arithmetic expansions can also include things like 1,2, 1e+66, inf, nan. There are even more in zsh, including # which is glob operator with extendedglob, but zsh never does split+glob upon arithmetic expansion, even in sh emulation']","[<code>`...`</code>, <code>$(...)</code>, <code>$((...))</code>, <code>$[...]</code>, <code>cmd $var
</code>, <code>cmd(glob(split($var)))
</code>, <code>$var</code>, <code>$IFS</code>, <code>$var</code>, <code>*.txt,/var/*.xml</code>, <code>$IFS</code>, <code>,</code>, <code>cmd</code>, <code>cmd</code>, <code>txt</code>, <code>xml</code>, <code>/var</code>, <code>cmd</code>, <code>cmd</code>, <code>*.txt,/var/*.xml</code>, <code>cmd ""$var""
</code>, <code>cmd($var)
</code>, <code>system('cmd $PATH_INFO')</code>, <code>php</code>, <code>perl</code>, <code>python</code>, <code>cmd</code>, <code>/tmp</code>, <code>~/tmp</code>, <code>~/.bashrc</code>, <code>bash</code>, <code>ssh</code>, <code>ForcedCommand</code>, <code>git</code>, <code>echo You entered: $unsanitised_external_input
</code>, <code>$unsanitised_external_input</code>, <code>/*</code>, <code>/</code>, <code>/home/*</code>, <code>/tmp/*</code>, <code>/home/*/.forward</code>, <code>/etc/rc*/*</code>, <code>/* /*/* /*/*/*...</code>, <code>#! /bin/sh -
: ${QUERYSTRING=$1}
</code>, <code>:</code>, <code>$1</code>, <code>$QUERYSTRING</code>, <code>$QUERYSTRING</code>, <code>$QUERYSTRING</code>, <code>/*/*/*/*</code>, <code>/*/*/*/*/../../../../*/*/*/*</code>, <code>/*/*/*/*/../../../../*/*/*/*/../../../../*/*/*/*</code>, <code>a='/*/*/*/*/../../../../*/*/*/*/../../../../*/*/*/*' sh -c ': ${a=foo}'
</code>, <code>echo $QUERYSTRING &gt; /some/file
</code>, <code>awk -v foo=$external_input '$2 == foo'
</code>, <code>$external_input</code>, <code>foo</code>, <code>awk</code>, <code>$ external_input='x BEGIN{system(""uname"")}'
$ awk -v foo=$external_input '$2 == foo'
Linux
</code>, <code>$external_input</code>, <code>foo</code>, <code>awk</code>, <code>uname</code>, <code>awk</code>, <code>env</code>, <code>sed</code>, <code>perl</code>, <code>find</code>, <code>ksh</code>, <code>bash</code>, <code>zsh</code>, <code>[</code>, <code>printf</code>, <code>for file in *; do
  [ -f $file ] || continue
  something-that-would-be-dangerous-if-$file-were-a-directory
done
</code>, <code>x -o yes</code>, <code>x -a a[0$(uname&gt;&amp;2)] -gt 1</code>, <code>sh</code>, <code>uname</code>, <code>[</code>, <code>$ touch x 'x -a a[0$(uname&gt;&amp;2)] -gt 1'
$ ksh -c 'for f in *; do [ -f $f ]; done'
Linux
</code>, <code>bash</code>, <code>x -a -v a[0$(uname&gt;&amp;2)]</code>, <code>$ touch -- '-R ..'
$ for file in *; do [ -f ""$file"" ] &amp;&amp; chmod +w $file; done
</code>, <code>..</code>, <code>chmod</code>, <code>/tmp</code>, <code>[ $# -gt 1 ]</code>, <code>$#</code>, <code>$#</code>, <code>$!</code>, <code>$?</code>, <code>-</code>, <code>$IFS</code>, <code>-</code>, <code>$IFS</code>, <code>my_function() {
  [ $# -eq 2 ] || return
  ...
}
</code>, <code>$IFS</code>, <code># my_function
#   inputs:
#     $1: source directory
#     $2: destination directory
#   $IFS: used to split $#, expected not to contain digits...
</code>, <code>$IFS</code>, <code>[ $# -eq 2 ]</code>, <code>$IFS</code>, <code>n=$(($1 + 1))
if [ $# -gt 2 ]; then
  echo &gt;&amp;2 ""Too many arguments""
  exit 1
fi
</code>, <code>$1</code>, <code>(IFS=-1234567890)</code>, <code>[</code>, <code>[[ $a = $b ]]   # a `ksh` construct also supported by `bash`
case $a in ($b) ...; esac
</code>, <code>$a</code>, <code>$b</code>, <code>zsh</code>, <code>$a</code>, <code>$b</code>, <code>$b</code>, <code>""${a#$b}""</code>, <code>""${a%$b}""</code>, <code>""${a##*$b*}""</code>, <code>$b</code>, <code>[[ $a = $b ]]</code>, <code>$a</code>, <code>$b</code>, <code>$a</code>, <code>anything</code>, <code>$b</code>, <code>*</code>, <code>$a</code>, <code>$b</code>, <code>[a]</code>, <code>if [[ $1 = $2 ]]; then
   echo &gt;&amp;2 '$1 and $2 cannot be the same or damage will incur'
   exit 1
fi
</code>, <code>'[a]' '[a]'</code>, <code>a=$b
case $a in...
</code>, <code>a=$b</code>, <code>export a=$b</code>, <code>export</code>, <code>env a=$b</code>, <code>zsh</code>, <code>zsh</code>, <code>zsh</code>, <code>$=var</code>, <code>$~var</code>, <code>echo $(cmd)</code>, <code>zsh</code>, <code>set -f</code>, <code>IFS=''</code>, <code>cmd $var
</code>, <code>$var</code>, <code>cmd</code>, <code>[ -n $var ]</code>, <code>printf '[%d] &lt;%s&gt;\n' 1 $attacker_supplied1 2 $attacker_supplied2
</code>, <code>$attacker_supplied1</code>, <code>$attacker_supplied2</code>, <code>%d</code>, <code>%s</code>, <code>$ attacker_supplied1='x y' attacker_supplied2='*'
$ printf '[%d] &lt;%s&gt;\n' 1 $attacker_supplied1 2 $attacker_supplied2
[1] &lt;x y&gt;
[2] &lt;*&gt;
</code>, <code>$ attacker_supplied1='' attacker_supplied2='psvar[$(uname&gt;&amp;2)0]'
$ printf '[%d] &lt;%s&gt;\n' 1 $attacker_supplied1 2 $attacker_supplied2
Linux
[1] &lt;2&gt;
[0] &lt;&gt;
</code>, <code>uname</code>, <code>set -o noglob</code>, <code>set -f</code>, <code>$IFS</code>, <code>ksh93</code>, <code>pdksh</code>, <code>ksh93</code>, <code>braceexpand</code>, <code>ksh93</code>, <code>yash</code>, <code>1,2</code>, <code>1e+66</code>, <code>inf</code>, <code>nan</code>, <code>zsh</code>, <code>#</code>, <code>extendedglob</code>, <code>zsh</code>, <code>sh</code>]"
26,https://unix.stackexchange.com/questions/31947/,How to add a newline to the end of a file?,"['To recursively sanitize a project I use this oneliner:', 'Explanation:', 'git ls-files -z lists files in the repository. It takes an optional pattern as additional parameter which might be useful in some cases if you want to restrict the operation to certain files/directories. As an alternative, you could use find -print0 ... or similar programs to list affected files - just make sure it emits NUL-delimited entries.', ""while IFS= read -rd '' f; do ... done iterates through the entries, safely handling filenames that include whitespace and/or newlines."", 'tail -c1 < ""$f"" reads the last char from a file.', 'read -r _ exits with a nonzero exit status if a trailing newline is missing.', '|| echo >> ""$f"" appends a newline to the file if the exit status of the previous command was nonzero.']","[<code>git ls-files -z | while IFS= read -rd '' f; do tail -c1 &lt; ""$f"" | read -r _ || echo &gt;&gt; ""$f""; done
</code>, <code>git ls-files -z</code>, <code>find -print0 ...</code>, <code>NUL</code>, <code>while IFS= read -rd '' f; do ... done</code>, <code>tail -c1 &lt; ""$f""</code>, <code>read -r _</code>, <code>|| echo &gt;&gt; ""$f""</code>]"
27,https://unix.stackexchange.com/questions/7558/,Execute a command once per line of piped input?,"[""That's what xargs does.""]","[<code>xargs</code>, <code>... | xargs command
</code>]"
28,https://unix.stackexchange.com/questions/813/,How to determine where an environment variable came from?,"[""If you use the env command to display the variables, they should show up roughly in the order in which they were created.  You can use this as a guide to if they were set by the system very early in the boot, or by a later .profile or other configuration file.  In my experience, the set and export commands will sort their variables by alphabetical order, so that listing isn't as useful.""]","[<code>env</code>, <code>set</code>, <code>export</code>]"
29,https://unix.stackexchange.com/questions/129143/,What is the purpose of .bashrc and how does it work?,"['.bashrc is a shell script that Bash runs whenever it is started interactively. It initializes an interactive shell session. You can put any command in that file that you could type at the command prompt.', 'You put commands here to set up the shell for use in your particular environment, or to customize things to your preferences. A common thing to put in .bashrc are aliases that you want to always be available.', '.bashrc runs on every interactive shell launch. If you say:', 'and then hit Ctrl-D three times, .bashrc will run three times.  But if you say this instead:', ""then .bashrc won't run at all, since -c makes the Bash call non-interactive. The same is true when you run a shell script from a file."", 'Contrast .bash_profile and .profile which are only run at the start of a new login shell. (bash -l) You choose whether a command goes in .bashrc vs .bash_profile depending on on whether you want it to run once or for every interactive shell start.', 'As a counterexample to aliases, which I prefer to put in .bashrc, you want to do PATH adjustments in .bash_profile instead, since these changes are typically not idempotent:', 'If you put that in .bashrc instead, every time you launched an interactive sub-shell, :/some/addition would get tacked on to the end of the PATH again, creating extra work for the shell when you mistype a command.', 'You get a new interactive Bash shell whenever you shell out of vi with :sh, for example.']","[<code>.bashrc</code>, <code>.bashrc</code>, <code>.bashrc</code>, <code>$ bash ; bash ; bash
</code>, <code>.bashrc</code>, <code>$ bash -c exit ; bash -c exit ; bash -c exit
</code>, <code>.bashrc</code>, <code>-c</code>, <code>.bash_profile</code>, <code>.profile</code>, <code>bash -l</code>, <code>.bashrc</code>, <code>.bash_profile</code>, <code>.bashrc</code>, <code>PATH</code>, <code>.bash_profile</code>, <code>export PATH=""$PATH:/some/addition""
</code>, <code>.bashrc</code>, <code>:/some/addition</code>, <code>PATH</code>, <code>vi</code>, <code>:sh</code>]"
30,https://unix.stackexchange.com/questions/105958/,Terminal prompt not wrapping correctly,"['Non-printable sequences should be enclosed in \\[ and \\]. Looking at your PS1 it has a unenclosed sequence after \\W. But, the second entry is redundant as well as it repeats the previous statement ""1;34"".', 'As such this should have intended coloring:', 'Keeping the ""original"" this should also work:', 'The reason for the behavior is because bash believes the prompt is longer then it actually is. As a simple example, if one use:', 'The prompt is believed to be 8 characters and not 1. As such if terminal window is 20 columns, after typing 12 characters, it is believed to be 20 and wraps around. This is also evident if one then try to do backspace or Ctrl+u. It stops at column 9.', 'However it also does not start new line unless one are on last column, as a result the first line is overwritten.', 'If one keep typing the line should wrap to next line after 32 characters.']","[<code>\[</code>, <code>\]</code>, <code>\W</code>, <code>\[\033[01;32m\]\u:\[\033[01;34m\] \W\033[01;34m \$\[\033[00m\]
                  |_____________|               |_|
                         |                       |
                         +--- Let this apply to this as well.
</code>, <code>\[\033[1;32m\]\u:\[\033[1;34m\] \W \$\[\033[0m\]
                               |_____|
                                  |
                                  +---- Bold blue.
</code>, <code>\[\033[1;32m\]\u:\[\033[1;34m\] \W\[\033[1;34m\] \$\[\033[0m\]
                                  |_|         |_|
                                   |           |
                                   +-----------+-- Enclose in \[ \]
</code>, <code>bash</code>, <code>PS1=""\033[0;34m$""
       1 2345678
</code>]"
31,https://unix.stackexchange.com/questions/9123/,Is there a one-liner that allows me to create a directory and move into it at the same time?,"['This is the one-liner that you need. No other config needed:', 'The $_ variable, in bash, is the last argument given to the previous command. In this case, the name of the directory you just created. As explained in man bash:', 'Use cd $_ to retrieve the last argument of the previous command instead of cd !$ because cd !$ gives the last argument of previous command in the shell history:', 'you end up home (or ~/ )', 'you end up in newfolder under home !! ( or ~/newfolder )']","[<code>mkdir longtitleproject &amp;&amp; cd $_
</code>, <code>$_</code>, <code>man bash</code>, <code>_         At  shell  startup,  set to the absolute pathname used to invoke
          the shell or shell script being executed as passed in the  envi‐
          ronment  or  argument  list.   Subsequently, expands to the last
          argument to the previous command, after expansion.  Also set  to
          the  full  pathname  used  to  invoke  each command executed and
          placed in the environment exported to that command.  When check‐
          ing  mail,  this  parameter holds the name of the mail file cur‐
          rently being checked.""$_"" is the last argument of the previous command.
</code>, <code>cd $_</code>, <code>cd !$</code>, <code>cd !$</code>, <code>cd ~/
mkdir folder &amp;&amp; cd !$
</code>, <code>cd ~/
mkdir newfolder &amp;&amp; cd $_
</code>]"
32,https://unix.stackexchange.com/questions/116959/,There are stopped jobs (on bash exit),"['A stopped job is one that has been temporarily put into the background and is no longer running, but is still using resources (i.e. system memory). Because that job is not attached to the current terminal, it cannot produce output and is not receiving input from the user.', 'You can see jobs you have running using the jobs builtin command in bash, probably other shells as well. Example:', 'You can resume a stopped job by using the fg (foreground) bash built-in command. If you have multiple commands that have been stopped you must specify which one to resume by passing jobspec number on the command line with fg. If only one program is stopped, you may use fg alone:', 'At this point you are back in the python interpreter and may exit by using control-D.', ""Conversely, you may kill the command with either it's jobspec or PID. For instance:"", 'To use the jobspec, precede the number with the percent (%) key:', ""If you issue an exit command with stopped jobs, the warning you saw will be given. The jobs will be left running for safety. That's to make sure you are aware you are attempting to kill jobs you might have forgotten you stopped. The second time you use the exit command the jobs are terminated and the shell exits. This may cause problems for some programs that aren't intended to be killed in this fashion."", 'In bash it seems you can use the logout command which will kill stopped processes and exit. This may cause unwanted results.', 'Also note that some programs may not exit when terminated in this way, and your system could end up with a lot of orphaned processes using up resources if you make a habit of doing that.', 'Note that you can create background process that will stop if they require user input:', 'You can resume and kill these jobs in the same way you did jobs that you stopped with the Ctrl-z interrupt.']","[<code>jobs</code>, <code>user@mysystem:~$ jobs
[1] + Stopped                python
user@mysystem:~$ 
</code>, <code>fg</code>, <code>fg</code>, <code>fg</code>, <code>user@mysystem:~$ fg 1
python
</code>, <code>kill</code>, <code>user@mysystem:~$ ps
  PID TTY          TIME CMD
16174 pts/3    00:00:00 bash
17781 pts/3    00:00:00 python
18276 pts/3    00:00:00 ps
user@mysystem:~$ kill 17781
[1]+  Killed                  python
user@mysystem:~$ 
</code>, <code>user@mysystem:~$ kill %1
[1]+  Terminated              python
</code>, <code>logout</code>, <code>user@mysystem:~$ python &amp;
[1] 19028
user@mysystem:~$ jobs
[1]+  Stopped                 python
</code>, <code>Ctrl-z</code>]"
33,https://unix.stackexchange.com/questions/39291/,Run a command that is shadowed by an alias,"['You can also prefix a back slash to disable the alias: \\ls', 'Edit: Other ways of doing the same include:', 'Use ""command"": command ls as per Mikel.', 'Use the full path: /bin/ls as per uther.', 'Quote the command: ""ls"" or \'ls\' as per Mikel comment.', 'You can remove the alias temporarily for that terminal session with unalias command_name.']","[<code>\ls</code>, <code>command ls</code>, <code>/bin/ls</code>, <code>""ls""</code>, <code>'ls'</code>, <code>unalias command_name</code>]"
34,https://unix.stackexchange.com/questions/9496/,Looping through files with spaces in the names?,"['Short answer (closest to your answer, but handles spaces)', 'Better answer (also handles wildcards and newlines in file names)', ""Best answer (based on Gilles' answer)"", 'Or even better, to avoid running one sh per file:', 'Long answer', 'You have three problems:', '1. Splitting only on newlines', 'To figure out what to set file to, the shell has to take the output of find and interpret it somehow, otherwise file would just be the entire output of find.', 'The shell reads the IFS variable, which is set to <space><tab><newline> by default.', ""Then it looks at each character in the output of find.  As soon as it sees any character that's in IFS, it thinks that marks the end of the file name, so it sets file to whatever characters it saw until now and runs the loop.  Then it starts where it left off to get the next file name, and runs the next loop, etc., until it reaches the end of output."", ""So it's effectively doing this:"", 'To tell it to only split the input on newlines, you need to do', 'before your for ... find command.', 'That sets IFS to a single newline, so it only splits on newlines, and not spaces and tabs as well.', ""If you are using sh or dash instead of ksh93, bash or zsh, you need to write IFS=$'\\n' like this instead:"", ""That is probably enough to get your script working, but if you're interested to handle some other corner cases properly, read on..."", '2. Expanding $file without wildcards', 'Inside the loop where you do', 'the shell tries to expand $file (again!).', ""It could contain spaces, but since we already set IFS above, that won't be a problem here."", 'But it could also contain wildcard characters such as * or ?, which would lead to unpredictable behavior.  (Thanks to Gilles for pointing this out.)', 'To tell the shell not to expand wildcard characters, put the variable inside double quotes, e.g.', 'The same problem could also bite us in', 'For example, if you had these three files', '(very unlikely, but still possible)', 'It would be as if you had run', 'which will get expanded to', 'causing file1.csv and file2.csv to be processed twice.', 'Instead, we have to do', 'read reads lines from standard input, splits the line into words according to IFS and stores them in the variable names that you specify.', ""Here, we're telling it not to split the line into words, and to store the line in $file."", 'Also note that read line has changed to read line </dev/tty.', 'This is because inside the loop, standard input is coming from find via the pipeline.', 'If we just did read, it would be consuming part or all of a file name, and some files would be skipped.', '/dev/tty is the terminal where the user is running the script from.  Note that this will cause an error if the script is run via cron, but I assume this is not important in this case.', 'Then, what if a file name contains newlines?', ""We can handle that by changing -print to -print0 and using read -d '' on the end of a pipeline:"", 'This makes find put a null byte at the end of each file name.  Null bytes are the only characters not allowed in file names, so this should handle all possible file names, no matter how weird.', ""To get the file name on the other side, we use IFS= read -r -d ''."", ""Where we used read above, we used the default line delimiter of newline, but now, find is using null as the line delimiter. In bash, you can't pass a NUL character in an argument to a command (even builtin ones), but bash understands -d '' as meaning NUL delimited. So we use -d '' to make read use the same line delimiter as find. Note that -d $'\\0', incidentally, works as well, because bash not supporting NUL bytes treats it as the empty string."", ""To be correct, we also add -r, which says don't handle backslashes in file names specially.  For example, without -r, \\<newline> are removed, and \\n is converted into n."", ""A more portable way of writing this that doesn't require bash or zsh or remembering all the above rules about null bytes (again, thanks to Gilles):"", '*3. Skipping directories whose names end in .csv', 'will also match directories that are called something.csv.', 'To avoid this, add -type f to the find command.', 'As glenn jackman points out, in both of these examples, the commands to execute for each file are being run in a subshell, so if you change any variables inside the loop, they will be forgotten.', 'If you need to set variables and have them still set at the end of the loop, you can rewrite it to use process substitution like this:', 'Note that if you try copying and pasting this at the command line, read line will consume the echo ""$i files processed"", so that command won\'t get run.', 'To avoid this, you could remove read line </dev/tty and send the result to a pager like less.', 'NOTES', 'I removed the semi-colons (;) inside the loop.  You can put them back if you want, but they are not needed.', ""These days, $(command) is more common than `command`.  This is mainly because it's easier to write $(command1 $(command2)) than `command1 \\`command2\\``."", ""read char doesn't really read a character.  It reads a whole line so I changed it to read line.""]","[<code>OIFS=""$IFS""
IFS=$'\n'
for file in `find . -type f -name ""*.csv""`  
do
     echo ""file = $file""
     diff ""$file"" ""/some/other/path/$file""
     read line
done
IFS=""$OIFS""
</code>, <code>find . -type f -name ""*.csv"" -print0 | while IFS= read -r -d '' file; do
    echo ""file = $file""
    diff ""$file"" ""/some/other/path/$file""
    read line &lt;/dev/tty
done
</code>, <code>find . -type f -name '*.csv' -exec sh -c '
  file=""$0""
  echo ""$file""
  diff ""$file"" ""/some/other/path/$file""
  read line &lt;/dev/tty
' exec-sh {} ';'
</code>, <code>sh</code>, <code>find . -type f -name '*.csv' -exec sh -c '
  for file do
    echo ""$file""
    diff ""$file"" ""/some/other/path/$file""
    read line &lt;/dev/tty
  done
' exec-sh {} +
</code>, <code>*.csv</code>, <code>file</code>, <code>find</code>, <code>file</code>, <code>find</code>, <code>IFS</code>, <code>&lt;space&gt;&lt;tab&gt;&lt;newline&gt;</code>, <code>find</code>, <code>IFS</code>, <code>file</code>, <code>for file in ""zquery"" ""-"" ""abc"" ...
</code>, <code>IFS=$'\n'
</code>, <code>for ... find</code>, <code>IFS</code>, <code>sh</code>, <code>dash</code>, <code>ksh93</code>, <code>bash</code>, <code>zsh</code>, <code>IFS=$'\n'</code>, <code>IFS='
'
</code>, <code>$file</code>, <code>diff $file /some/other/path/$file
</code>, <code>$file</code>, <code>IFS</code>, <code>*</code>, <code>?</code>, <code>diff ""$file"" ""/some/other/path/$file""
</code>, <code>for file in `find . -name ""*.csv""`
</code>, <code>file1.csv
file2.csv
*.csv
</code>, <code>for file in file1.csv file2.csv *.csv
</code>, <code>for file in file1.csv file2.csv *.csv file1.csv file2.csv
</code>, <code>file1.csv</code>, <code>file2.csv</code>, <code>find . -name ""*.csv"" -print | while IFS= read -r file; do
    echo ""file = $file""
    diff ""$file"" ""/some/other/path/$file""
    read line &lt;/dev/tty
done
</code>, <code>read</code>, <code>IFS</code>, <code>$file</code>, <code>read line</code>, <code>read line &lt;/dev/tty</code>, <code>find</code>, <code>read</code>, <code>/dev/tty</code>, <code>-print</code>, <code>-print0</code>, <code>read -d ''</code>, <code>find . -name ""*.csv"" -print0 | while IFS= read -r -d '' file; do
    echo ""file = $file""
    diff ""$file"" ""/some/other/path/$file""
    read char &lt;/dev/tty
done
</code>, <code>find</code>, <code>IFS= read -r -d ''</code>, <code>read</code>, <code>find</code>, <code>bash</code>, <code>bash</code>, <code>-d ''</code>, <code>-d ''</code>, <code>read</code>, <code>find</code>, <code>-d $'\0'</code>, <code>bash</code>, <code>-r</code>, <code>-r</code>, <code>\&lt;newline&gt;</code>, <code>\n</code>, <code>n</code>, <code>bash</code>, <code>zsh</code>, <code>find . -name '*.csv' -exec sh -c '
  file=""$0""
  echo ""$file""
  diff ""$file"" ""/some/other/path/$file""
  read char &lt;/dev/tty
' exec-sh {} ';'
</code>, <code>find . -name ""*.csv""
</code>, <code>something.csv</code>, <code>-type f</code>, <code>find</code>, <code>find . -type f -name '*.csv' -exec sh -c '
  file=""$0""
  echo ""$file""
  diff ""$file"" ""/some/other/path/$file""
  read line &lt;/dev/tty
' exec-sh {} ';'
</code>, <code>i=0
while IFS= read -r -d '' file; do
    echo ""file = $file""
    diff ""$file"" ""/some/other/path/$file""
    read line &lt;/dev/tty
    i=$((i+1))
done &lt; &lt;(find . -type f -name '*.csv' -print0)
echo ""$i files processed""
</code>, <code>read line</code>, <code>echo ""$i files processed""</code>, <code>read line &lt;/dev/tty</code>, <code>less</code>, <code>;</code>, <code>$(command)</code>, <code>`command`</code>, <code>$(command1 $(command2))</code>, <code>`command1 \`command2\``</code>, <code>read char</code>, <code>read line</code>]"
35,https://unix.stackexchange.com/questions/2107/,How to suspend and resume processes,"['You can use kill to stop the process.', ""For a 'polite' stop to the process (prefer this for normal use), send SIGTSTP:"", ""For a 'hard' stop, send SIGSTOP:"", ""Note that if the process you are trying to stop by PID is in your shell's job table, it may remain visible there, but terminated, until the process is fg'd again."", 'To resume execution of the process, sent SIGCONT:']","[<code>kill</code>, <code>kill -TSTP [pid]
</code>, <code>kill -STOP [pid]
</code>, <code>fg</code>, <code>kill -CONT [pid]
</code>]"
36,https://unix.stackexchange.com/questions/129391/,Passing named arguments to shell scripts,"[""If you don't mind being limited to single-letter argument names i.e. my_script -p '/some/path' -a5, then in bash you could use the built-in getopts, e.g."", 'Then you can do', 'There is a helpful Small getopts tutorial or you can type help getopts at the shell prompt.']","[<code>my_script -p '/some/path' -a5</code>, <code>getopts</code>, <code>#!/bin/bash

while getopts "":a:p:"" opt; do
  case $opt in
    a) arg_1=""$OPTARG""
    ;;
    p) p_out=""$OPTARG""
    ;;
    \?) echo ""Invalid option -$OPTARG"" &gt;&amp;2
    ;;
  esac
done

printf ""Argument p_out is %s\n"" ""$p_out""
printf ""Argument arg_1 is %s\n"" ""$arg_1""
</code>, <code>$ ./my_script -p '/some/path' -a5
Argument p_out is /some/path
Argument arg_1 is 5
</code>, <code>help getopts</code>]"
37,https://unix.stackexchange.com/questions/1136/,Batch renaming files,['If you are using Bash or other POSIX-compatible shell:'],"[<code>for f in *.png; do
    mv -- ""$f"" ""${f#image}""
done
</code>]"
38,https://unix.stackexchange.com/questions/45676/,How do I remove a directory and all its contents?,['The following command will do it for you. Use caution though.'],"[<code>rm -rf directoryname
</code>]"
39,https://unix.stackexchange.com/questions/125385/,Combined `mkdir` and `cd`?,"['Function?', 'Put the above code in the ~/.bashrc or another file sourced by the ~/.bashrc. Then restart the terminal for changes to apply.', 'After that simply run mkcdir foo or mkcdir ""nested/path/in quotes"".', 'Notes:']","[<code>mkcdir ()
{
    mkdir -p -- ""$1"" &amp;&amp;
      cd -P -- ""$1""
}
</code>, <code>~/.bashrc</code>, <code>~/.bashrc</code>, <code>mkcdir foo</code>, <code>mkcdir ""nested/path/in quotes""</code>, <code>""$1""</code>, <code>mkcdir</code>, <code>--</code>, <code>mkdir</code>, <code>cd</code>, <code>-</code>, <code>--</code>, <code>-p</code>, <code>mkdir</code>, <code>-P</code>, <code>cd</code>]"
40,https://unix.stackexchange.com/questions/94331/,How can I delete a word backward at the command line (bash and zsh)?,"['Ctrl+W is the standard ""kill word"" (aka werase).\nCtrl+U kills the whole line (kill).', 'You can change them with stty.', 'Note that one does not have to put the actual control character on the line, stty understands putting ^ and then the character you would hit with control.', 'After doing this, if I hit Ctrl+P it will erase a word from the line.  And if I hit Ctrl+A, it will erase the whole line.']","[<code>werase</code>, <code>kill</code>, <code>stty</code>, <code>-bash-4.2$ stty -a
speed 38400 baud; 24 rows; 80 columns;
lflags: icanon isig iexten echo echoe -echok echoke -echonl echoctl
        -echoprt -altwerase -noflsh -tostop -flusho pendin -nokerninfo
        -extproc -xcase
iflags: -istrip icrnl -inlcr -igncr -iuclc ixon -ixoff ixany imaxbel
        -ignbrk brkint -inpck -ignpar -parmrk
oflags: opost onlcr -ocrnl -onocr -onlret -olcuc oxtabs -onoeot
cflags: cread cs8 -parenb -parodd hupcl -clocal -cstopb -crtscts -mdmbuf
cchars: discard = ^O; dsusp = ^Y; eof = ^D; eol = &lt;undef&gt;;
        eol2 = &lt;undef&gt;; erase = ^?; intr = ^C; kill = ^U; lnext = ^V;
        min = 1; quit = ^\; reprint = ^R; start = ^Q; status = &lt;undef&gt;;
        stop = ^S; susp = ^Z; time = 0; werase = ^W;
-bash-4.2$ stty werase ^p
-bash-4.2$ stty kill ^a
-bash-4.2$
</code>, <code>stty</code>, <code>^</code>]"
41,https://unix.stackexchange.com/questions/80362/,What does <<< mean?,"[""Others have answered the basic question: what is it?\nLet's look at why it's useful."", ""You can also feed a string to a command's stdin like this:"", 'However in bash, introducing a pipe means the individual commands are run in subshells. Consider this:', 'The output of the 2nd echo command prints just a single space. Whaaaa? What happened to my variables? Because the read command is in a pipeline, it is run in a subshell. It correctly reads 2 words from its stdin and assigns to the variables. But then the command completes, the subshell exits and the variables are lost. ', 'Sometimes you can work around this with braces:', ""That's OK if your need for the values is contained, but you still don't have those variables in the current shell of your script.\nTo remedy this confusing situation, use a here-string"", 'Ah, much better!']","[<code>echo ""$string"" | command
</code>, <code>echo ""hello world"" | read first second
echo $second $first
</code>, <code>echo ""hello world"" | {
    read first second
    echo $second $first
}
</code>, <code>read first second &lt;&lt;&lt; ""hello world""
echo $second $first
</code>]"
42,https://unix.stackexchange.com/questions/118433/,Quoting within $(command substitution) in Bash,"['\nIn order from worst to best:', 'To improve even further:', 'You can nest command expansions as much as you like. With $() you always create a new quoting context, so you can do things like this:', 'You do not want to try that with backticks.']","[<code>DIRNAME=""$(dirname $FILE)""</code>, <code>$FILE</code>, <code>\[?*</code>, <code>DIRNAME=`dirname ""$FILE""`</code>, <code>DIRNAME=$(dirname ""$FILE"")</code>, <code>export DIRNAME=$(dirname ""$FILE"")</code>, <code>du $(dirname ""$FILE"")</code>, <code>DIRNAME=""$(dirname ""$FILE"")""</code>, <code>DIRNAME=</code>, <code>dirname</code>, <code>DIRNAME=""$(dirname -- ""$FILE"")""</code>, <code>$FILE</code>, <code>DIRNAME=""$(dirname -- ""$FILE""; printf x)"" &amp;&amp; DIRNAME=""${DIRNAME%?x}""</code>, <code>$FILE</code>, <code>$()</code>, <code>dirname</code>, <code>dirname</code>, <code>$()</code>, <code>foo ""$(bar ""$(baz ""$(ban ""bla"")"")"")""
</code>]"
43,https://unix.stackexchange.com/questions/74520/,Can I redirect output to a log file and background a process at the same time?,"['One problem with your first command is that you redirect stderr to where stdout is (if you changed the $ to a & as suggested in the comment) and then, you redirected stdout to some log file, but that does not pull along the redirected stderr. You must do it in the other order, first send stdout to where you want it to go, and then send stderr to the address stdout is at', 'and then you could throw the & on to send it to the background. Jobs can be accessed with the jobs command. jobs will show you the running jobs, and number them. You could then talk about the jobs using a % followed by the number like kill %1 or so.  ', 'Also, without the & on the end you can suspend the command with Ctrlz, use the bg command to put it in the background and fg to bring it back to the foreground.  In combination with the jobs command, this is powerful.', 'to clarify the above part about the order you write the commands. Suppose stderr is address 1002, stdout is address 1001, and the file is 1008. The command reads left to right, so the first thing it sees in yours is 2>&1 which moves stderr to the address 1001, it then sees > file which moves stdout to 1008, but keeps stderr at 1001. It does not pull everything pointing at 1001 and move it to 1008, but simply references stdout and moves it to the file.\nThe other way around, it moves stdout to 1008, and then moves stderr to the point that stdout is pointing to, 1008 as well. This way both can point to the single file.']","[<code>some_cmd &gt; some_file 2&gt;&amp;1 &amp;
</code>, <code>jobs</code>, <code>jobs</code>, <code>kill %1</code>, <code>bg</code>, <code>fg</code>, <code>jobs</code>, <code>2&gt;&amp;1</code>, <code>&gt; file</code>]"
44,https://unix.stackexchange.com/questions/104881/,remove particular characters from a variable using bash,"[""There is no need to execute an external program. bash's string manipulation can handle it (also available in ksh93 (where it comes from), zsh and recent versions of mksh, yash and busybox sh (at least)):"", ""(In those shells' manuals you can generally find this in the parameter expansion section.)""]","[<code>bash</code>, <code>ksh93</code>, <code>zsh</code>, <code>mksh</code>, <code>yash</code>, <code>sh</code>, <code>$ VERSION='2.3.3'
$ echo ""${VERSION//.}""
233
</code>]"
45,https://unix.stackexchange.com/questions/45201/,"Bash: What does "">|"" do?","[""It's not useless - it's a specialised form of the plain > redirect operator (and, perhaps confusingly, nothing to do with pipes). bash and most other modern shells have an option noclobber, which prevents redirection from overwriting or destroying a file that already exists. For example, if noclobber is true, and the file /tmp/output.txt already exists, then this should fail:"", 'However, you can explicitly override the setting of noclobber with the >| redirection operator - the redirection will work, even if noclobber is set.', 'You can find out if noclobber is set in your current environment with set -o.', 'For the historical note, both the ""noclobber"" option and its bypass features come from csh (late 70s). ksh copied it (early 80s) but used >| instead of >!. POSIX specified the ksh syntax (so all POSIX shells including bash, newer ash derivatives used as sh on some systems support it). Zsh supports both syntaxes. I don\'t think it was added to any Bourne shell variant but I might be wrong.']","[<code>&gt;</code>, <code>bash</code>, <code>noclobber</code>, <code>noclobber</code>, <code>/tmp/output.txt</code>, <code>$ some-command &gt; /tmp/output.txt
</code>, <code>noclobber</code>, <code>&gt;|</code>, <code>noclobber</code>, <code>noclobber</code>, <code>set -o</code>, <code>csh</code>, <code>ksh</code>, <code>&gt;|</code>, <code>&gt;!</code>, <code>ksh</code>]"
46,https://unix.stackexchange.com/questions/88850/,"Precedence of the shell logical operators &&, ||","['In many computer languages, operators with the same precedence are left-associative. That is, in the absence of grouping structures, leftmost operations are executed first. Bash is no exception to this rule.', 'This is important because, in Bash, && and || have the same precedence.', 'So what happens in your example is that the leftmost operation (||) is carried out first:', 'Since true is obviously true, the || operator short-circuits and the whole statement is considered true without the need to evaluate echo aaa as you would expect. Now it remains to do the rightmost operation:', ""Since the first operation evaluated to true (i.e. had a 0 exit status), it's as if you're executing"", 'so the && will not short-circuit, which is why you see bbb echoed.', 'You would get the same behavior with', 'Notes based on the comments', 'It seems that in C and C-like languages && has higher precedence than || which is probably why you expected your original construct to behave like ', ""This is not the case with Bash, however, in which both operators have the same precedence, which is why Bash parses your expression using the left-associativity rule. Thanks to Kevin's comment for bringing this up."", ""There might also be cases where all 3 expressions are evaluated. If the first command returns a non-zero exit status, the || won't short circuit and goes on to execute the second command. If the second command returns with a zero exit status, then the && won't short-circuit as well and the third command will be executed. Thanks to Ignacio Vazquez-Abrams' comment for bringing this up.""]","[<code>&amp;&amp;</code>, <code>||</code>, <code>||</code>, <code>true || echo aaa
</code>, <code>true</code>, <code>||</code>, <code>echo aaa</code>, <code>(...) &amp;&amp; echo bbb
</code>, <code>true &amp;&amp; echo bbb
</code>, <code>&amp;&amp;</code>, <code>bbb</code>, <code>false &amp;&amp; echo aaa || echo bbb
</code>, <code>[[...]]</code>, <code>((...))</code>, <code>-o</code>, <code>-a</code>, <code>test</code>, <code>[</code>, <code>&amp;&amp;</code>, <code>-a</code>, <code>||</code>, <code>-o</code>, <code>&amp;&amp;</code>, <code>||</code>, <code>true || (echo aaa &amp;&amp; echo bbb). 
</code>, <code>||</code>, <code>&amp;&amp;</code>]"
47,https://unix.stackexchange.com/questions/124407/,What color codes can I use in my PS1 prompt?,"['Those are ANSI escape sequences; that link is to a chart of color codes but there are other interesting things on that Wikipedia page as well.  Not all of them work on (e.g.) a normal Linux console.', 'This is incorrect:', '\\033]00m\\]   # white', '0 resets the terminal to its default (which is probably white).  The actual code for white foreground is 37.  Also, the escaped closing brace at the end (\\]) is not part of the color sequence (see the last few paragraphs below for an explanation of their purpose in setting a prompt).', 'Note that some GUI terminals allow you to specify a customized color scheme. This will affect the output.', ""There's a list here which adds 7 foreground and 7 background colors I had not seen before, but they seem to work:"", 'In addition, if you have a 256 color GUI terminal (I think most of them are now), you can apply colors from this chart: ', '', 'The ANSI sequence to select these, using the number in the bottom left corner, starts 38;5; for the foreground and 48;5; for the background, then the color number, so e.g.:', 'Gives me a light orange on tan (meaning, the color chart is roughly approximated).', 'You can see the colors in this chart1 as they would appear on your terminal fairly easily:', 'The output is self-explanatory.  ', 'Some systems set the $TERM variable to xterm-256color if you are on a 256 color terminal via some shell code in /etc/profile.  On others, you should be able to configure your terminal to use this.  That will let TUI applications know there are 256 colors, and allow you to add something like this to your ~/.bashrc:', 'Beware that when you use color escape sequences in your prompt, you should enclose them in escaped (\\ prefixed) square brackets, like this:', ""Notice the ['s interior to the color sequence are not escaped, but the enclosing ones are.  The purpose of the latter is to indicate to the shell that the enclosed sequence does not count toward the character length of the prompt.  If that count is wrong, weird things will happen when you scroll back through the history, e.g., if it is too long, the excess length of the last scrolled string will appear attached to your prompt and you won't be able to backspace into it (it's ignored the same way the prompt is)."", 'Also note that if you want to include the output of a command run every time the prompt is used (as opposed to just once when the prompt is set), you should set it as a literal string with single quotes, e.g.:', ""Although this is not a great example if you are happy with using bash's special \\d or \\D{format} prompt escapes -- which are not the topic of the question but can be found in man bash under PROMPTING.  There are various other useful escapes such as \\w for current directory, \\u for current user, etc."", '1. The main portion of this chart, colors 16 - 231 (notice they are not in numerical order) are a 6 x 6 x 6 RGB color cube. ""Color cube"" refers to the fact that an RGB color space can be represented using a three dimensional array (with one axis for red, one for green, and one for blue).  Each color in the cube here can be represented as coordinates in a 6 x 6 x 6 array, and the index in the chart calculated thusly:', 'The first color in the cube, at index 16 in the chart, is black (RGB 0, 0, 0).  You could use this formula in shell script:']","[<code>\033]00m\]   # white</code>, <code>0</code>, <code>\]</code>, <code># Foreground colors
90   Dark gray  
91   Light red  
92   Light green    
93   Light yellow   
94   Light blue 
95   Light magenta  
96   Light cyan  

# Background colors
100  Dark gray  
101  Light red  
102  Light green    
103  Light yellow   
104  Light blue 
105  Light magenta  
106  Light cyan 
</code>, <code>38;5;</code>, <code>48;5;</code>, <code>echo -e ""\\033[48;5;95;38;5;214mhello world\\033[0m""
</code>, <code>#!/bin/bash

color=16;

while [ $color -lt 245 ]; do
    echo -e ""$color: \\033[38;5;${color}mhello\\033[48;5;${color}mworld\\033[0m""
    ((color++));
done  
</code>, <code>xterm-256color</code>, <code>/etc/profile</code>, <code>~/.bashrc</code>, <code>if [[ ""$TERM"" =~ 256color ]]; then
     PS1=""MyCrazyPrompt...""
fi
</code>, <code>\</code>, <code>PS1=""\[\033[01;32m\]MyPrompt: \[\033[0m\]""
</code>, <code>[</code>, <code>PS1='\[\033[01;32m\]$(date): \[\033[0m\]'
</code>, <code>\d</code>, <code>\D{format}</code>, <code>man bash</code>, <code>PROMPTING</code>, <code>\w</code>, <code>\u</code>, <code>    16 + R * 36 + G * 6 + B
</code>, <code>#!/bin/sh                                                         

function RGBcolor {                                               
    echo ""16 + $1 * 36 + $2 * 6 + $3"" | bc                        
}                                                                 

fg=$(RGBcolor 1 0 2)  # Violet                                            
bg=$(RGBcolor 5 3 0)  # Bright orange.                                            

echo -e ""\\033[1;38;5;$fg;48;5;${bg}mviolet on tangerine\\033[0m""
</code>]"
48,https://unix.stackexchange.com/questions/42847/,Are there naming conventions for variables in shell scripts?,"['Environment variables or shell variables that are introduced by the operating system, shell startup scripts, or by the shell itself etc. are usually all in CAPITALS.', 'To prevent your own variables from conflicting with these variables, it is a good practice to use lower_case variable names.']","[<code>CAPITALS</code>, <code>lower_case</code>]"
49,https://unix.stackexchange.com/questions/51983/,How to uppercase the command line argument?,"['The syntax str^^ which you are trying is available from Bash 4.0 and above. Perhaps yours is an older version (or you ran the script with sh explicitly):', 'Try this:']","[<code>str^^</code>, <code>sh</code>, <code>str=""Some string""
printf '%s\n' ""$str"" | awk '{ print toupper($0) }'
</code>]"
50,https://unix.stackexchange.com/questions/10922/,Temporarily suspend bash_history on a given shell?,"[""This should be what you're looking for:"", 'If HISTFILE is unset, or if the history file is unwritable, the history is not saved.', 'Alternatively, if you want to toggle it off and then back on again, it may be easier to use set:']","[<code>unset HISTFILE
</code>, <code>man bash</code>, <code>set</code>, <code>set +o history
</code>, <code>set -o history
</code>]"
51,https://unix.stackexchange.com/questions/49053/,How do I add X days to date and get new date?,"['You can just use the -d switch and provide a date to be calculated', 'This is quite a powerful tool as you can do things like ', 'or', 'or', 'So if $end_date=20131001 then $prog_end_date=20131011']","[<code>-d</code>, <code>date
Sun Sep 23 08:19:56 BST 2012
NEW_expration_DATE=$(date -d ""+10 days"")
echo $NEW_expration_DATE
Wed Oct 3 08:12:33 BST 2012 
</code>, <code>  -d, --date=STRING
          display time described by STRING, not ‘now’
</code>, <code>date -d ""Sun Sep 11 07:59:16 IST 2012+10 days""
Fri Sep 21 03:29:16 BST 2012
</code>, <code>TZ=IST date -d ""Sun Sep 11 07:59:16 IST 2012+10 days""
Fri Sep 21 07:59:16 IST 2012
</code>, <code>prog_end_date=`date '+%C%y%m%d' -d ""$end_date+10 days""`
</code>]"
52,https://unix.stackexchange.com/questions/68694/,When is double-quoting necessary?,"[""First, separate zsh from the rest. It's not a matter of old vs modern shells: zsh behaves differently. The zsh designers decided to make it incompatible with traditional shells (Bourne, ksh, bash), but easier to use."", ""Second, it is far easier to use double quotes all the time than to remember when they are needed. They are needed most of the time, so you'll need to learn when they aren't needed, not when they are needed."", 'In a nutshell, double quotes are necessary wherever a list of words or a pattern is expected. They are optional in contexts where a raw string is expected by the parser.', 'Note that without double quotes, two things happen.', 'An unquoted variable expansion $foo is colloquially known as the “split+glob operator”, in contrast with ""$foo"" which just takes the value of the variable foo. The same goes for command substitution: ""$(foo)"" is a command substitution, $(foo) is a command substitution followed by split+glob.', 'Here are all the cases I can think of in a Bourne-style shell where you can write a variable or command substitution without double quotes, and the value is interpreted literally.', 'On the right-hand side of an assignment.', ""Note that you do need the double quotes after export, because it's an ordinary builtin, not a keyword. This is only true in some shells such as dash, zsh (in sh emulation), yash or posh; bash and ksh both treat export specially."", 'In a case statement.', ""Note that you do need double quotes in a case pattern. Word splitting doesn't happen in a case pattern, but an unquoted variable is interpreted as a pattern whereas a quoted variable is interpreted as a literal string."", 'Within double brackets. Double brackets are shell special syntax.', 'Except that you do need double quotes where a pattern or regular expression is expected: on the right-hand side of = or == or != or =~.', ""You do need double quotes as usual within single brackets [ …\xa0] because they are ordinary shell syntax (it's a command that happens to be called [). See Single or double brackets"", 'In a redirection in non-interactive POSIX shells (not bash, nor ksh88).', ""Some shells, when interactive, do treat the value of the variable as a wildcard pattern. POSIX prohibits that behaviour in non-interactive shells, but a few shells including bash (except in POSIX mode) and ksh88  (including when found as the (supposedly) POSIX sh of some commercial Unices like Solaris) still do it there (bash does also attempt splitting and the redirection fails unless that split+globbing results in exactly one word), which is why it's better to quote targets of redirections in a sh script in case you want to convert it to a bash script some day, or run it on a system where sh is non-compliant on that point, or it may be sourced from interactive shells."", 'Inside an arithmetic expression. In fact, you need to leave the quotes out in order for a variable to be parsed as an arithmetic expression.', 'However, you do need the quotes around the arithmetic expansion as they are subject to word splitting in most shells as POSIX requires (!?).', 'In an associative array subscript.', 'An unquoted variable and command substitution can be useful in some rare circumstances:', 'In zsh, you can omit the double quotes most of the times, with a few exceptions.', '$var never expands to multiple words, however it expands to the empty list (as opposed to a list containing a single, empty word) if the value of var is the empty string. Contrast:', 'Similarly, ""${array[@]}"" expands to all the elements of the array, while $array only expands to the non-empty elements.', 'The @ parameter expansion flag sometimes requires double quotes around the whole substitution: ""${(@)foo}"".', 'Command substitution undergoes field splitting if unquoted: echo $(echo \'a\'; echo \'*\') prints a * (with a single space) whereas echo ""$(echo \'a\'; echo \'*\')"" prints the unmodified two-line string. Use ""$(somecommand)"" to get the output of the command in a single word, sans final newlines. Use ""${$(somecommand; echo _)%?}"" to get the exact output of the command including final newlines. Use ""${(@f)$(somecommand)}"" to get an array of lines from the command\'s output.']","[<code>${foo}</code>, <code>$(foo)</code>, <code>IFS</code>, <code>IFS="" :""</code>, <code>:one::two : three: :four </code>, <code>one</code>, <code>one</code>, <code>two</code>, <code>three</code>, <code>four</code>, <code>\[*?</code>, <code>$foo</code>, <code>""$foo""</code>, <code>foo</code>, <code>""$(foo)""</code>, <code>$(foo)</code>, <code>var=$stuff
a_single_star=*
</code>, <code>export</code>, <code>export</code>, <code>export VAR=""$stuff""
</code>, <code>case</code>, <code>case $var in …
</code>, <code>a_star='a*'
case $var in
  ""$a_star"") echo ""'$var' is the two characters a, *"";;
   $a_star) echo ""'$var' begins with a"";;
esac
</code>, <code>[[ -e $filename ]]
</code>, <code>=</code>, <code>==</code>, <code>!=</code>, <code>=~</code>, <code>a_star='a*'
if [[ $var == ""$a_star"" ]]; then echo ""'$var' is the two characters a, *""
elif [[ $var == $a_star ]]; then echo ""'$var' begins with a""
fi
</code>, <code>[ … ]</code>, <code>[</code>, <code>bash</code>, <code>ksh88</code>, <code>echo ""hello world"" &gt;$filename
</code>, <code>sh</code>, <code>bash</code>, <code>sh</code>, <code>bash</code>, <code>sh</code>, <code>expr=2*2
echo ""$(($expr))""
</code>, <code>typeset -A a
i='foo bar*qux'
a[foo\ bar\*qux]=hello
echo ""${a[$i]}""
</code>, <code>$IFS</code>, <code>set -f</code>, <code>IFS</code>, <code>$var</code>, <code>var</code>, <code>var=
print -l $var foo        # prints just foo
print -l ""$var"" foo      # prints an empty line, then foo
</code>, <code>""${array[@]}""</code>, <code>$array</code>, <code>@</code>, <code>""${(@)foo}""</code>, <code>echo $(echo 'a'; echo '*')</code>, <code>a *</code>, <code>echo ""$(echo 'a'; echo '*')""</code>, <code>""$(somecommand)""</code>, <code>""${$(somecommand; echo _)%?}""</code>, <code>""${(@f)$(somecommand)}""</code>]"
53,https://unix.stackexchange.com/questions/87405/,How can I execute local script on remote machine and include arguments?,"['You were pretty close with your example. It works just fine when you use it with arguments such as these.', 'Sample script:', 'Example that works:', 'But it fails for these types of arguments:', ""The problem you're encountering is that the argument, -time, or --time in my example, is being interpreted as a switch to bash -s. You can pacify bash by terminating it from taking any of the remaining command line arguments for itself using the -- argument."", 'Like this:', '#1:', '#2:', '#3:', '#4:', ""NOTE: Just to make it clear that wherever the redirection appears on the command line makes no difference, because ssh calls a remote shell with the concatenation of its arguments anyway, quoting doesn't make much difference, except when you need quoting on the remote shell like in example #4:""]","[<code>$ more ex.bash 
#!/bin/bash

echo $1 $2
</code>, <code>$ ssh serverA ""bash -s"" &lt; ./ex.bash ""hi"" ""bye""
hi bye
</code>, <code>$ ssh serverA ""bash -s"" &lt; ./ex.bash ""--time"" ""bye""
bash: --: invalid option
...
</code>, <code>-time</code>, <code>--time</code>, <code>bash -s</code>, <code>bash</code>, <code>--</code>, <code>$ ssh root@remoteServer ""bash -s"" -- &lt; /var/www/html/ops1/sysMole -time Aug 18 18
</code>, <code>$ ssh serverA ""bash -s"" -- &lt; ./ex.bash ""-time"" ""bye""
-time bye
</code>, <code>$ ssh serverA ""bash -s"" -- &lt; ./ex.bash ""--time"" ""bye""
--time bye
</code>, <code>$ ssh serverA ""bash -s"" -- &lt; ./ex.bash --time ""bye""
--time bye
</code>, <code>$ ssh  &lt; ./ex.bash serverA ""bash -s -- --time bye""
--time bye
</code>, <code>ssh</code>, <code>$ ssh  &lt; ./ex.bash serverA ""bash -s -- '&lt;--time bye&gt;' '&lt;end&gt;'""
&lt;--time bye&gt; &lt;end&gt;
</code>]"
54,https://unix.stackexchange.com/questions/76049/,"What is the difference between ""sort -u"" and ""sort | uniq""?","[""sort | uniq existed before sort -u, and is compatible with a wider range of systems, although almost all modern systems do support -u -- it's POSIX. It's mostly a throwback to the days when sort -u didn't exist (and people don't tend to change their methods if the way that they know continues to work, just look at ifconfig vs. ip adoption)."", ""The two were likely merged because removing duplicates within a file requires sorting (at least, in the standard case), and is an extremely common use case of sort. It is also faster internally as a result of being able to do both operations at the same time (and due to the fact that it doesn't require IPC between uniq and sort). Especially if the file is big, sort -u will likely use fewer intermediate files to sort the data."", 'On my system I consistently get results like this:', ""It also doesn't mask the return code of sort, which may be important (in modern shells there are ways to get this, for example, bash's $PIPESTATUS array, but this wasn't always true).""]","[<code>sort | uniq</code>, <code>sort -u</code>, <code>-u</code>, <code>sort -u</code>, <code>ifconfig</code>, <code>ip</code>, <code>uniq</code>, <code>sort</code>, <code>sort -u</code>, <code>$ dd if=/dev/urandom of=/dev/shm/file bs=1M count=100
100+0 records in
100+0 records out
104857600 bytes (105 MB) copied, 8.95208 s, 11.7 MB/s
$ time sort -u /dev/shm/file &gt;/dev/null

real        0m0.500s
user        0m0.767s
sys         0m0.167s
$ time sort /dev/shm/file | uniq &gt;/dev/null

real        0m0.772s
user        0m1.137s
sys         0m0.273s
</code>, <code>sort</code>, <code>bash</code>, <code>$PIPESTATUS</code>]"
55,https://unix.stackexchange.com/questions/126927/,Have backticks (i.e. `cmd`) in *sh shells been deprecated?,"['There are two different meanings of ""deprecated.""', 'be deprecated: (chiefly of a software feature) be usable but regarded as obsolete and best avoided, typically due to having been superseded.', '—New Oxford American Dictionary', 'By this definition backticks are deprecated.', 'Deprecated status may also indicate the feature will be removed in the future.', '—Wikipedia', 'By this definition backticks are not deprecated.', 'Citing the Open Group Specification on Shell Command Languages,\nspecifically section ""2.6.3 Command Substitution,"" it can be seen that both forms of command substitution, backticks (`..cmd..`) or dollar parens ($(..cmd..)) are still supported insofar as the specification goes.', 'excerpt', 'Command substitution allows the output of a command to be substituted in place\n  of the command name itself. Command substitution shall occur when the command\n  is enclosed as follows:', 'The shell shall expand the command substitution by executing command in a\n  subshell environment (see Shell Execution Environment) and replacing the\n  command substitution (the text of command plus the enclosing $() or\n  backquotes) with the standard output of the command, removing sequences of one\n  or more <newline> characters at the end of the substitution. Embedded <newline> characters before the end of the output shall not be removed; however, \n  they may be treated as field delimiters and eliminated during field splitting, \n  depending on the value of IFS and quoting that is in effect. If the output \n  contains any null bytes, the behavior is unspecified.', 'Within the backquoted style of command substitution, <backslash> shall retain\n  its literal meaning, except when followed by: \'$\', \'\\`\', or <backslash>. The\n  search for the matching backquote shall be satisfied by the first unquoted\n  non-escaped backquote; during this search, if a non-escaped backquote is\n  encountered within a shell comment, a here-document, an embedded command\n  substitution of the $(command) form, or a quoted string, undefined results\n  occur. A single-quoted or double-quoted string that begins, but does not end,\n  within the ""`...`"" sequence produces undefined results.', 'With the $(command) form, all characters following the open parenthesis to\n  the matching closing parenthesis constitute the command. Any valid shell \n  script can be used for command, except a script consisting solely of\n  re-directions which produces unspecified results.', ""Because most of the use cases should be making use of the dollar parens form instead of backticks.  (Deprecated in the first sense above.)  Many of the most reputable sites (including U&L) often state this as well, throughout, so it's sound advice.  This advice should not be confused with some non-existent plan to remove support for backticks from shells."", 'BashFAQ #082 - Why is $(...) preferred over `...` (backticks)?', 'excerpt', '`...` is the legacy syntax required by only the very oldest of\n  non-POSIX-compatible bourne-shells. There are several reasons to always\n  prefer the $(...) syntax:', '...', 'Bash Hackers Wiki - Obsolete and deprecated syntax', 'excerpt', 'This is the older Bourne-compatible form of the command substitution.\n  Both the `COMMANDS` and $(COMMANDS) syntaxes are specified by POSIX, \n  but the latter is greatly preferred, though the former is unfortunately \n  still very prevalent in scripts. New-style command substitutions are widely \n  implemented by every modern shell (and then some). The only reason for using \n  backticks is for compatibility with a real Bourne shell (like Heirloom). \n  Backtick command substitutions require special escaping when nested, and \n  examples found in the wild are improperly quoted more often than not. See: \n  Why is $(...) preferred over `...` (backticks)?.', 'POSIX standard rationale', 'excerpt', 'Because of these inconsistent behaviors, the backquoted variety of command substitution is not recommended for new applications that nest command substitutions or attempt to embed complex scripts.', ""NOTE: This third excerpt (above) goes on to show several situations where backticks simply won't work, but the newer dollar parens method does, beginning with the following paragraph:"", 'Additionally, the backquoted syntax has historical restrictions on the contents of the embedded command. While the newer ""$()"" form can process any kind of valid embedded script, the backquoted form cannot handle some valid scripts that include backquotes. ', 'If you continue reading that section the failures are highlighted showing how they would fail using backticks, but do work using the newer dollar parens notation.', 'So it\'s preferable that you use dollar parens instead of backticks but you aren\'t actually using something that\'s been technically ""deprecated"" as in ""this will stop working entirely at some planned point.""', ""After reading all this you should have the take away that you're strongly encouraged to use dollar parens unless you specifically require compatibility with a real original non-POSIX Bourne shell.""]","[<code>`..cmd..`</code>, <code>$(..cmd..)</code>, <code>          $(command)

          or (backquoted version):

          `command`
</code>, <code>$()</code>, <code>\`</code>, <code>$(command)</code>, <code>`...`</code>, <code>$(command)</code>, <code>`...`</code>, <code>$(...)</code>, <code>`COMMANDS`</code>, <code>$(COMMANDS)</code>]"
56,https://unix.stackexchange.com/questions/101332/,Generate File of a certain size?,"['You can use dd:', 'or', 'or, on Mac,']","[<code>dd if=/dev/zero of=output.dat  bs=24M  count=1
</code>, <code>dd if=/dev/zero of=output.dat  bs=1M  count=24
</code>, <code>dd if=/dev/zero of=output.dat  bs=1m  count=24
</code>]"
57,https://unix.stackexchange.com/questions/275053/,Is there any way to execute commands from history?,"['In bash, just !636 will be ok.']",[<code>!636</code>]
58,https://unix.stackexchange.com/questions/48994/,How to run a program in a clean environment in bash?,"['You can do this with env:', 'Contrary to comments below, this does completely clear out the environment, but it does not prevent your_command setting new variables. In particular, running a shell will cause the /etc/profile to run, and the shell may have some built in settings also.', 'You can check this with:', 'i.e. wipe the environment and then print it. The output will be blank.']","[<code>env</code>, <code>env -i your_command
</code>, <code>your_command</code>, <code>/etc/profile</code>, <code>env -i env
</code>]"
59,https://unix.stackexchange.com/questions/52330/,How to redirect output to a file from within cron?,"['I solved the problem. There are two ways:', 'M1', 'Change the redirection from &>> to 2>&1. So now crontab -e looks like', 'I believe the above works because by default cron is using sh to run the task instead of bash so &>> is not supported by sh.', 'M2', 'Change the default shell by adding SHELL=/bin/bash in the crontab -e file.']","[<code>&amp;&gt;&gt;</code>, <code>2&gt;&amp;1</code>, <code>crontab -e</code>, <code>*/1 * * * * /home/ranveer/vimbackup.sh &gt;&gt; /home/ranveer/vimbackup.log 2&gt;&amp;1
</code>, <code>cron</code>, <code>sh</code>, <code>bash</code>, <code>&amp;&gt;&gt;</code>, <code>sh</code>, <code>SHELL=/bin/bash</code>, <code>crontab -e</code>]"
60,https://unix.stackexchange.com/questions/33339/,Can't use exclamation mark (!) in bash?,"['The exclamation mark is part of history expansion in bash.  To use it you need it enclosed in single quotes (eg: \'http://example.org/!132\') or to directly escape it with a backslash (\\) before the character (eg: ""http://example.org/\\!132"").', ""Note that in double quotes, a backslash before the exclam prevents history expansion, BUT the backslash is not removed in such a case.  So it's better to use single quotes, so you're not passing a literal backslash to curl as part of the URL.""]","[<code>'http://example.org/!132'</code>, <code>\</code>, <code>""http://example.org/\!132""</code>, <code>curl</code>]"
61,https://unix.stackexchange.com/questions/37790/,How do I delete the first n lines of an ascii file using shell commands?,"['As long as the file is not a symlink or hardlink, you can use sed, tail, or awk. Example below.', ""You can also use sed in-place without a temp file: sed -i -e 1,3d yourfile. This won't echo anything, it will just modify the file in-place. If you don't need to pipe the result to another command, this is easier.""]","[<code>$ cat t.txt
12
34
56
78
90
</code>, <code>$ sed -e '1,3d' &lt; t.txt
78
90
</code>, <code>sed -i -e 1,3d yourfile</code>, <code>$ tail -n +4 t.txt
78
90
</code>, <code>$ awk 'NR &gt; 3 { print }' &lt; t.txt
78
90
</code>]"
62,https://unix.stackexchange.com/questions/93029/,"how can I add (subtract, etc.) two numbers with bash?","['Arithmetic in POSIX shells is done with $ and double parentheses (( )):', 'You can assign from that (sans echo):', 'There is also expr:', 'In scripting $(()) is preferable since it avoids a fork/execute for the expr command.']","[<code>$</code>, <code>(( ))</code>, <code>echo ""$(($num1+$num2))""
</code>, <code>echo</code>, <code>num1=""$(($num1+$num2))""
</code>, <code>expr</code>, <code>expr $num1 + $num2
</code>, <code>$(())</code>, <code>expr</code>]"
63,https://unix.stackexchange.com/questions/86012/,What is the purpose of the hash command?,"['hash is a bash built-in command. The hash table is a feature of bash  that prevents it from having to search $PATH every time you type a command by caching the results in memory. The table gets cleared on events that obviously invalidate the results (such as modifying $PATH)', 'The hash command is just how you interact with that system (for whichever reason you feel you need to).', 'Some use cases:', 'Like you saw it prints out how many times you hit which commands if you type it with no arguments. This might tell you which commands you use most often.', 'You can also use it to remember executables in non-standard locations. ', 'Example:', 'Which might be useful if you just have a single executable in a directory outside of $PATH that you want to run by just type the name instead of including everything in that directory (which would be the effect if you added it to $PATH).', ""An alias can usually do this as well, though and since you're modifying the current shell's behavior, it isn't mapped in programs you kick off. A symlink to the lone executable is probably the preferable option here. hash is one way of doing it."", 'Example:', ""The cp command caused a new version of the ls executable to show up earlier in my $PATH but didn't trigger a purge of the hash table. I used hash -d to selectively purge the entry for ls from the hash table. Bash was then forced to look through $PATH again and when it did, it found it in the newer location (earlier in $PATH than it was running before)."", 'You can selectively invoke this ""find new location of executable from $PATH"" behavior, though:', ""You'd mostly just want to do this if you wanted something out of the hash table and weren't 100% that you could logout and then back in successfully, or you wanted to preserve some modifications you've made to your shell."", ""To get rid of stale mappings, you can also do hash -r (or export PATH=$PATH) which effectively just purges bash's entire hash table. "", 'There are lots of little situations like that. I don\'t know if I\'d call it one of the ""most useful"" commands but it does have some use cases. ']","[<code>hash</code>, <code>bash</code>, <code>$PATH</code>, <code>$PATH</code>, <code>hash</code>, <code>[root@policyServer ~]# hash -p /lol-wut/whoami whoami
[root@policyServer ~]# whoami
Not what you're thinking
[root@policyServer ~]# which whoami
/usr/bin/whoami
[root@policyServer ~]# /usr/bin/whoami
root
[root@policyServer ~]#
</code>, <code>$PATH</code>, <code>$PATH</code>, <code>hash</code>, <code>PATH</code>, <code>mv</code>, <code>[root@policyServer ~]# hash
hits    command
   1    /bin/ls
[root@policyServer ~]# cp /bin/ls /lol-wut
[root@policyServer ~]# hash
hits    command
   1    /bin/cp
   1    /bin/ls
[root@policyServer ~]# hash -d ls
[root@policyServer ~]# ls
default.ldif  newDIT.ldif  notes.txt  users.ldif
[root@policyServer ~]# hash
hits    command
   1    /bin/cp
   1    /lol-wut/ls
[root@policyServer ~]#
</code>, <code>cp</code>, <code>ls</code>, <code>$PATH</code>, <code>hash -d</code>, <code>ls</code>, <code>$PATH</code>, <code>$PATH</code>, <code>[root@policyServer ~]# hash
hits    command
   1    /bin/ls
[root@policyServer ~]# hash ls
[root@policyServer ~]# hash
hits    command
   0    /lol-wut/ls
[root@policyServer ~]#
</code>, <code>hash -r</code>, <code>export PATH=$PATH</code>]"
64,https://unix.stackexchange.com/questions/37069/,"What is the difference between ""&&"" and "";"" when chaining commands","['Assume there is command1 && command2.', 'In this case command2 will be executed if and only if command1 returned zero exit status.', '; is just a command separator. Thus command2 will be executed whatever command1 returned.']","[<code>command1 &amp;&amp; command2</code>, <code>command2</code>, <code>command1</code>, <code>;</code>, <code>command2</code>, <code>command1</code>, <code>$&gt; [[ ""a"" = ""b"" ]] &amp;&amp; echo ok 

$&gt; [[ ""a"" = ""b"" ]]; echo ok 
ok
</code>]"
65,https://unix.stackexchange.com/questions/3052/,"Is there a "".bashrc"" equivalent file read by all shells?","['The file $HOME/.profile is used by a number of shells, including bash, sh, dash, and possibly others.', 'From the bash man page:', 'When bash is invoked as an interactive login shell, ... it first reads and executes commands from the file /etc/profile, if that file exists.   After  reading that file, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile, in that order, and reads and executes commands from the first one that exists and is readable.', ""csh and tcsh explicitly don't look at ~/.profile but those shells are kinda antiquated.""]","[<code>$HOME/.profile</code>, <code>~/.profile</code>]"
66,https://unix.stackexchange.com/questions/157381/,"When was the shellshock (CVE-2014-6271/7169) bug introduced, and what is the patch that fully fixes it?","['The shellshock vulnerability is fully fixed in', 'If your bash shows an older version, your OS vendor may still have patched it by themselves, so best is to check.', 'If:', 'shows ""vulnerable"", you\'re still vulnerable. That is the only test that is relevant (whether the bash parser is still exposed to code in any environment variable).', 'The bug was in the initial implementation of the function exporting/importing introduced on the 5th of August 1989 by Brian Fox, and first released in bash-1.03 about a month later at a time where bash was not in such widespread use, before security was that much of a concern and HTTP and the web or Linux even existed.', 'From the ChangeLog in 1.05:', 'Some discussions in gnu.bash.bug and comp.unix.questions around that time also mention the feature.', ""It's easy to understand how it got there."", 'bash exports the functions in env vars like', 'And on import, all it has to do is interpret that with the = replaced with a space... except that it should not blindly interpret it.', ""It's also broken in that in bash (contrary to the Bourne shell), scalar variables and functions have a different name space. Actually if you have"", ""bash will happily put both in the environment (yes entries with same variable name) but many tools (including many shells) won't propagate them."", ""One would also argue that bash should use a BASH_ namespace prefix for that as that's env vars only relevant from bash to bash. rc uses a fn_ prefix for a similar feature."", 'A better way to implement it would have been to put the definition of all exported variables in a variable like:', 'That would still need to be sanitized but at least that could not be more exploitable than $BASH_ENV or $SHELLOPTS...', ""There is a patch that prevents bash from interpreting anything else than the function definition in there (https://lists.gnu.org/archive/html/bug-bash/2014-09/msg00081.html), and that's the one that has been applied in all the security updates from the various Linux distributions."", 'However, bash still interprets the code in there and any bug in the interpreter could be exploited. One such bug has already been found (CVE-2014-7169) though its impact is a lot smaller. So there will be another patch coming soon.', ""Until a hardening fix that prevents bash to interpret code in any variable (like using the BASH_FUNCDEFS approach above), we won't know for sure if we're not vulnerable from a bug in the bash parser. And I believe there will be such a hardening fix released sooner or later."", ""Two additional bugs in the parser have been found (CVE-2014-718{6,7}) (note that most shells are bound to have bugs in their parser for corner cases, that wouldn't have been a concern if that parser hadn't been exposed to untrusted data)."", ""While all 3 bugs 7169, 7186 and 7187 have been fixed in following patches, Red Hat pushed for the hardening fix. In their patch, they changed the behaviour so that functions were exported in variables called BASH_FUNC_myfunc() more or less preempting Chet's design decision."", 'Chet later published that fix as an official upstreams bash patch.', 'That hardening patch, or variants of it are now available for most major Linux distribution and eventually made it to Apple OS/X.', 'That now plugs the concern for any arbitrary env var exploiting the parser via that vector including two other vulnerabilities in the parser (CVE-2014-627{7,8}) that were disclosed later by Michał Zalewski (CVE-2014-6278 being almost as bad as CVE-2014-6271) thankfully after most people had had time to install the hardening patch', 'Bugs in the parser will be fixed as well, but they are no longer that much of an issue now that the parser is no longer so easily exposed to untrusted input.', ""Note that while the security vulnerability has been fixed, it's likely that we'll see some changes in that area. The initial fix for CVE-2014-6271 has broken backward compatibility in that it stops importing functions with . or : or / in their name. Those can still be declared by bash though which makes for an inconsistent behaviour. Because functions with . and : in their name are commonly used, it's likely a patch will restore accepting at least those from the environment."", ""That's also something I wondered about. I can offer a few explanations."", ""First, I think that if a security researcher (and I'm not a professional security researcher) had specifically been looking for vulnerabilities in bash, they would have likely found it."", 'For instance, if I were a security researcher, my approaches could be:', 'Now, I suspect nobody thought to consider bash (the interpreter) as a threat, or that the threat could have come that way.', 'The bash interpreter is not meant to process untrusted input.', ""Shell scripts (not the interpreter) are often looked at closely from a security point of view. The shell syntax is so awkward and there are so many caveats with writing reliable scripts (ever seen me or others mentioning the split+glob operator or why you should quote variables for instance?) that it's quite common to find security vulnerabilities in scripts that process untrusted data."", ""That's why you often hear that you shouldn't write CGI shell scripts, or setuid scripts are disabled on most Unices. Or that you should be extra careful when processing files in world-writeable directories (see CVE-2011-0441 for instance)."", 'The focus is on that, the shell scripts, not the interpreter.', ""You can expose a shell interpreter to untrusted data (feeding foreign data as shell code to interpret) via eval or . or calling it on user provided files, but then you don't need a vulnerability in bash to exploit it. It's quite obvious that if you're passing unsanitized data for a shell to interpret, it will interpret it."", ""So the shell is called in trusted contexts. It's given fixed scripts to interpret and more often than not (because it's so difficult to write reliable scripts) fixed data to process."", 'For instance, in a web context, a shell might be invoked in something like:', 'What can possibly go wrong with that? If something wrong is envisaged, that\'s about the data fed to that sendmail, not how that shell command line itself is parsed or what extra data is fed to that shell. There\'s no reason you\'d want to consider the environment variables that are passed to that shell. And if you do, you realise it\'s all env vars whose name start with ""HTTP_"" or are well known CGI env vars like SERVER_PROTOCOL or QUERYSTRING none of which the shell or sendmail have any business to do with.', 'In privilege elevation contexts like when running setuid/setgid or via sudo, the environment is generally considered and there have been plenty of vulnerabilities in the past, again not against the shell itself but against the things that elevate the privileges like sudo (see for instance CVE-2011-3628).', ""For instance, bash doesn't trust the environment when setuid or called by a setuid command (think mount for instance that invokes helpers). In particular, it ignores exported functions."", ""sudo does clean the environment: all by default except for a white list, and if configured not to, at least black lists a few that are known to affect a shell or another (like PS4, BASH_ENV, SHELLOPTS...). It does also blacklist the environment variables whose content starts with () (which is why CVE-2014-6271 doesn't allow privilege escalation via sudo)."", ""But again, that's for contexts where the environment cannot be trusted: any variable with any name and value can be set by a malicious user in that context. That doesn't apply to web servers/ssh or all the vectors that exploit CVE-2014-6271 where the environment is controlled (at least the name of the environment variables is controlled...)"", 'It\'s important to block a variable like echo=""() { evil; }"", but not HTTP_FOO=""() { evil; }"", because HTTP_FOO is not going to be called as a command by any shell script or command line. And apache2 is never going to set an echo or BASH_ENV variable.', ""It's quite obvious some environment variables should be black-listed in some contexts based on their name, but nobody thought that they should be black-listed based on their content (except for sudo). Or in other words, nobody thought that arbitrary env vars could be a vector for code injection."", ""As to whether extensive testing when the feature was added could have caught it, I'd say it's unlikely."", ""When you test for the feature, you test for functionality. The functionality works fine. If you export the function in one bash invocation, it's imported alright in another. A very thorough testing could have spotted issues when both a variable and function with the same name are exported or when the function is imported in a locale different from the one it was exported in."", ""But to be able to spot the vulnerability, it's not a functionality test you would have had to do. The security aspect would have had to be the main focus, and you wouldn't be testing the functionality, but the mechanism and how it could be abused."", ""It's not something that developers (especially in 1989) often have at the back of their mind, and a shell developer could be excused to think his software is unlikely to be network exploitable.""]","[<code>env xx='() { echo vulnerable; }' bash -c xx
</code>, <code>Fri Sep  1 18:52:08 1989  Brian Fox  (bfox at aurel)

       * readline.c: rl_insert ().  Optimized for large amounts
         of typeahead.  Insert all insertable characters at once.

       * I update this too irregularly.
         Released 1.03.
[...]
Sat Aug  5 08:32:05 1989  Brian Fox  (bfox at aurel)

       * variables.c: make_var_array (), initialize_shell_variables ()
         Added exporting of functions.
</code>, <code>foo=() {
  code
}
</code>, <code>=</code>, <code>bash</code>, <code>foo() { echo bar; }; export -f foo
export foo=bar
</code>, <code>bash</code>, <code>BASH_</code>, <code>rc</code>, <code>fn_</code>, <code>BASH_FUNCDEFS='f1() { echo foo;}
  f2() { echo bar;}...'
</code>, <code>$BASH_ENV</code>, <code>$SHELLOPTS</code>, <code>bash</code>, <code>BASH_FUNCDEFS</code>, <code>BASH_FUNC_myfunc()</code>, <code>.</code>, <code>:</code>, <code>/</code>, <code>.</code>, <code>:</code>, <code>bash</code>, <code>bash</code>, <code>bash</code>, <code>bash</code>, <code>bash</code>, <code>eval</code>, <code>.</code>, <code>bash</code>, <code>popen(""sendmail -oi -t"", ""w"");
</code>, <code>SERVER_PROTOCOL</code>, <code>QUERYSTRING</code>, <code>sudo</code>, <code>bash</code>, <code>mount</code>, <code>sudo</code>, <code>PS4</code>, <code>BASH_ENV</code>, <code>SHELLOPTS</code>, <code>()</code>, <code>sudo</code>, <code>echo=""() { evil; }""</code>, <code>HTTP_FOO=""() { evil; }""</code>, <code>HTTP_FOO</code>, <code>echo</code>, <code>BASH_ENV</code>, <code>sudo</code>, <code>bash</code>]"
67,https://unix.stackexchange.com/questions/50612/,How to combine 2 -name conditions in find?,"['You can do this using a negated -regex, too:-']","[<code>-regex</code>, <code> find ./ ! -regex  '.*\(deb\|vmdk\)$'
</code>]"
68,https://unix.stackexchange.com/questions/79064/,How to export variables from a file?,"[""Judging by your other question, you don't want to hardcode the variable names:"", 'test it:']","[<code>source tmp.txt
export a b c
./child ...
</code>, <code>source tmp.txt
export $(cut -d= -f1 tmp.txt)
</code>, <code>$ source tmp.txt
$ echo ""$a $b $c""
123 hello world one more variable
$ perl -E 'say ""@ENV{qw(a b c)}""'

$ export $(cut -d= -f1 tmp.txt)
$ perl -E 'say ""@ENV{qw(a b c)}""'
123 hello world one more variable
</code>]"
69,https://unix.stackexchange.com/questions/3747/,Understanding the exclamation mark (!) in bash,"['! is a feature that originally appeared in the C shell, back in the days before you could count on terminals to have arrow keys.  It\'s especially useful if you add the current command number to the prompt (PS1=""\\!$ "") so you can quickly look at your screen to get numbers for past commands.', ""Now that you can use arrow keys and things like Ctrl-R to search the command history, I don't see much use for the feature.  "", ""One variant of it you might still find useful is !!, which re-executes the previous command. On its own, I don't find !!Enter any faster than just ↑ Enter, but it can be helpful when combined into a larger command."", ""Example: A common pilot error on sudo based systems is to forget the sudo prefix on a command that requires extra privileges. A novice retypes the whole command. The diligent student edits the command from the shell's command history. The enlightened one types sudo !!."", 'Bash lets you disable ! processing in the shell with set +o histexpand or set +H. You can disable it in Zsh with set -K.']","[<code>!</code>, <code>PS1=""\!$ ""</code>, <code>!!</code>, <code>sudo</code>, <code>sudo</code>, <code>sudo !!</code>, <code>!</code>, <code>set +o histexpand</code>, <code>set +H</code>, <code>set -K</code>]"
70,https://unix.stackexchange.com/questions/145250/,Where is bash's history stored?,"[""Bash maintains the list of commands internally in memory while it's running. They are written into .bash_history on exit:"", 'When an interactive shell exits, the last $HISTSIZE lines are copied from the history list to the file named by $HISTFILE', 'If you want to force the command history to be written out, you can use the history -a command, which will:', 'Append the new history lines (history lines entered since the beginning of the current Bash session) to the history file.', 'There is also a -w option:', 'Write out the current history to the history file.', 'which may suit you more depending on exactly how you use your history.', ""If you want to make sure that they're always written immediately, you can put that command into your PROMPT_COMMAND variable:""]","[<code>.bash_history</code>, <code>history -a</code>, <code>-w</code>, <code>PROMPT_COMMAND</code>, <code>export PROMPT_COMMAND='history -a'
</code>]"
71,https://unix.stackexchange.com/questions/63923/,Pseudo files for temporary data,"['Use a named pipe.  By way of illustration:', 'The -e tells echo to properly interpret the newline escape (\\n).  This will block, ie, your shell will hang until something reads the data from the pipe.', 'Open another shell somewhere and in the same directory:', ""You'll read the echo, which will release the other shell.  Although the pipe exists as a file node on disk, the data which passes through it does not; it all takes place in memory.  You can background (&) the echo."", 'The pipe has a 64k buffer (on linux) and, like a socket, will block the writer when full, so you will not lose data as long as you do not prematurely kill the writer.']","[<code>mkfifo fifo
echo -e ""hello world\nnext line\nline 3"" &gt; fifo
</code>, <code>-e</code>, <code>\n</code>, <code>cat fifo
</code>, <code>&amp;</code>]"
72,https://unix.stackexchange.com/questions/64736/,Combine the output of two commands in bash,"['I ended up doing this, the other suggestions did not work, as the 2nd command was either killed or never executed.']","[<code>alias app () {
    nohup python ~/projects/trunk/run.py run 1&gt;/tmp/log 2&gt;&amp;1 &amp;
    echo $! &gt; /tmp/api.pid
    nohup node ~/projects/trunk/index.js 1&gt;/tmp/log 2&gt;&amp;1 &amp;
    echo $! &gt; /tmp/client.pid
    tail -f /tmp/log
}
</code>]"
73,https://unix.stackexchange.com/questions/138463/,Do parentheses really put the command in a subshell?,"[""A subshell starts out as an almost identical copy of the original shell process. Under the hood, the shell calls the fork system call1, which creates a new process whose code and memory are copies2. When the subshell is created, there are very few differences between it and its parent. In particular, they have the same variables. Even the $$ special variable keeps the same value in subshells: it's the original shell's process ID. Similarly $PPID is the PID of the parent of the original shell."", 'A few shells change a few variables in the subshell. Bash sets BASHPID to the PID of the shell process, which changes in subshells. Bash, zsh and mksh arrange for $RANDOM to yield different values in the parent and in the subshell. But apart from built-in special cases like these, all variables have the same value in the subshell as in the original shell, the same export status, the same read-only status, etc. All function definitions, alias definitions, shell options and other settings are inherited as well.', ""A subshell created by (…) has the same file descriptors as its creator. Some other means of creating subshells modify some file descriptors before executing user code; for example, the left-hand side of a pipe runs in a subshell3 with standard output connected to the pipe. The subshell also starts out with the same current directory, the same signal mask, etc. One of the few exceptions is that subshells do not inherit custom traps: ignored signals (trap '' SIGNAL) remain ignored in the subshell, but other traps (trap CODE SIGNAL) are reset to the default action4."", ""A subshell is thus different from executing a script. A script is a separate program. This separate program might coincidentally be also a script which is executed by the same interpreter as the parent, but this coincidence doesn't give the separate program any special visibility on internal data of the parent. Non-exported variables are internal data, so when the interpreter for the child shell script is executed, it doesn't see these variables. Exported variables, i.e. environment variables, are transmitted to executed programs."", 'Thus:', 'prints 1 because the subshell is a replication of the shell that spawned it.', 'happens to run a shell as a child process of a shell, but the x on the second line has no more connection with the x on the second line than in', 'or', '1  An exception is the ksh93 shell where the forking is optimised out and most of its side effects are emulated. \n2  Semantically, they\'re copies. From an implementation perspective, there\'s a lot of sharing going on. \n3  For the right-hand side, it depends on the shell. \n4  If you test this out, note that things like $(trap) may report the traps of the original shell. Note also that many shells have bugs in corner cases involving traps. For example ninjalj notes that as of bash 4.3, bash -x -c \'trap ""echo ERR at \\$BASH_SUBSHELL \\$BASHPID"" ERR; set -E; false; echo one subshell; (false); echo two subshells; ( (false) )\' runs the ERR trap from the nested subshell in the “two subshells” case, but not the ERR trap from the intermediate subshell — set -E option should propagate the ERR trap to all subshells but the intermediate subshell is optimized away and so isn\'t there to run its ERR trap.  ']","[<code>fork</code>, <code>$$</code>, <code>$PPID</code>, <code>BASHPID</code>, <code>$RANDOM</code>, <code>(…)</code>, <code>trap '' <em>SIGNAL</em></code>, <code>trap <em>CODE</em></code>, <code>x=1
(echo $x)
</code>, <code>1</code>, <code>x=1
sh -c 'echo $x'
</code>, <code>x</code>, <code>x</code>, <code>x=1
perl -le 'print $x'
</code>, <code>x=1
python -c 'print x'
</code>, <code>ksh93</code>, <code>$(trap)</code>, <code>bash -x -c 'trap ""echo ERR at \$BASH_SUBSHELL \$BASHPID"" ERR; set -E; false; echo one subshell; (false); echo two subshells; ( (false) )'</code>, <code>ERR</code>, <code>ERR</code>, <code>set -E</code>, <code>ERR</code>, <code>ERR</code>]"
74,https://unix.stackexchange.com/questions/116623/,^x^y unix trick for all instances in last command?,"['You can use the !!:gs/search/replace/ notation to do what you want. This utilizes the global search & replace (:gs):', 'before', 'after']","[<code>!!:gs/search/replace/</code>, <code>:gs</code>, <code>$ echo ""harm warm swarm barm""
harm warm swarm barm
</code>, <code>$ !!:gs/arm/orn/
echo ""horn worn sworn born""
horn worn sworn born
</code>]"
75,https://unix.stackexchange.com/questions/24684/,Confusing use of && and || operators,"['The right side of && will only be evaluated if the exit status of the left side is zero (i.e. true). || is the opposite: it will evaluate the right side only if the left side exit status is non-zero (i.e. false).', 'You can consider [ ... ] to be a program with a return value. If the test inside evaluates to true, it returns zero; it returns nonzero otherwise.', 'Examples:', 'Extra notes:', ""If you do which [, you might see that [ actually does point to a program! It's usually not actually the one that runs in scripts, though; run type [ to see what actually gets run. If you wan to try using the program, just give the full path like so: /bin/[ 1 = 1.""]","[<code>&amp;&amp;</code>, <code>||</code>, <code>[ ... ]</code>, <code>$ false &amp;&amp; echo howdy!

$ true &amp;&amp; echo howdy!
howdy!
$ true || echo howdy!

$ false || echo howdy!
howdy!
</code>, <code>which [</code>, <code>[</code>, <code>type [</code>, <code>/bin/[ 1 = 1</code>]"
76,https://unix.stackexchange.com/questions/22796/,"Can I ""export"" functions in bash?","['In Bash you can export function definitions to sub-shell with', 'For example you can try this simple example:', 'Then if you call ./script1 you will see the output Hello!.']","[<code>export -f function_name
</code>, <code>./script1</code>, <code>#!/bin/bash

myfun() {
    echo ""Hello!""
}

export -f myfun
./script2
</code>, <code>./script2</code>, <code>#!/bin/bash

myfun
</code>, <code>./script1</code>]"
77,https://unix.stackexchange.com/questions/13731/,"Is there a way to get the min, max, median, and average of a list of numbers in a single command?","['You can use the R programming language.', 'Here is a quick and dirty R script:', 'Note the ""stdin"" in scan which is a special filename to read from standard input (that means from pipes or redirections).', 'Now you can redirect your data over stdin to the R script:', 'Also works for floating points:', ""If you don't want to write an R script file you can invoke a true one-liner (with linebreak only for readability) in the command line using Rscript:"", 'Read the fine R manuals at http://cran.r-project.org/manuals.html.', 'Unfortunately the full reference is only available in PDF. Another way to read the reference is by typing ?topicname in the prompt of an interactive R session.', 'For completeness: there is an R command which outputs all the values you want and more. Unfortunately in a human friendly format which is hard to parse programmatically.']","[<code>#! /usr/bin/env Rscript
d&lt;-scan(""stdin"", quiet=TRUE)
cat(min(d), max(d), median(d), mean(d), sep=""\n"")
</code>, <code>""stdin""</code>, <code>scan</code>, <code>$ cat datafile
1
2
4
$ ./mmmm.r &lt; datafile
1
4
2
2.333333
</code>, <code>$ cat datafile2
1.1
2.2
4.4
$ ./mmmm.r &lt; datafile2
1.1
4.4
2.2
2.566667
</code>, <code>Rscript</code>, <code>$ Rscript -e 'd&lt;-scan(""stdin"", quiet=TRUE)' \
          -e 'cat(min(d), max(d), median(d), mean(d), sep=""\n"")' &lt; datafile
1
4
2
2.333333
</code>, <code>?topicname</code>, <code>&gt; summary(c(1,2,4))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   1.500   2.000   2.333   3.000   4.000 
</code>]"
78,https://unix.stackexchange.com/questions/73750/,"difference between ""function foo() {}"" and ""foo() {}""","['There is no difference AFAIK, other than the fact that the second version is more portable.']",[]
79,https://unix.stackexchange.com/questions/203290/,How do I clear the terminal History?,"['reset or tput reset only does things to the terminal. The history is entirely managed by the shell, which remains unaffected.', ""history -c clears your history in the current shell. That's enough (but overkill) if you've just typed your password and haven't exited that shell or saved its history explicitly."", ""When you exit bash, the history is saved to the history file, which by default is .bash_history in your home directory. More precisely, the history created during the current session is appended to the file; entries that are already present are unaffected. To overwrite the history file with the current shell's history, run history -w."", ""Instead of removing all your history entries, you can open .bash_history in an editor and remove the lines you don't want to keep. You can also do that inside bash, less conveniently, by using history to display all the entries, then history -d to delete the entries you don't want, and finally history -w to save."", 'Note that if you have multiple running bash instances that have read the password, each of them might save it again. Before definitively purging the password from the history file, make sure that it is purged from all running shell instances.', ""Note that even after you've edited the history file, it's possible that your password is still present somewhere on the disk from an earlier version of the file. It can't be retrieved through the filesystem anymore, but it might still be possible (but probably not easy) to find it by accessing the disk directly. If you use this password elsewhere and your disk gets stolen (or someone gets access to the disk), this could be a problem.""]","[<code>reset</code>, <code>tput reset</code>, <code>history -c</code>, <code>.bash_history</code>, <code>history -w</code>, <code>.bash_history</code>, <code>history</code>, <code>history -d</code>, <code>history -w</code>]"
80,https://unix.stackexchange.com/questions/146756/,Forward SIGTERM to child in Bash,"['Try:', ""Normally, bash will ignore any signals while a child process is executing. Starting the server with & will background it into the shell's job control system, with $! holding the server's PID (to be used with wait and kill). Calling wait will then wait for the job with the specified PID (the server) to finish, or for any signals to be fired."", ""When the shell receives SIGTERM (or the server exits independently), the wait call will return (exiting with the server's exit code, or with the signal number + 128 in case a signal was received). Afterward, if the shell received SIGTERM, it will call the _term function specified as the SIGTERM trap handler before exiting (in which we do any cleanup and manually propagate the signal to the server process using kill).""]","[<code>#!/bin/bash 

_term() { 
  echo ""Caught SIGTERM signal!"" 
  kill -TERM ""$child"" 2&gt;/dev/null
}

trap _term SIGTERM

echo ""Doing some initial work..."";
/bin/start/main/server --nodaemon &amp;

child=$! 
wait ""$child""
</code>, <code>bash</code>, <code>&amp;</code>, <code>$!</code>, <code>wait</code>, <code>kill</code>, <code>wait</code>, <code>SIGTERM</code>, <code>wait</code>, <code>_term</code>, <code>kill</code>]"
81,https://unix.stackexchange.com/questions/43601/,How can I set my default shell to start up tmux,"['Start tmux on every shell login, from Arch wiki, seems to work. Simply add the following line of bash code to your .bashrc before your aliases; the code for other shells is very similar:']","[<code>.bashrc</code>, <code>[[ $TERM != ""screen"" ]] &amp;&amp; exec tmux
</code>]"
82,https://unix.stackexchange.com/questions/94527/,How do I kill all screens?,"['You can use :', 'Or ', 'In OSX the process is called SCREEN in all caps. So, use:', 'Or']","[<code>pkill screen
</code>, <code>killall screen
</code>, <code>pkill SCREEN
</code>, <code>killall SCREEN
</code>]"
83,https://unix.stackexchange.com/questions/49913/,Recursive glob?,"['In order to do recursive globs in bash, you need the globstar feature from bash version 4 or higher.', 'From the bash manpage:', 'For your example pattern:']","[<code>globstar</code>, <code>globstar
    If set, the pattern ** used in a pathname expansion context will
    match all files and zero or more directories and subdirectories.
    If the pattern is followed by a /, only directories and
    subdirectories match.
</code>, <code>shopt -s globstar
ls -d -- **/*.py
</code>]"
84,https://unix.stackexchange.com/questions/105569/,bash - replace space with new line,"['Use the tr command', 'Found on http://www.unix.com/shell-programming-scripting/67831-replace-space-new-line.html']","[<code>tr</code>, <code>echo ""/path/to/file /path/to/file2 /path/to/file3 /path/to/file4 /path/to/file5""\
| tr "" "" ""\n""
</code>]"
85,https://unix.stackexchange.com/questions/269077/,tput setaf color table? How to determine color codes?,"['The count of colors available to tput is given by tput colors.  ', 'To see the basic 8 colors (as used by setf in urxvt terminal and setaf in xterm terminal):', 'And usually named as this:', 'To see the extended 256 colors (as used by setaf in urxvt):', 'If you want numbers and an ordered output:', ' ', 'The 16 million colors need quite a bit of code (some consoles can not show this).\nThe basics is:', 'fb is front/back or 3/4.  ', 'A simple test of your console capacity to present so many colors is:', '\nIt will present a red line with a very small change in tone from left to right. If that small change is visible, your console is capable of 16 million colors.', 'Each r, g, and  b is a value from 0 to 255 for RGB (Red,Green,Blue).', 'If your console type support this, this code will create a color table:', '', 'To convert an hex color value to a (nearest) 0-255 color index:', 'Use it as:', 'To find the color number as used in HTML colors format:', 'Use it as (""basic"" is the first 16 colors, ""color"" is the main group, ""gray"" is the last gray colors):']","[<code>tput colors</code>, <code>setf</code>, <code>setaf</code>, <code>$ printf '\e[%sm▒' {30..37} 0; echo           ### foreground
$ printf '\e[%sm ' {40..47} 0; echo           ### background
</code>, <code>Color       #define       Value       RGB
black     COLOR_BLACK       0     0, 0, 0
red       COLOR_RED         1     max,0,0
green     COLOR_GREEN       2     0,max,0
yellow    COLOR_YELLOW      3     max,max,0
blue      COLOR_BLUE        4     0,0,max
magenta   COLOR_MAGENTA     5     max,0,max
cyan      COLOR_CYAN        6     0,max,max
white     COLOR_WHITE       7     max,max,max
</code>, <code>setaf</code>, <code>$ printf '\e[48;5;%dm ' {0..255}; printf '\e[0m \n'
</code>, <code>#!/bin/bash
color(){
    for c; do
        printf '\e[48;5;%dm%03d' $c $c
    done
    printf '\e[0m \n'
}

IFS=$' \t\n'
color {0..15}
for ((i=0;i&lt;6;i++)); do
    color $(seq $((i*36+16)) $((i*36+51)))
done
color {232..255}
</code>, <code>fb=3;r=255;g=1;b=1;printf '\e[0;%s8;2;%s;%s;%sm▒▒▒ ' ""$fb"" ""$r"" ""$g"" ""$b""
</code>, <code>fb</code>, <code>front/back</code>, <code>3/4</code>, <code>for r in {200..255..5}; do fb=4;g=1;b=1;printf '\e[0;%s8;2;%s;%s;%sm   ' ""$fb"" ""$r"" ""$g"" ""$b""; done; echo
</code>, <code>r</code>, <code>g</code>, <code>b</code>, <code>mode2header(){
    #### For 16 Million colors use \e[0;38;2;R;G;Bm each RGB is {0..255}
    printf '\e[mR\n' # reset the colors.
    printf '\n\e[m%59s\n' ""Some samples of colors for r;g;b. Each one may be 000..255""
    printf '\e[m%59s\n'   ""for the ansi option: \e[0;38;2;r;g;bm or \e[0;48;2;r;g;bm :""
}
mode2colors(){
    # foreground or background (only 3 or 4 are accepted)
    local fb=""$1""
    [[ $fb != 3 ]] &amp;&amp; fb=4
    local samples=(0 63 127 191 255)
    for         r in ""${samples[@]}""; do
        for     g in ""${samples[@]}""; do
            for b in ""${samples[@]}""; do
                printf '\e[0;%s8;2;%s;%s;%sm%03d;%03d;%03d ' ""$fb"" ""$r"" ""$g"" ""$b"" ""$r"" ""$g"" ""$b""
            done; printf '\e[m\n'
        done; printf '\e[m'
    done; printf '\e[mReset\n'
}
mode2header
mode2colors 3
mode2colors 4
</code>, <code>fromhex(){
    hex=${1#""#""}
    r=$(printf '0x%0.2s' ""$hex"")
    g=$(printf '0x%0.2s' ${hex#??})
    b=$(printf '0x%0.2s' ${hex#????})
    printf '%03d' ""$(( (r&lt;75?0:(r-35)/40)*6*6 + 
                       (g&lt;75?0:(g-35)/40)*6   +
                       (b&lt;75?0:(b-35)/40)     + 16 ))""
}
</code>, <code>$ fromhex 00fc7b
048
$ fromhex #00fc7b
048
</code>, <code>#!/bin/dash
tohex(){
    dec=$(($1%256))   ### input must be a number in range 0-255.
    if [ ""$dec"" -lt ""16"" ]; then
        bas=$(( dec%16 ))
        mul=128
        [ ""$bas"" -eq ""7"" ] &amp;&amp; mul=192
        [ ""$bas"" -eq ""8"" ] &amp;&amp; bas=7
        [ ""$bas"" -gt ""8"" ] &amp;&amp; mul=255
        a=""$((  (bas&amp;1)    *mul ))""
        b=""$(( ((bas&amp;2)&gt;&gt;1)*mul ))"" 
        c=""$(( ((bas&amp;4)&gt;&gt;2)*mul ))""
        printf 'dec= %3s basic= #%02x%02x%02x\n' ""$dec"" ""$a"" ""$b"" ""$c""
    elif [ ""$dec"" -gt 15 ] &amp;&amp; [ ""$dec"" -lt 232 ]; then
        b=$(( (dec-16)%6  )); b=$(( b==0?0: b*40 + 55 ))
        g=$(( (dec-16)/6%6)); g=$(( g==0?0: g*40 + 55 ))
        r=$(( (dec-16)/36 )); r=$(( r==0?0: r*40 + 55 ))
        printf 'dec= %3s color= #%02x%02x%02x\n' ""$dec"" ""$r"" ""$g"" ""$b""
    else
        gray=$(( (dec-232)*10+8 ))
        printf 'dec= %3s  gray= #%02x%02x%02x\n' ""$dec"" ""$gray"" ""$gray"" ""$gray""
    fi
}

for i in $(seq 0 255); do
    tohex ${i}
done
</code>, <code>$ tohex 125                  ### A number in range 0-255
dec= 125 color= #af005f
$ tohex 6
dec=   6 basic= #008080
$ tohex 235
dec= 235  gray= #262626
</code>]"
86,https://unix.stackexchange.com/questions/32210/,"Why does parameter expansion with spaces without quotes work inside double brackets ""[["" but not inside single brackets ""[""?","[""The single bracket [ is actually an alias for the test command, it's not syntax."", 'One of the downsides (of many) of the single bracket is that if one or more of the operands it is trying to evaluate return an empty string, it will complain that it was expecting two operands (binary). This is why you see people do [ x$foo = x$blah ], the x guarantees that the operand will never evaluate to an empty string.', 'The double bracket [[ ]], on the other hand, is syntax and is much more capable than [ ].  As you found out, it does not have the ""missing operand"" issue and it also allows for more C-like syntax with >, <, >=, <=, !=, ==, &&, || operators.', 'My recommendation is the following: If your interpreter is #!/bin/bash, then always use [[ ]]', 'It is important to note that [[ ]] is not supported by all POSIX shells, however many shells do support it such as zsh and ksh in addition to bash']","[<code>[</code>, <code>test</code>, <code>[ x$foo = x$blah ]</code>, <code>x</code>, <code>[[ ]]</code>, <code>[ ]</code>, <code>&gt;, &lt;, &gt;=, &lt;=, !=, ==, &amp;&amp;, ||</code>, <code>#!/bin/bash</code>, <code>[[ ]]</code>, <code>[[ ]]</code>, <code>zsh</code>, <code>ksh</code>, <code>bash</code>]"
87,https://unix.stackexchange.com/questions/25945/,How to check if there are no parameters provided to a command?,"['To check if there were no arguments provided to the command, check value of $# variable then,', 'If you want to use $*(not preferable) then,', 'Some explanation:', 'The second approach is not preferable because in positional parameter expansion * expands to the positional parameters, starting from one. When the expansion occurs within double quotes, it expands to a single word with the value of each parameter separated by the first character of the IFS special variable. That means a string is constructed. So there is extra overhead. ', 'On the other hand # expands to the number of positional parameters.', 'Example:', '$ command param1 param2', 'Here,', 'Value of $# is 2 and value of $* is string ""param1 param2"" (without quotes), if IFS is unset. Because if IFS is unset, the parameters are separated by spaces', 'For more details man bash and read topic named Special Parameters']","[<code>$#</code>, <code>if [ $# -eq 0 ]; then
    echo ""No arguments provided""
    exit 1
fi
</code>, <code>$*</code>, <code>if [ ""$*"" == """" ]; then
    echo ""No arguments provided""
    exit 1
fi
</code>, <code>*</code>, <code>#</code>, <code>$ command param1 param2</code>, <code>$#</code>, <code>$*</code>, <code>man bash</code>]"
88,https://unix.stackexchange.com/questions/10825/,Remember a half-typed command while I check something,"[""A somewhat faster version of alex's Ctrl+A Ctrl+K (which moves to the front of the line and then cuts everything forward) is to just use Ctrl+U, which cuts backward on bash, and the entire line (regardless of your current position) on zsh. Then you use Ctrl+Y to paste it again""]",[]
89,https://unix.stackexchange.com/questions/78376/,"In linux, how to delete all files EXCEPT the pattern *.txt?","['You can use find:', ""Or bash's extended globbing features:"", 'Or in zsh:']","[<code>find</code>, <code>find . -type f ! -name '*.txt' -delete
</code>, <code>shopt -s extglob
rm *.!(txt)
</code>, <code>setopt extendedglob
rm *~*.txt(.)
#  ||     ^^^ Only plain files
#  ||^^^^^ files ending in "".txt""
#  | \Except
#   \Everything
</code>]"
90,https://unix.stackexchange.com/questions/64258/,What do the scripts in /etc/profile.d do?,"['Why are these files not a part of /etc/profile if they are also critical to Bash startup ?', 'If you mean, ""Why are they not just combined into one giant script?"", the answer is:', 'If these files are application-specific startup files not critical to Bash startup, then why are they part of the startup process ? Why\n  are they not run only when the specific applications, for which they\n  contain settings, are executed ?', 'That seems to me like a broader design philosophy question that I\'ll split into two.  The first question is about the value and appropriateness of using the shell environment.  Does it have positive value?  Yes, it is useful.  Is it the best solution to all configuration issues?  No, but it is very efficient for managing simple parameters, and also widely recognized and understood. Contrast that to say, deciding to configure such things heterogeneously, perhaps $PATH could be managed by a separate independent tool, preferred tools such as $EDITOR could be in an sqlite file somewhere, $LC lang stuff could be in a text file with a custom format somewhere else, etc -- doesn\'t just using env variables and /etc/profile.d suddenly seem simpler?  You probably already know what an env variable is, how they work and how to use them, vs. learning 5 completely different mechanisms for 5 different ubiquitous aspects of what is appropriately named ""the environment"".', 'The second question is, ""Is startup the appropriate time for this?"", which begs the objection that it is not very efficient (all that data which may or may not get used, etc). But:  ', ""More could be added to that list, but hopefully this gives you some idea about the pros and cons of the issue -- the major 'pro' and the major 'con' being that it is a global namespace.""]","[<code>/etc/profile.d</code>, <code>gcc</code>]"
91,https://unix.stackexchange.com/questions/5366/,Command-line completion from command history,"['Pressing Ctrl+R will open the reverse history search. Now start typing your command, this will give the first match.\nBy pressing Ctrl+R again (and again) you can cycle through the history.', 'Would give:', 'Ctrl+R again:']","[<code>mysq(Ctrl+R)
</code>, <code>mysqldump  --add-drop-table -e -q -n -C -u 
</code>, <code>mysql -u ben.dauphinee -p
</code>]"
92,https://unix.stackexchange.com/questions/18212/,"Bash history: ""ignoredups"" and ""erasedups"" setting conflict with common history across sessions","['This is actually a really interesting behavior and I confess I have greatly underestimated the question at the beginning.  But first the facts:', '###1. What works', 'The functionality can be achieved in several ways, though each works a bit differently. Note that, in each case, to have the history ""transferred"" to another terminal (updated), one has to press Enter in the terminal, where he/she wants to retrieve the history.', 'option 1:', 'This has two drawbacks:', 'option 2:', '(Yes, no need for shopt -s histappend and yes, it has to be history -c in the middle of PROMPT_COMMAND)\nThis version has  also two important drawbacks:', '[Edit]\n""And the winner is...""', 'option 3:', 'This is as far as it gets. It is the only option to have both erasedups and common history working simultaneously.\nThis is probably the final solution to all your problems, Aahan.', '###2. Why does option 2 not seem to work (or: what really doesn\'t work as expected)?\nAs I mentioned, each of the above solutions works differently. But the most misleading interpretation of how the settings work comes from analysing the output of history command.  In many cases, the command can give false output. Why? Because it is executed before the sequence of other history commands contained in the PROMPT_COMMAND! However, when using the second or third option, one can monitor the changes of .bash_history contents  (using watch -n1 ""tail -n20 .bash_history"" for example) and see what the real history is.', '###3. Why option 3 is so complicated?\nIt all lies in the way erasedups works. As the bash manual states,  ""(...) erasedups causes all previous lines matching the current line to be removed from  the history list before that line is saved"". So this is really what the OP wanted (and not just, as I previously thought, to have no duplicates appearing in sequence). Here\'s why each of the history -. commands either has to or can not be in the PROMPT_COMMAND:', 'history -n has to be there before history -w to read from .bash_history the commands saved from any other terminal,', 'history -w has to be there in order to save the new history to the file after bash has checked if the command was a duplicate,', 'history -a must not be placed there instead of history -w, because it will add to the file any new command, regardless of whether it was checked as a duplicate.', 'history -c is also needed because it prevents trashing the history buffer after each command,', 'and finally, history -r is needed to restore the history buffer from file, thus finally making the history shared across terminal sessions.', 'Be aware that this solution will mess up the history order by putting all history from other terminals in front of the newest command entered in the current terminal. It also does not delete duplicate lines already in the history file unless you enter that command again.']","[<code> shopt -s histappend
 HISTCONTROL=ignoredups
 PROMPT_COMMAND=""history -a; history -n; $PROMPT_COMMAND""
</code>, <code> HISTCONTROL=ignoredups
 PROMPT_COMMAND=""history -a; history -c; history -r; $PROMPT_COMMAND""
</code>, <code>shopt -s histappend</code>, <code>history -c</code>, <code>PROMPT_COMMAND</code>, <code>history</code>, <code> HISTCONTROL=ignoredups:erasedups
 shopt -s histappend
 PROMPT_COMMAND=""history -n; history -w; history -c; history -r; $PROMPT_COMMAND""
</code>, <code>erasedups</code>, <code>history</code>, <code>history</code>, <code>PROMPT_COMMAND</code>, <code>.bash_history</code>, <code>watch -n1 ""tail -n20 .bash_history""</code>, <code>erasedups</code>, <code>erasedups</code>, <code>history -.</code>, <code>PROMPT_COMMAND</code>, <code>history -n</code>, <code>history -w</code>, <code>.bash_history</code>, <code>history -w</code>, <code>history -a</code>, <code>history -w</code>, <code>history -c</code>, <code>history -r</code>]"
93,https://unix.stackexchange.com/questions/296838/,What's the difference between eval and exec?,"['eval and exec are completely different beasts. (Apart from the fact that both will run commands, but so does everything you do in a shell.)', 'What exec cmd does, is exactly the same as just running cmd, except that the current shell is replaced with the command, instead of a separate process being run. Internally, running say /bin/ls will call fork() to create a child process, and then exec() in the child to execute /bin/ls. exec /bin/ls on the other hand will not fork, but just replaces the shell.', 'Compare:', 'with', ""echo $$ prints the PID of the shell I started, and listing /proc/self gives us the PID of the ls that was ran from the shell. Usually, the process IDs are different, but with exec the shell and ls have the same process ID. Also, the command following exec didn't run, since the shell was replaced."", 'On the other hand:', 'eval will run the arguments as a command in the current shell.  In other words eval foo bar is the same as just foo bar. But variables will be expanded before executing, so we can execute commands saved in shell variables:', 'It will not create a child process, so the variable is set in the current shell. (Of course eval /bin/ls will create a child process, the same way a plain old /bin/ls would.)', 'Or we could have a command that outputs shell commands. Running ssh-agent starts the agent in the background, and outputs a bunch of variable assignments, which could be set in the current shell and used by child processes (the ssh commands you would run). Hence ssh-agent can be started with:', 'And the current shell will get the variables for other commands to inherit.', 'Of course, if the variable cmd happened to contain something like rm -rf $HOME, then running eval ""$cmd"" would not be something you\'d want to do. Even things like command substitutions inside the string would be processed, so one should really be sure that the input to eval is safe before using it.', ""Often, it's possible to avoid eval and avoid even accidentally mixing code and data in the wrong way.""]","[<code>eval</code>, <code>exec</code>, <code>$ help exec
exec: exec [-cl] [-a name] [command [arguments ...]] [redirection ...]
    Replace the shell with the given command.
</code>, <code>exec cmd</code>, <code>cmd</code>, <code>/bin/ls</code>, <code>fork()</code>, <code>exec()</code>, <code>/bin/ls</code>, <code>exec /bin/ls</code>, <code>$ bash -c 'echo $$ ; ls -l /proc/self ; echo foo'
7218
lrwxrwxrwx 1 root root 0 Jun 30 16:49 /proc/self -&gt; 7219
foo
</code>, <code>$ bash -c 'echo $$ ; exec ls -l /proc/self ; echo foo'
7217
lrwxrwxrwx 1 root root 0 Jun 30 16:49 /proc/self -&gt; 7217
</code>, <code>echo $$</code>, <code>/proc/self</code>, <code>ls</code>, <code>exec</code>, <code>ls</code>, <code>exec</code>, <code>$ help eval
eval: eval [arg ...]
    Execute arguments as a shell command.
</code>, <code>eval</code>, <code>eval foo bar</code>, <code>foo bar</code>, <code>$ unset bar
$ cmd=""bar=foo""
$ eval ""$cmd""
$ echo ""$bar""
foo
</code>, <code>eval /bin/ls</code>, <code>/bin/ls</code>, <code>ssh-agent</code>, <code>ssh</code>, <code>ssh-agent</code>, <code>eval $(ssh-agent)
</code>, <code>cmd</code>, <code>rm -rf $HOME</code>, <code>eval ""$cmd""</code>, <code>eval</code>, <code>eval</code>]"
94,https://unix.stackexchange.com/questions/37411/,Multiline shell script comments - how does this work?,"['That is not a multi-line comment.  # is a single line comment. \n: (colon) is not a comment at all, but rather a shell built-in command that is basically a NOP, a null operation that does nothing except return true, like true (and thus setting $? to 0 as a side effect).  However since it is a command, it can accept arguments, and since it ignores its arguments, in most cases it superficially acts like a comment.  The main problem with this kludge is the arguments are still expanded, leading to a host of unintended consequences.  The arguments are still affected by syntax errors, redirections are still performed so : > file will truncate file, and : $(dangerous command) substitutions will still run.', 'The least surprising completely safe way to insert comments in shell scripts is with #.  Stick to that even for multi-line comments.  Never attempt to (ab)use : for comments.  There is no dedicated multi-line comment mechanism in shell that is analogous to the slash-star /* */ form in C-like languages.', 'For the sake of completeness, but not because it is recommended practice, I will mention that it is possible to use here-documents to do multi-line ""comments"":']","[<code>#</code>, <code>:</code>, <code>true</code>, <code>$?</code>, <code>: &gt; file</code>, <code>file</code>, <code>: $(dangerous command)</code>, <code>#</code>, <code>:</code>, <code>/* */</code>, <code>C</code>, <code>: &lt;&lt;'end_long_comment'
This is an abuse of the null command ':' and the here-document syntax
to achieve a ""multi-line comment"".  According to the POSIX spec linked 
above, if any character in the delimiter word (""end_long_comment"" in 
this case) above is quoted, the here-document will not be expanded in 
any way.  This is **critical**, as failing to quote the ""end_long_comment"" 
will result in the problems with unintended expansions described above. 
All of this text in this here-doc goes to the standard input of :, which 
does nothing with it, hence the effect is like a comment.  There is very 
little point to doing this besides throwing people off.  Just use '#'.
end_long_comment
</code>]"
95,https://unix.stackexchange.com/questions/48106/,"What does it mean to have a $""dollarsign-prefixed string"" in a script?","['There are two different things going on here, both documented in the bash manual', 'Dollar-sign single quote is a special form of quoting:', 'ANSI C Quoting', ""Words of the form $'string' are treated specially. The word expands to string, with backslash-escaped characters replaced as specified by the ANSI C standard."", 'Dollar-sign double-quote is for localization:', 'Locale translation', 'A double-quoted string preceded by a dollar sign (‘$’) will cause the string to be translated according to the current locale. If the current locale is C or POSIX, the dollar sign is ignored. If the string is translated and replaced, the replacement is double-quoted.']",[<code>bash</code>]
96,https://unix.stackexchange.com/questions/61584/,How to solve the issue that a Terminal screen is messed up? (usually after a resizing),"['If you are using bash, check if ""checkwinsize"" option is activated in your session using', ""If you don't get "", 'then activate it with', 'Bash documentation says for ""checkwinsize"" attribute : ', '""If set, Bash checks the window size after each command and, if\n  necessary, updates the values of LINES and COLUMNS.""', 'If you like the setting, you could activate checkwinsize in your ~/.bashrc.']","[<code>shopt | grep checkwinsize
</code>, <code>checkwinsize    on
</code>, <code>shopt -s checkwinsize
</code>, <code>checkwinsize</code>, <code>~/.bashrc</code>, <code>shopt -s checkwinsize</code>, <code>shopt -u checkwinsize</code>]"
97,https://unix.stackexchange.com/questions/1087/,su options - running command as another user,"[""Yes. Here's the --help:"", ""And some testing (I used sudo as I don't know the password for the nobody account)"", ""When your command takes arguments you need to quote it. If you don't, strange things will occur. Here I am —as root— trying to create a directory in /home/oli (as oli) without quoting the full command:"", ""It's only read mkdir as the value for the -c flag and it's trying to use /home/oli/java as the username. If we quote it, it just works:""]","[<code>--help</code>, <code>$ su --help
Usage: su [options] [LOGIN]

Options:
  -c, --command COMMAND         pass COMMAND to the invoked shell
  -h, --help                    display this help message and exit
  -, -l, --login                make the shell a login shell
  -m, -p,
  --preserve-environment        do not reset environment variables, and
                                keep the same shell
  -s, --shell SHELL             use SHELL instead of the default in passwd
</code>, <code>sudo</code>, <code>nobody</code>, <code>$ sudo su -c whoami nobody
[sudo] password for oli: 
nobody
</code>, <code># su -c mkdir /home/oli/java oli
No passwd entry for user '/home/oli/java'
</code>, <code>mkdir</code>, <code>-c</code>, <code>/home/oli/java</code>, <code># su -c ""mkdir /home/oli/java"" oli
# stat /home/oli/java
  File: ‘/home/oli/java’
  Size: 4096        Blocks: 8          IO Block: 4096   directory
Device: 811h/2065d  Inode: 5817025     Links: 2
Access: (0775/drwxrwxr-x)  Uid: ( 1000/     oli)   Gid: ( 1000/     oli)
Access: 2016-02-16 10:49:15.467375905 +0000
Modify: 2016-02-16 10:49:15.467375905 +0000
Change: 2016-02-16 10:49:15.467375905 +0000
 Birth: -
</code>]"
98,https://unix.stackexchange.com/questions/134437/,Press space to continue,"['You can use read:', ""Replace ' ' for space at above with '' for Enter key, $'\\t' for Tab key.""]","[<code>read</code>, <code>read -n1 -s -r -p $'Press space to continue...\n' key

if [ ""$key"" = ' ' ]; then
    # Space pressed, do something
    # echo [$key] is empty when SPACE is pressed # uncomment to trace
else
    # Anything else pressed, do whatever else.
    # echo [$key] not empty
fi
</code>, <code>' '</code>, <code>''</code>, <code>$'\t'</code>]"
99,https://unix.stackexchange.com/questions/318859/,How to use watch command with a piped chain of commands/programs,[],"[<code>watch 'command | othertool | yet-another-tool'
</code>]"
100,https://unix.stackexchange.com/questions/86270/,How do you use the command coproc in various shells?,"['co-processes are a ksh feature (already in ksh88). zsh has had the feature from the start (early 90s), while it has just only been added to bash in 4.0 (2009).', 'However, the behaviour and interface is significantly different between the 3 shells.', 'The idea is the same, though: it allows to start a job in background and being able to send it input and read its output without having to resort to  named pipes.', 'That is done with unnamed pipes with most shells and socketpairs with recent versions of ksh93 on some systems. ', 'In a | cmd | b, a feeds data to cmd and b reads its output. Running cmd as a co-process allows the shell to be both a and b.', 'In ksh, you start a coprocess as:', 'You feed data to cmd by doing things like:', 'or', ""And read cmd's output with things like:"", 'or', 'cmd is started as any background job, You can use fg, bg, kill on it and refer it by %job-number or via $!.', 'To close the writing end of the pipe cmd is reading from, you can do:', 'And to close the reading end of the other pipe (the one cmd is writing to):', 'You cannot start a second co-process unless you first save the pipe file descriptors to some other fds. For instance:', 'In zsh, co-processes are nearly identical to those in ksh. The only real difference is that zsh co-processes are started with the coproc keyword.', 'Doing:', ""Note: This doesn't move the coproc file descriptor to fd 3 (like in ksh), but duplicates it. So, there's no explicit way to close the feeding or reading pipe, other starting another coproc. "", 'For instance, to close the feeding end:', ""In addition to pipe based co-processes, zsh (since 3.1.6-dev19, released in 2000) has pseudo-tty based constructs like expect. To interact with most programs, ksh-style co-processes won't work, since programs start buffering when their output is a pipe."", 'Here are some examples.', 'Start the co-process x:', '(Here, cmd is a simple command. But you can do fancier things with eval or functions.)', 'Feed a co-process data:', 'Read co-process data (in the simplest case):', 'Like expect, it can wait for some output from the co-process matching a given pattern.', 'The bash syntax is a lot newer, and builds on top of a new feature recently added to ksh93, bash, and zsh. It provides a syntax to allow handling of dynamically-allocated file descriptors above 10.', 'bash offers a basic coproc syntax, and an extended one. ', ""The basic syntax for starting a co-process looks like zsh's:"", 'In ksh or zsh, the pipes to and from the co-process are accessed with >&p and <&p. ', 'But in bash, the file descriptors of the pipe from the co-process and the other pipe to the co-proccess are returned in the $COPROC array (respectively ${COPROC[0]} and ${COPROC[1]}. So…', 'Feed data to the co-process:', 'Read data from the co-process:', 'With the basic syntax, you can start only one co-process at the time.', 'In the extended syntax, you can name your co-processes (like in zsh zpty co-proccesses):', 'The command has to be a compound command. (Notice how the example above is reminiscent of function f { ...; }.)', 'This time, the file descriptors are in ${mycoproc[0]} and ${mycoproc[1]}.', 'You can start more than one co-process at a time—but you do get a warning when you start a co-process while one is still running (even in non-interactive mode).', 'You can close the file descriptors when using the extended syntax.', ""Note that closing that way doesn't work in bash versions prior to 4.3 where you have to write it instead:"", 'As in ksh and zsh, those pipe file descriptors are marked as close-on-exec. ', 'But in bash, the only way to pass those to executed commands is to duplicate them to fds 0, 1, or 2. That limits the number of co-processes you can interact with for a single command. (See below for an example.)', ""yash doesn't have a co-process feature per se, but the same concept can be implemented with its pipeline and process redirection features. yash has an interface to the pipe() system call, so this kind of thing can be done relatively easily by hand there."", ""You'd start a co-process with:"", ""Which first creates a pipe(4,5) (5 the writing end, 4 the reading end), then redirects fd 3 to a pipe to a process that runs with its stdin at the other end, and stdout going to the pipe created earlier. Then we close the writing end of that pipe in the parent which we won't need. So now in the shell we have fd 3 connected to the cmd's stdin and fd 4 connected to cmd's stdout with pipes."", 'Note that the close-on-exec flag is not set on those file descriptors.', 'To feed data:', 'To read data:', 'And you can close fds as usual:', 'Co-processes can easily be implemented with standard named pipes. I don\'t know when exactly named pipes were introduced but it\'s possible it was after ksh came up with co-processes (probably in the mid 80s, ksh88 was ""released"" in 88, but I believe ksh was used internally at AT&T a few years before that) which would explain why.', 'Can be written with:', 'Interacting with those is more straightforward—especially if you need to run more than one co-process. (See examples below.)', ""The only benefit of using coproc is that you don't have to clean up of those named pipes after use."", 'Shells use pipes in a few constructs: ', 'In those, the data flows in only one direction between different processes.', ""With co-processes and named pipes, though, it's easy to run into deadlock. You have to keep track of which command has which file descriptor open, to prevent one staying open and holding a process alive. Deadlocks can be tricky to investigate, because they may occur non-deterministically; for instance, only when as much data as to fill one pipe up is sent."", 'The main purpose of co-processes was to provide the shell with a way to interact with commands. However, it does not work so well.', 'The simplest form of deadlock mentioned above is:', ""Because its output doesn't go to a terminal, tr buffers its output. So it won't output anything until either it sees end-of-file on its stdin, or it has accumulated a buffer-full of data to output. So above, after the shell has output  a\\n (only 2 bytes), the read will block indefinitely because tr is waiting for the shell to send it more data."", ""In short, pipes aren't good for interacting with commands. Co-processes can only be used to interact with commands that don't buffer their output, or commands which can be told not to buffer their output; for example, by using stdbuf with some commands on recent GNU or FreeBSD systems."", ""That's why expect or zpty use pseudo-terminals instead. expect is a tool designed for interacting with commands, and it does it well."", 'Co-processes can be used to do some more complex plumbing than what simple shell pipes allow.', 'that other Unix.SE answer has an example of a coproc usage.', ""Here's a simplified example: Imagine you want a function that feeds a copy of a command's output to 3 other commands, and then have the output of those 3 commands get concatenated. "", 'All using pipes.', ""For instance: feed the output of printf '%s\\n' foo bar to tr a b, sed 's/./&&/g', and cut -b2- to obtain something like:"", ""First, it's not necessarily obvious, but there’s a possibility for deadlock there, and it will start to happen after only a few kilobytes of data."", 'Then, depending on your shell, you’ll run in a number of different problems that have to be addressed differently.', ""For instance, with zsh, you'd do it with:"", ""Above, the co-process fds have the close-on-exec flag set, but not the ones that are duplicated from them (as in {o1}<&p). So, to avoid deadlocks, you’ll have to make sure they're closed in any processes that don't need them. "", ""Similarly, we have to use a subshell and use exec cat in the end, to ensure there's no shell process lying about holding a pipe open."", 'With ksh (here ksh93), that would have to be:', '(Note: That won’t work on systems where ksh uses socketpairs instead of pipes, and where /dev/fd/n works like on Linux.)', ""In ksh, fds above 2 are marked with the close-on-exec flag, unless they’re passed explicitly on the command line. That’s why we don't have to close the unused file descriptors like with zsh—but it’s also why we have to do {i1}>&$i1 and use eval for that new value of $i1, to be passed to tee and cat…"", ""In bash this cannot be done, because you can't avoid the close-on-exec flag."", ""Above, it's relatively simple, because we use only simple external commands. It gets more complicated when you want to use shell constructs in there instead, and you start running into shell bugs."", 'Compare the above with the same using named pipes:', ""If you want to interact with a command, use expect, or zsh's zpty, or named pipes."", 'If you want to do some fancy plumbing with pipes, use named pipes.', 'Co-processes can do some of the above, but be prepared to do some serious head scratching for anything non-trivial.']","[<code>ksh</code>, <code>ksh88</code>, <code>zsh</code>, <code>bash</code>, <code>4.0</code>, <code>a | cmd | b</code>, <code>a</code>, <code>cmd</code>, <code>b</code>, <code>cmd</code>, <code>a</code>, <code>b</code>, <code>ksh</code>, <code>cmd |&amp;
</code>, <code>cmd</code>, <code>echo test &gt;&amp;p
</code>, <code>print -p test
</code>, <code>cmd</code>, <code>read var &lt;&amp;p
</code>, <code>read -p var
</code>, <code>cmd</code>, <code>fg</code>, <code>bg</code>, <code>kill</code>, <code>%job-number</code>, <code>$!</code>, <code>cmd</code>, <code>exec 3&gt;&amp;p 3&gt;&amp;-
</code>, <code>cmd</code>, <code>exec 3&lt;&amp;p 3&lt;&amp;-
</code>, <code>tr a b |&amp;
exec 3&gt;&amp;p 4&lt;&amp;p
tr b c |&amp;
echo aaa &gt;&amp;3
echo bbb &gt;&amp;p
</code>, <code>zsh</code>, <code>ksh</code>, <code>zsh</code>, <code>coproc</code>, <code>coproc cmd
echo test &gt;&amp;p
read var &lt;&amp;p
print -p test
read -p var
</code>, <code>exec 3&gt;&amp;p
</code>, <code>coproc</code>, <code>3</code>, <code>ksh</code>, <code>coproc</code>, <code>coproc tr a b
echo aaaa &gt;&amp;p # send some data

exec 4&lt;&amp;p     # preserve the reading end on fd 4
coproc :      # start a new short-lived coproc (runs the null command)

cat &lt;&amp;4       # read the output of the first coproc
</code>, <code>zsh</code>, <code>expect</code>, <code>x</code>, <code>zmodload zsh/zpty
zpty x cmd
</code>, <code>cmd</code>, <code>eval</code>, <code>zpty -w x some data
</code>, <code>zpty -r x var
</code>, <code>expect</code>, <code>bash</code>, <code>coproc</code>, <code>zsh</code>, <code>coproc cmd
</code>, <code>ksh</code>, <code>zsh</code>, <code>&gt;&amp;p</code>, <code>&lt;&amp;p</code>, <code>bash</code>, <code>$COPROC</code>, <code>${COPROC[0]}</code>, <code>${COPROC[1]}</code>, <code>echo xxx &gt;&amp;""${COPROC[1]}""
</code>, <code>read var &lt;&amp;""${COPROC[0]}""
</code>, <code>zsh</code>, <code>coproc mycoproc { cmd; }
</code>, <code>function f { ...; }</code>, <code>${mycoproc[0]}</code>, <code>${mycoproc[1]}</code>, <code>coproc tr { tr a b; }
echo aaa &gt;&amp;""${tr[1]}""

exec {tr[1]}&gt;&amp;-

cat &lt;&amp;""${tr[0]}""
</code>, <code>fd=${tr[1]}
exec {fd}&gt;&amp;-
</code>, <code>ksh</code>, <code>zsh</code>, <code>bash</code>, <code>0</code>, <code>1</code>, <code>2</code>, <code>yash</code>, <code>yash</code>, <code>pipe()</code>, <code>exec 5&gt;&gt;|4 3&gt;(cmd &gt;&amp;5 4&lt;&amp;- 5&gt;&amp;-) 5&gt;&amp;-
</code>, <code>pipe(4,5)</code>, <code>echo data &gt;&amp;3 4&lt;&amp;-
</code>, <code>read var &lt;&amp;4 3&gt;&amp;-
</code>, <code>exec 3&gt;&amp;- 4&lt;&amp;-
</code>, <code>ksh</code>, <code>ksh</code>, <code>cmd |&amp;
echo data &gt;&amp;p
read var &lt;&amp;p
</code>, <code>mkfifo in out

cmd &lt;in &gt;out &amp;
exec 3&gt; in 4&lt; out
echo data &gt;&amp;3
read var &lt;&amp;4
</code>, <code>coproc</code>, <code>cmd1 | cmd2</code>, <code>$(cmd)</code>, <code>&lt;(cmd)</code>, <code>&gt;(cmd)</code>, <code>expect</code>, <code>tr a b |&amp;
echo a &gt;&amp;p
read var&lt;&amp;p
</code>, <code>tr</code>, <code>stdin</code>, <code>a\n</code>, <code>read</code>, <code>tr</code>, <code>stdbuf</code>, <code>expect</code>, <code>zpty</code>, <code>expect</code>, <code>printf '%s\n' foo bar</code>, <code>tr a b</code>, <code>sed 's/./&amp;&amp;/g'</code>, <code>cut -b2-</code>, <code>foo
bbr
ffoooo
bbaarr
oo
ar
</code>, <code>zsh</code>, <code>f() (
  coproc tr a b
  exec {o1}&lt;&amp;p {i1}&gt;&amp;p
  coproc sed 's/./&amp;&amp;/g' {i1}&gt;&amp;- {o1}&lt;&amp;-
  exec {o2}&lt;&amp;p {i2}&gt;&amp;p
  coproc cut -c2- {i1}&gt;&amp;- {o1}&lt;&amp;- {i2}&gt;&amp;- {o2}&lt;&amp;-
  tee /dev/fd/$i1 /dev/fd/$i2 &gt;&amp;p {o1}&lt;&amp;- {o2}&lt;&amp;- &amp;
  exec cat /dev/fd/$o1 /dev/fd/$o2 - &lt;&amp;p {i1}&gt;&amp;- {i2}&gt;&amp;-
)
printf '%s\n' foo bar | f
</code>, <code>{o1}&lt;&amp;p</code>, <code>exec cat</code>, <code>ksh</code>, <code>ksh93</code>, <code>f() (
  tr a b |&amp;
  exec {o1}&lt;&amp;p {i1}&gt;&amp;p
  sed 's/./&amp;&amp;/g' |&amp;
  exec {o2}&lt;&amp;p {i2}&gt;&amp;p
  cut -c2- |&amp;
  exec {o3}&lt;&amp;p {i3}&gt;&amp;p
  eval 'tee ""/dev/fd/$i1"" ""/dev/fd/$i2""' &gt;&amp;""$i3"" {i1}&gt;&amp;""$i1"" {i2}&gt;&amp;""$i2"" &amp;
  eval 'exec cat ""/dev/fd/$o1"" ""/dev/fd/$o2"" -' &lt;&amp;""$o3"" {o1}&lt;&amp;""$o1"" {o2}&lt;&amp;""$o2""
)
printf '%s\n' foo bar | f
</code>, <code>ksh</code>, <code>socketpairs</code>, <code>pipes</code>, <code>/dev/fd/n</code>, <code>ksh</code>, <code>2</code>, <code>zsh</code>, <code>{i1}&gt;&amp;$i1</code>, <code>eval</code>, <code>$i1</code>, <code>tee</code>, <code>cat</code>, <code>bash</code>, <code>f() {
  mkfifo p{i,o}{1,2,3}
  tr a b &lt; pi1 &gt; po1 &amp;
  sed 's/./&amp;&amp;/g' &lt; pi2 &gt; po2 &amp;
  cut -c2- &lt; pi3 &gt; po3 &amp;

  tee pi{1,2} &gt; pi3 &amp;
  cat po{1,2,3}
  rm -f p{i,o}{1,2,3}
}
printf '%s\n' foo bar | f
</code>, <code>expect</code>, <code>zsh</code>, <code>zpty</code>]"
101,https://unix.stackexchange.com/questions/20035/,How to add newlines into variables in bash script,"['In bash you can use the syntax', 'Single quotes preceded by a $ is a new syntax that allows to insert escape sequences in strings.', 'Also printf builtin allows to save the resulting output to a variable', 'Both solutions do not require a subshell.', 'If in the following you need to print the string, you should use double quotes, like in the following example:', 'because when you print the string without quotes, newline are converted to spaces.']","[<code>bash</code>, <code>str=$'Hello World\n===========\n'
</code>, <code>$</code>, <code>printf</code>, <code>printf -v str 'Hello World\n===========\n'
</code>, <code>echo ""$str""
</code>]"
102,https://unix.stackexchange.com/questions/42901/,How to do nothing forever in an elegant way?,"['In shells that support them (ksh, zsh, bash4), you can start program as a co-process.', 'That starts program in background with its input redirected from a pipe. The other end of the pipe is open to the shell.', 'Three benefits of that approach']","[<code>program</code>, <code>ksh</code>, <code>program &gt; output |&amp;</code>, <code>zsh</code>, <code>bash</code>, <code>coproc program &gt; output</code>, <code>program</code>, <code>pipe</code>, <code>program</code>, <code>wait</code>, <code>program</code>, <code>eof</code>]"
103,https://unix.stackexchange.com/questions/18899/,When would you use an additional file descriptor?,"[""Most commands have a single input channel (standard input, file descriptor 0) and a single output channel (standard output, file descriptor 1) or else operate on several files which they open by themselves (so you pass them a file name). (That's in addition from standard error (fd 2), which usually filters up all the way to the user.) It is however sometimes convenient to have a command that acts as a filter from several sources or to several targets. For example, here's a simple script that separates the odd-numbered lines in a file from the even-numbered ones"", ""Now suppose you want to apply a different filter to the odd-number lines and to the even-numbered lines (but not put them back together, that would be a different problem, not feasible from the shell in general). In the shell, you can only pipe a command's standard output to another command; to pipe another file descriptor, you need to redirect it to fd 1 first."", 'Another, simpler use case is filtering the error output of a command.', 'exec M>&N redirects a file descriptor to another one for the remainder of the script (or until another such command changes the file descriptors again). There is some overlap in functionality between exec M>&N and somecommand M>&N. The exec form is more powerful in that it does not have to be nested:', 'Other examples that may be of interest:', 'And for even more examples:', ' P.S. This is a surprising question coming from the author of the most upvoted post on the site that uses redirection through fd 3!']","[<code>while IFS= read -r line; do
  printf '%s\n' ""$line""
  if IFS= read -r line; then printf '%s\n' ""$line"" &gt;&amp;3; fi
done &gt;odd.txt 3&gt;even.txt
</code>, <code>{ while … done | odd-filter &gt;filtered-odd.txt; } 3&gt;&amp;1 | even-filter &gt;filtered-even.txt
</code>, <code>exec M&gt;&amp;N</code>, <code>exec M&gt;&amp;N</code>, <code>somecommand M&gt;&amp;N</code>, <code>exec</code>, <code>exec 8&lt;&amp;0 9&gt;&amp;1
exec &gt;output12
command1
exec &lt;input23
command2
exec &gt;&amp;9
command3
exec &lt;&amp;8
</code>, <code>io-redirection</code>, <code>file-descriptors</code>]"
104,https://unix.stackexchange.com/questions/4219/,How do I get bash completion for command aliases?,"['There is a great thread about this on the Ubuntu forums. Ole J proposes the following alias completion definition function:', 'Use it to define a completion function for your alias, then specify that function as a completer for the alias:', 'I prefer to use aliases for adding always-used arguments to existing programs. For instance, with grep, I always want to skip devices and binary files, so I make an alias for grep. For adding new commands such as grepbin, I use a shell script in my ~/bin folder. If that folder is in your path, it will get autocompleted.']","[<code>function make-completion-wrapper () {
  local function_name=""$2""
  local arg_count=$(($#-3))
  local comp_function_name=""$1""
  shift 2
  local function=""
    function $function_name {
      ((COMP_CWORD+=$arg_count))
      COMP_WORDS=( ""$@"" \${COMP_WORDS[@]:1} )
      ""$comp_function_name""
      return 0
    }""
  eval ""$function""
  echo $function_name
  echo ""$function""
}
</code>, <code>make-completion-wrapper _apt_get _apt_get_install apt-get install
complete -F _apt_get_install apt-inst
</code>, <code>grep</code>, <code>grep</code>, <code>grepbin</code>, <code>~/bin</code>]"
105,https://unix.stackexchange.com/questions/27054/,#!/bin/bash - no such file or directory,"['This kind of message is usually due to a bogus shebang line, either an extra carriage return at the end of the first line or a BOM at the beginning of it.', 'Run: ', 'and see how it ends.  ', 'This is wrong:', 'This is wrong too:', 'This is correct:', 'Use dos2unix (or sed, tr, awk, perl, python…) to fix your script if this is the issue.', 'Here is one that will remove both of a BOM and tailing CRs:', '\nNote that the shell you are using to run the script will slightly affect the error messages that are displayed.', 'Here are three scripts just showing their name (echo $0) and having the following respective shebang lines:', 'correctScript:', 'scriptWithBom:', 'scriptWithCRLF:', 'Under bash, running them will show these messages:', 'Running the bogus ones by explicitely calling the interpreter allows the CRLF script to run without any issue:', 'Here is the behavior observed under ksh:', 'and under dash:']","[<code>$ head -1 yourscript | od -c
</code>, <code>0000000   #   !   /   b   i   n   /   b   a   s   h  \r  \n
</code>, <code>0000000 357 273 277   #   !   /   b   i   n   /   b   a   s   h  \n
</code>, <code>0000000   #   !   /   b   i   n   /   b   a   s   h  \n
</code>, <code>dos2unix</code>, <code>sed</code>, <code>tr</code>, <code>awk</code>, <code>perl</code>, <code>python</code>, <code>sed -i '1s/^.*#//;s/\r$//' brokenScript
</code>, <code>echo $0</code>, <code>0000000   #   !   /   b   i   n   /   b   a   s   h  \n
</code>, <code>0000000 357 273 277   #   !   /   b   i   n   /   b   a   s   h  \n
</code>, <code>0000000   #   !   /   b   i   n   /   b   a   s   h  \r  \n
</code>, <code>$ ./correctScript
./correctScript
$ ./scriptWithCRLF
bash: ./scriptWithCRLF: /bin/bash^M: bad interpreter: No such file or directory
$ ./scriptWithBom
./scriptWithBom: line 1: #!/bin/bash: No such file or directory
./scriptWithBom
</code>, <code>$ bash ./scriptWithCRLF
./scriptWithCRLF
$ bash ./scriptWithBom
./scriptWithBom: line 1: #!/bin/bash: No such file or directory
./scriptWithBom
</code>, <code>ksh</code>, <code>$ ./scriptWithCRLF
ksh: ./scriptWithCRLF: not found [No such file or directory]
$ ./scriptWithBom
./scriptWithBom[1]: #!/bin/bash: not found [No such file or directory]
./scriptWithBom
</code>, <code>dash</code>, <code>$ ./scriptWithCRLF
dash: 2: ./scriptWithCRLF: not found
$ ./scriptWithBom
./scriptWithBom: 1: ./scriptWithBom: #!/bin/bash: not found
./scriptWithBom
</code>]"
106,https://unix.stackexchange.com/questions/198787/,Is there a way of reading the last element of an array with bash?,"['As of bash 4.2, you can just use a negative index ${myarray[-1]} to get the last element. You can do the same thing for the second-last, and so on; in Bash:', 'If the subscript used to reference an element of an indexed array\nevaluates to a number less than zero, it is interpreted as relative to\none greater than the maximum index of the array, so negative indices\ncount back from the end of the array, and an index of -1 refers to the\nlast element.', 'The same also works for assignment. When it says ""expression"" it really means an expression; you can write in any arithmetic expression there to compute the index, including one that computes using the length of the array ${#myarray[@]} explicitly like ${myarray[${#myarray[@]} - 1]} for earlier versions.']","[<code>${myarray[-1]}</code>, <code>${#myarray[@]}</code>, <code>${myarray[${#myarray[@]} - 1]}</code>]"
107,https://unix.stackexchange.com/questions/25903/,Awesome symbols and characters in a bash prompt,"[""You can use any printable character, bash doesn't mind. You'll probably want to configure your terminal to support Unicode (in the form of UTF-8)."", 'There are a lot of characters in Unicode, so here are a few tips to help you search through the Unicode charts:', 'P.S. On Shapecatcher, I got U+2234 THEREFORE for ∴, U+2192 RIGHTWARDS ARROW for →, U+263F MERCURY for ☿ and U+2605 BLACK STAR for ★.', ""In a bash script, up to bash 4.1, you can write a byte by its code point, but not a character. If you want to avoid non-ASCII characters to make your .bashrc resilient to file encoding changes, you'll need to enter the bytes corresponding to these characters in the UTF-8 encoding. You can see the hexidecimal values by running echo ∴ → ☿ ★ | hexdump -C in a UTF-8 terminal, e.g. ∴ is encoded by \\xe2\\x88\\xb4 in UTF-8."", ""Since bash 4.2, you can use \\u followed by 4 hexadecimal digits in a $'…' string.""]","[<code>Ǫ</code>, <code>ı</code>, <code>∉</code>, <code>∴</code>, <code>→</code>, <code>☿</code>, <code>★</code>, <code>.bashrc</code>, <code>echo ∴ → ☿ ★ | hexdump -C</code>, <code>∴</code>, <code>\xe2\x88\xb4</code>, <code>if [[ $LC_CTYPE =~ '\.[Uu][Tt][Ff]-?8' ]]; then
  PS1=$'\\[\e[31m\\]\xe2\x88\xb4\\[\e[0m\\]\n\xe2\x86\x92 \xe2\x98\xbf \\~ \\[\e[31m\\]\xe2\x98\x85 $? \\[\e[0m\\]'
fi
</code>, <code>\u</code>, <code>$'…'</code>, <code>  PS1=$'\\[\e[31m\\]\u2234\\[\e[0m\\]\n\u2192 \u263f \\~ \\[\e[31m\\]\u2605 $? \\[\e[0m\\]'
</code>]"
108,https://unix.stackexchange.com/questions/16024/,How can I assign the output of a command to a shell variable?,"['A shell assignment is a single word, with no space after the equal sign. So what you wrote assigns an empty value to thefile; furthermore, since the assignment is grouped with a command, it makes thefile an environment variable and the assignment is local to that particular command, i.e. only the call to ls sees the assigned value.', 'You want to capture the output of a command, so you need to use command substitution:', '(Some literature shows an alternate syntax thefile=`ls …`; the backquote syntax is equivalent to the dollar-parentheses syntax except that quoting inside backquotes is weird sometimes, so just use $(…).)', 'Other remarks about your script:', ""Rather than using grep to match screenshots, it's clearer to pass a wildcard to ls and use head to capture the first file:"", ""It's generally a bad idea to parse the output of ls. This could fail quite badly if you have file names with nonprintable characters. However, sorting files by date is difficult without ls, so it's an acceptable solution if you know you won't have unprintable characters or backslashes in file names."", 'Always use double quotes around variable substitutions, i.e. here write', 'Without double quotes, the value of the variable is reexpanded, which will cause trouble if it contains whitespace or other special characters.', ""If you have GNU find (in particular if you're running non-embedded Linux or Cygwin), there's another approach to finding the most recent file: have find list the files and their dates, and use sort and tail to extract the youngest file."", ""If you're willing to write this script in zsh instead of bash, there's a much easier way to catch the newest file, because zsh has glob qualifiers that permit wildcard matches not only on names but also on file metadata. The (om[1]) part after the pattern is the glob qualifiers; om sorts matches by increasing age (i.e. by modification time, newest first) and [1] extracts the first match only. The whole match needs to be in parentheses because it's technically an array, since globbing returns a list of files, even if the [1] means that in this particular case the list contains (at most) one file.""]","[<code>thefile</code>, <code>thefile</code>, <code>ls</code>, <code>thefile=$(ls -t -U | grep -m 1 ""Screen Shot"")
</code>, <code>thefile=`ls …`</code>, <code>$(…)</code>, <code>-t</code>, <code>-U</code>, <code>-t</code>, <code>grep</code>, <code>ls</code>, <code>head</code>, <code>thefile=$(ls -t *""Screen Shot""* | head -n 1)
</code>, <code>ls</code>, <code>ls</code>, <code>echo ""Most recent screenshot is: $thefile""
</code>, <code>set -e</code>, <code>find</code>, <code>sort</code>, <code>tail</code>, <code>thefile=$(find -maxdepth 1 -type f -name ""*Screen Shot*"" -printf ""%T@ %p"" |
          sort -k 1n | tail -n 1)
</code>, <code>(om[1])</code>, <code>om</code>, <code>[1]</code>, <code>[1]</code>, <code>#!/bin/zsh
set -e
cd ~/Desktop
thefile=(*""Screen Shot""*(om[1]))
echo ""Most recent screenshot is: $thefile""
</code>]"
109,https://unix.stackexchange.com/questions/231605/,Search for a previous command with the prefix I just typed,"['What you are looking for is CtrlR.', 'Type CtrlR and then type part of the command you want.  Bash will display the first matching command.  Keep typing CtrlR and bash will cycle through previous matching commands.', ""To search backwards in the history, type CtrlS instead.  (If CtrlS doesn't work that way for you, that likely means that you need to disable  XON/XOFF flow control: to do that, run stty -ixon.)"", 'This is documented under ""Searching"" in man bash.']","[<code>stty -ixon</code>, <code>man bash</code>]"
110,https://unix.stackexchange.com/questions/100801/,"Can I somehow add a ""&& prog2"" to an already running prog1?","[""You should be able to do this in the same shell you're in with the wait command:"", 'excerpt from Bash man page']","[<code>wait</code>, <code>$ sleep 30 &amp;
[1] 17440

$ wait 17440 &amp;&amp; echo hi

...30 seconds later...
[1]+  Done                    sleep 30
hi
</code>, <code>wait [n ...]
     Wait for each specified process and return its termination status. Each n 
     may be a process ID or a job specification; if a job spec is given,  all 
     processes  in that job's pipeline are waited for.  If n is not given, all 
     currently active child processes are waited for, and the return status is 
     zero.  If n specifies a non-existent process or job, the return status is 
     127.  Otherwise, the return status is the exit status of the last process 
     or job waited for.
</code>]"
111,https://unix.stackexchange.com/questions/72661/,Show sum of file sizes in directory listing,"[""The following function does most of what you're asking for:"", ""... but it won't give you what you're asking for from dir -R *.jpg *.tif, because that's not how ls -R works. You might want to play around with the find utility for that.""]","[<code>dir () { ls -FaGl ""${@}"" | awk '{ total += $4; print }; END { print total }'; }
</code>, <code>dir -R *.jpg *.tif</code>, <code>ls -R</code>, <code>find</code>]"
112,https://unix.stackexchange.com/questions/45684/,What is the difference between ~/.profile and ~/.bash_profile?,"['The .profile was the original profile configuration for the Bourne shell (a.k.a., sh). bash, being a Bourne compatible shell will read and use it. The .bash_profile on the other hand is only read by bash. It is intended for commands that are incompatible with the standard Bourne shell.']","[<code>.profile</code>, <code>sh</code>, <code>bash</code>, <code>.bash_profile</code>, <code>bash</code>]"
113,https://unix.stackexchange.com/questions/38172/,Are all bash scripts compatible with `zsh`?,"['If your scripts start with the line #!/bin/bash they will still be run using bash, even if your default shell is zsh.', ""I've found the syntax of zsh really close to the one of bash, and I did not pay attention if there was really some incompatibilities. I switched 6 years ago from bash to zsh seamlessly.""]",[<code>#!/bin/bash</code>]
114,https://unix.stackexchange.com/questions/129072/,What's the difference between $@ and $*,"[""They aren't the same.  $* is a single string, whereas $@ is an actual array.  To see the difference, execute the following script like so:"", 'The script:', 'The explanation and the results for the four cases are below.', 'In the first case, the parameters are regarded as one long quoted string:', 'Case 2 (unquoted) - the string is broken into words by the for loop:', 'Case 3 - it treats each element of $@ as a quoted string:', 'Last case - it treats each element as an unquoted string, so the last one is again split by  what amounts to for three four:']","[<code>$*</code>, <code>$@</code>, <code> &gt; ./test.sh one two ""three four""
</code>, <code>#!/bin/bash

echo ""Using \""\$*\"":""
for a in ""$*""; do
    echo $a;
done

echo -e ""\nUsing \$*:""
for a in $*; do
    echo $a;
done

echo -e ""\nUsing \""\$@\"":""
for a in ""$@""; do
    echo $a;
done

echo -e ""\nUsing \$@:""
for a in $@; do
    echo $a;
done              
</code>, <code>Using ""$*"":
one two three four
</code>, <code>for</code>, <code>Using $*:
one
two
three
four
</code>, <code>Using ""$@"":
one
two
three four
</code>, <code>for three four</code>, <code>Using $@:
one
two
three
four
</code>]"
115,https://unix.stackexchange.com/questions/212183/,How do I check if a variable exists in an 'if' statement?,"['In modern bash (version 4.2 and above):', 'From help test:', '-v VAR, True if the shell variable VAR is set']","[<code>[[ -v name_of_var ]]
</code>, <code>help test</code>]"
116,https://unix.stackexchange.com/questions/32409/,Set and Shopt - Why Two?,"[""As far as I know, the set -o options are the ones that are inherited from other Bourne-style shells (mostly ksh), and the shopt options are the ones that are specific to bash. There's no logic that I know of.""]","[<code>set -o</code>, <code>shopt</code>]"
117,https://unix.stackexchange.com/questions/96907/,How do I check if a file is a symbolic link to a directory?,['Just combine the two tests with &&:'],"[<code>&amp;&amp;</code>, <code>if [[ -L ""$file"" &amp;&amp; -d ""$file"" ]]
then
    echo ""$file is a symlink to a directory""
fi
</code>]"
118,https://unix.stackexchange.com/questions/55713/,Make cd follow symbolic links,"['With any POSIX implementation of cd, you can use the -P option to do this.', 'You can see it in action here:', 'If you want this to be the default behaviour, you can either create an alias for cd, like so:', '...or use set -o physical. For tcsh, the equivalent command is set symlinks=chase.']","[<code>cd</code>, <code>-P</code>, <code>$ help cd
...
    -P      use the physical directory structure without following symbolic links
...
</code>, <code>$ mkdir foo
$ ln -s foo bar
$ cd -P bar
$ pwd
/tmp/tmp.WkupF2Ucuh/foo
</code>, <code>cd</code>, <code>alias cd='cd -P'
</code>, <code>set -o physical</code>, <code>set symlinks=chase</code>]"
119,https://unix.stackexchange.com/questions/193039/,how to count the length of an array defined in bash?,"['You can access the array indices using ${!array[@]} and the length of the array using ${#array[@]}, e.g. :', 'Note that since bash arrays are zero indexed, you will actually get :', 'If you want the count to run from 1 you can replace $index by $((index+1)). If you want the values as well as the indices you can use ""${array[index]}"" i.e.', 'giving']","[<code>${!array[@]}</code>, <code>${#array[@]}</code>, <code>#!/bin/bash

array=( item1 item2 item3 )
for index in ${!array[@]}; do
    echo $index/${#array[@]}
done
</code>, <code>0/3
1/3
2/3
</code>, <code>$index</code>, <code>$((index+1))</code>, <code>""${array[index]}""</code>, <code>#!/bin/bash

array=( item1 item2 item3 )
for index in ${!array[@]}; do
    echo $((index+1))/${#array[@]} = ""${array[index]}""
done
</code>, <code>1/3 = item1
2/3 = item2
3/3 = item3
</code>]"
120,https://unix.stackexchange.com/questions/84310/,"How do I force yum to install without prompting the user, using bash?",['You can use the -y switch:'],"[<code>-y</code>, <code>$ yum -y install php54w
</code>, <code>-y, --assumeyes
      Assume yes; assume that the answer to any question which would be asked
      is yes. Configuration Option: assumeyes
</code>]"
121,https://unix.stackexchange.com/questions/126938/,Why is setting a variable before a command legal in bash?,"['Relevant information can be found on the man page provided by the BASH maintainer (last checked August 2020). Section Shell Grammar, Simple Commands states (emphasis added):', 'A simple command is a sequence of optional  variable  assignments  followed  by  blank-separated  words and redirections, and terminated by a control operator.  The first word specifies the command to be executed, and  is  passed  as  argument  zero.  The remaining words are passed as arguments to the invoked command.', ""So you can pass any variable you'd like. Your echo example does not work because the variables are passed to the command, not set in the shell. The shell expands $x and $y before invoking the command. This works, for example:""]","[<code>echo</code>, <code>$x</code>, <code>$y</code>, <code>$ x=""once upon"" y=""a time"" bash -c 'echo $x $y'
once upon a time
</code>]"
122,https://unix.stackexchange.com/questions/122681/,How can I tell whether a package is installed via yum in a bash script?,"[""I found the following on a semi-related StackOverflow question; the answer I needed didn't actually quite answer the question there (and was not selected as the correct answer) so I figured I'd post it here for others to find easier."", 'yum list installed PACKAGE_NAME', 'This command returns some human-readable output, but more importantly returns an exit status code; 0 indicates the package is installed, 1 indicates the package is not installed (does not check whether the package is valid, so yum list installed herpderp-beepbopboop will return a ""1"" just as yum list installed traceroute will if you don\'t have traceroute installed). You can subsequently check ""$?"" for this exit code. ', 'Since the output is somewhat counter-intuitive, I used @Chris Downs\' ""condensed"" version below in a wrapper function to make the output more ""logical"" (i.e. 1=installed 0=not installed):', 'usage would be', 'if isinstalled $package; then echo ""installed""; else echo ""not installed""; fi', 'Replaced return statements with calls to true and false which help make the function more readable/intuitive, while returning the values bash expects (i.e. 0 for true, 1 for false).', ""If you're just checking for one package in your script, you may just be better off testing yum list installed directly, but (IMHO) the function makes it easier to understand what's going on, and its syntax is much easier to remember than yum with all the redirects to supress its output.""]","[<code>yum list installed PACKAGE_NAME</code>, <code>yum list installed herpderp-beepbopboop</code>, <code>yum list installed traceroute</code>, <code>function isinstalled {
  if yum list installed ""$@"" &gt;/dev/null 2&gt;&amp;1; then
    true
  else
    false
  fi
}
</code>, <code>if isinstalled $package; then echo ""installed""; else echo ""not installed""; fi</code>, <code>return</code>, <code>true</code>, <code>false</code>, <code>yum list installed</code>, <code>yum</code>]"
123,https://unix.stackexchange.com/questions/167582/,Why ZSH ends a line with a highlighted percent symbol?,"['Yes, this happens because it is a ""partial line"". And by default zsh goes to the next line to avoid covering it with the prompt.', 'When a partial line is preserved, by default you will see an\n  inverse+bold character at the end of the partial line: a ""%"" for a\n  normal user or a ""#"" for root. If set, the shell parameter\n  PROMPT_EOL_MARK can be used to customize how the end of partial lines\n  are shown.']",[]
124,https://unix.stackexchange.com/questions/209123/,"Understanding ""IFS= read -r line""","[""In POSIX shells, read, without any option doesn't read a line, it reads words from a (possibly backslash-continued) line, where words are $IFS delimited and backslash can be used to escape the delimiters (or continue lines)."", 'The generic syntax is:', 'read reads stdin one byte at a time¹ until it finds an unescaped newline character (or end-of-input), splits that according to complex rules and stores the result of that splitting into $word1, $word2... $remaining_words.', 'For instance on an input like:', 'and with the default value of $IFS, read a b c would assign:', ""Now if passed only one argument, that doesn't become read line. It's still read remaining_words. Backslash processing is still done, IFS whitespace characters are still removed from the beginning and end."", 'The -r option removes the backslash processing. So that same command above with -r would instead assign', ""Now, for the splitting part, it's important to realise that there are two classes of characters for $IFS: the IFS whitespace characters (namely space and tab (and newline, though here that doesn't matter unless you use -d), which also happen to be in the default value of $IFS) and the others. The treatment for those two classes of characters is different."", 'With IFS=: (: being not an IFS whitespace character), an input like :foo::bar:: would be split into """", ""foo"", """", bar and """" (and an extra """" with some implementations though that doesn\'t matter except for read -a). While if we replace that : with space, the splitting is done into only foo and bar. That is leading and trailing ones are ignored, and sequences of them are treated like one. There are additional rules when whitespace and non-whitespace characters are combined in $IFS. Some implementations can add/remove the special treatment by doubling the characters in IFS (IFS=:: or IFS=\'  \').', ""So here, if we don't want the leading and trailing unescaped whitespace characters to be stripped, we need to remove those IFS white space characters from IFS."", ""Even with IFS-non-whitespace characters, if the input line contains one (and only one) of those characters and it's the last character in the line (like IFS=: read -r word on a input like foo:) with POSIX shells (not zsh nor some pdksh versions), that input is considered as one foo word because in those shells, the characters $IFS are considered as terminators, so word will contain foo, not foo:."", 'So, the canonical way to read one line of input with the read builtin is:', '(note that for most read implementations, that only works for text lines as the NUL character is not supported except in zsh).', 'Using var=value cmd syntax makes sure IFS is only set differently for the duration of that cmd command.', 'The read builtin was introduced by the Bourne shell and was already to read words, not lines. There are a few important differences with modern POSIX shells.', ""The Bourne shell's read didn't support a -r option (which was introduced by the Korn shell), so there's no way to disable backslash processing other than pre-processing the input with something like sed 's/\\\\/&&/g' there."", ""The Bourne shell didn't have that notion of two classes of characters (which again was introduced by ksh). In the Bourne shell all characters undergo the same treatment as IFS whitespace characters do in ksh, that is IFS=: read a b c on an input like foo::bar would assign bar to $b, not the empty string."", 'In the Bourne shell, with:', 'If cmd is a built-in (like read is), var remains set to value after cmd has finished. That\'s particularly critical with $IFS because in the Bourne shell, $IFS is used to split everything, not only the expansions. Also, if you remove the space character from $IFS in the Bourne shell, ""$@"" no longer works.', ""In the Bourne shell, redirecting a compound command causes it to run in a subshell (in the earliest versions, even things like read var < file or exec 3< file; read var <&3 didn't work), so it was rare in the Bourne shell to use read for anything but user input on the terminal (where that line continuation handling made sense)"", ""Some Unices (like HP/UX, there's also one in util-linux) still have a line command to read one line of input (that used to be a standard UNIX command up until the Single UNIX Specification version 2)."", ""That's basically the same as head -n 1 except that it reads one byte at a time to make sure it doesn't read more than one line. On those systems, you can do:"", ""Of course, that means spawning a new process, execute a command and read its output through a pipe, so a lot less efficient than ksh's IFS= read -r line, but still a lot more intuitive."", ""¹ though on seekable input, some implementations can revert to reading by blocks and seek-back afterwards as an optimisation. ksh93 goes even further and remembers what was read and uses it for the next read invocation, though that's currently broken""]","[<code>read</code>, <code>$IFS</code>, <code>read word1 word2... remaining_words
</code>, <code>read</code>, <code>$word1</code>, <code>$word2</code>, <code>$remaining_words</code>, <code>  &lt;tab&gt; foo bar\ baz   bl\ah   blah\
whatever whatever
</code>, <code>$IFS</code>, <code>read a b c</code>, <code>$a</code>, <code>foo</code>, <code>$b</code>, <code>bar baz</code>, <code>$c</code>, <code>blah   blahwhatever whatever</code>, <code>read line</code>, <code>read remaining_words</code>, <code>-r</code>, <code>-r</code>, <code>$a</code>, <code>foo</code>, <code>$b</code>, <code>bar\</code>, <code>$c</code>, <code>baz   bl\ah   blah\</code>, <code>$IFS</code>, <code>$IFS</code>, <code>IFS=:</code>, <code>:</code>, <code>:foo::bar::</code>, <code>""""</code>, <code>""foo""</code>, <code>""""</code>, <code>bar</code>, <code>""""</code>, <code>""""</code>, <code>read -a</code>, <code>:</code>, <code>foo</code>, <code>bar</code>, <code>$IFS</code>, <code>IFS=::</code>, <code>IFS='  '</code>, <code>IFS=: read -r word</code>, <code>foo:</code>, <code>zsh</code>, <code>pdksh</code>, <code>foo</code>, <code>$IFS</code>, <code>word</code>, <code>foo</code>, <code>foo:</code>, <code>read</code>, <code>IFS= read -r line
</code>, <code>read</code>, <code>zsh</code>, <code>var=value cmd</code>, <code>IFS</code>, <code>cmd</code>, <code>read</code>, <code>read</code>, <code>-r</code>, <code>sed 's/\\/&amp;&amp;/g'</code>, <code>IFS=: read a b c</code>, <code>foo::bar</code>, <code>bar</code>, <code>$b</code>, <code>var=value cmd
</code>, <code>cmd</code>, <code>read</code>, <code>var</code>, <code>value</code>, <code>cmd</code>, <code>$IFS</code>, <code>$IFS</code>, <code>$IFS</code>, <code>""$@""</code>, <code>read var &lt; file</code>, <code>exec 3&lt; file; read var &lt;&amp;3</code>, <code>read</code>, <code>util-linux</code>, <code>line</code>, <code>head -n 1</code>, <code>line=`line`
</code>, <code>IFS= read -r line</code>, <code>read</code>]"
125,https://unix.stackexchange.com/questions/43882/,What is the difference between sourcing ('.' or 'source') and executing a file in bash?,"['./test.sh runs test.sh as a separate program. It may happen to be a bash script, if the file test.sh starts with #!/bin/bash. But it could be something else altogether.', '. ./test.sh executes the code of the file test.sh inside the running instance of bash. It works as if the content file test.sh had been included textually instead of the . ./test.sh line. (Almost: there are a few details that differ, such as the value of $BASH_LINENO, and the behavior of the return builtin.)', 'source ./test.sh is identical to . ./test.sh in bash (in other shells, source may be slightly different or not exist altogether; . for inclusion is in the POSIX standard).', ""The most commonly visible difference between running a separate script with ./test.sh and including a script with the . builtin is that if the test.sh script sets some environment variables, with a separate process, only the environment of the child process is set, whereas with script inclusion, the environment of the sole shell process is set. If you add a line foo=bar in test.sh and echo $foo at the end of the calling script, you'll see the difference:""]","[<code>./test.sh</code>, <code>test.sh</code>, <code>test.sh</code>, <code>#!/bin/bash</code>, <code>. ./test.sh</code>, <code>test.sh</code>, <code>test.sh</code>, <code>. ./test.sh</code>, <code>$BASH_LINENO</code>, <code>return</code>, <code>source ./test.sh</code>, <code>. ./test.sh</code>, <code>source</code>, <code>.</code>, <code>./test.sh</code>, <code>.</code>, <code>test.sh</code>, <code>foo=bar</code>, <code>test.sh</code>, <code>echo $foo</code>, <code>$ cat test.sh
#!/bin/sh
foo=bar
$ ./test.sh
$ echo $foo

$ . ./test.sh
$ echo $foo
bar
</code>]"
126,https://unix.stackexchange.com/questions/128559/,"Solving ""mv: Argument list too long""?","['xargs is the tool for the job. That, or find with -exec … {} +. These tools run a command several times, with as many arguments as can be passed in one go.', ""Both methods are easier to carry out when the variable argument list is at the end, which isn't the case here: the final argument to mv is the destination. With GNU utilities (i.e. on non-embedded Linux or Cygwin), the -t option to mv is useful, to pass the destination first."", 'If the file names have no whitespace nor any of \\""\', then you can simply provide the file names as input to xargs (the echo command is a bash builtin, so it isn\'t subject to the command line length limit):', 'You can use the -0 option to xargs to use null-delimited input instead of the default quoted format.', 'Alternatively, you can generate the list of file names with find. To avoid recursing into subdirectories, use -type d -prune. Since no action is specified for the listed image files, only the other files are moved.', '(This includes dot files, unlike the shell wildcard methods.)', ""If you don't have GNU utilities, you can use an intermediate shell to get the arguments in the right order. This method works on all POSIX systems."", 'In zsh, you can load the mv builtin:', 'or if you prefer to let mv and other names keep referring to the external commands:', 'or with ksh-style globs:', 'Alternatively, using GNU mv and zargs:']","[<code>xargs</code>, <code>find</code>, <code>-exec … {} +</code>, <code>mv</code>, <code>-t</code>, <code>mv</code>, <code>\""'</code>, <code>xargs</code>, <code>echo</code>, <code>echo !(*.jpg|*.png|*.bmp) | xargs mv -t targetdir
</code>, <code>-0</code>, <code>xargs</code>, <code>printf '%s\0' !(*.jpg|*.png|*.bmp) | xargs -0 mv -t targetdir
</code>, <code>find</code>, <code>-type d -prune</code>, <code>find . -name . -o -type d -prune -o \
       -name '*.jpg' -o -name '*.png' -o -name '*.bmp' -o \
       -exec mv -t targetdir/ {} +
</code>, <code>find . -name . -o -type d -prune -o \
       -name '*.jpg' -o -name '*.png' -o -name '*.bmp' -o \
       -exec sh -c 'mv ""$@"" ""$0""' targetdir/ {} +
</code>, <code>mv</code>, <code>setopt extended_glob
zmodload zsh/files
mv -- ^*.(jpg|png|bmp) targetdir/
</code>, <code>mv</code>, <code>setopt extended_glob
zmodload -Fm zsh/files b:zf_\*
zf_mv -- ^*.(jpg|png|bmp) targetdir/
</code>, <code>setopt ksh_glob
zmodload -Fm zsh/files b:zf_\*
zf_mv -- !(*.jpg|*.png|*.bmp) targetdir/
</code>, <code>mv</code>, <code>zargs</code>, <code>autoload -U zargs
setopt extended_glob
zargs -- ./^*.(jpg|png|bmp) -- mv -t targetdir/
</code>]"
127,https://unix.stackexchange.com/questions/3284/,What is the bash shortcut to change to the previous directory?,"['The shortcut is -', 'Try cd -', 'If you want to use this in your prompt, you have to refer to it with ~-.', 'See the example:']","[<code>-</code>, <code>cd -</code>, <code>~-</code>, <code>[echox@kaffeesatz ~]$ cd /tmp
[echox@kaffeesatz tmp]$ ls
cron.iddS32  serverauth.CfIgeXuvka
[echox@kaffeesatz tmp]$ cd -
/home/echox
[echox@kaffeesatz ~]$ ls ~-
cron.iddS32  serverauth.CfIgeXuvka
</code>]"
128,https://unix.stackexchange.com/questions/45781/,"Shell script fails: Syntax error: ""("" unexpected","[""The script does not begin with a shebang line, so the system executes it with /bin/sh. On Ubuntu, /bin/sh is dash, a shell designed for fast startup and execution with only standard features. When dash reaches line 68, it sees a syntax error: that parenthesis doesn't mean anything to it in context."", ""Since dash (like all other shells) is an interpreter, it won't complain until the execution reaches the problematic line. So even if the script successfully started at some point in your testing, it would have aborted once line 68 was reached."", 'The shebang line must be the very first thing in the file. Since you use bash features, the first line of the file must be #!/bin/bash or #!/usr/bin/env bash.']","[<code>/bin/sh</code>, <code>/bin/sh</code>, <code>#!/bin/bash</code>, <code>#!/usr/bin/env bash</code>]"
129,https://unix.stackexchange.com/questions/166359/,How to grep the output of cURL?,"['curl writes the output to stderr, so redirect that and also suppress the progress:', 'The reason why curl writes the information to stderr is so you can do:\ncurl <url> | someprgram without that information clobbering the input of someprogram']","[<code>curl -v --silent https://google.com/ 2&gt;&amp;1 | grep expire
</code>, <code>curl</code>, <code>curl &lt;url&gt; | someprgram</code>, <code>someprogram</code>]"
130,https://unix.stackexchange.com/questions/1168/,how to glob every hidden file except current and parent directory,"['You can use the GLOBIGNORE variable to hide the . and .. directories. This does automatically also set the dotglob option, so * now matches both hidden and non-hidden files. You can again manually unset dotglob, though, this then gives the behavior you want.', 'See this example:']","[<code>GLOBIGNORE</code>, <code>.</code>, <code>..</code>, <code>dotglob</code>, <code>*</code>, <code>dotglob</code>, <code>$ ls -a
.  ..  a  .a  ..a
$ GLOBIGNORE="".:..""
$ shopt -u dotglob
$ echo * # all (only non-hidden)
a
$ echo .* # all (only hidden)
.a ..a
</code>]"
131,https://unix.stackexchange.com/questions/444946/,How can we run a command stored in a variable?,"[""This has been discussed in a number of questions on unix.SE, I'll try to collect all issues I can come up with here. References at the end."", ""The reason you face those problems is word splitting and the fact that quotes expanded from variables don't act as quotes, but are just ordinary characters."", 'The cases presented in the question:', 'The assignment here assigns the single string ls -l ""/tmp/test/my dir"" to abc:', 'Below, $abc is split on whitespace, and ls gets the three arguments -l, ""/tmp/test/my and dir"" (with a quote at the front of the second and another at the back of the third). The option works, but the path gets incorrectly processed:', 'Here, the expansion is quoted, so it\'s kept as a single word. The shell tries to find a program literally called ls -l ""/tmp/test/my dir"", spaces and quotes included.', 'And here, $abc is split, and only the first resulting word is taken as the argument to -c, so Bash just runs ls in the current directory. The other words are arguments to bash, and are used to fill $0, $1, etc.', 'With bash -c ""$abc"", and eval ""$abc"", there\'s an additional shell processing step, which does make the quotes work, but also causes all shell expansions to be processed again, so there\'s a risk of accidentally running e.g. a command substitution from user-provided data, unless you\'re very careful about quoting.', 'The two better ways to store a command are a) use a function instead, b) use an array variable (or the positional parameters).', 'Using a function:', ""Simply declare a function with the command inside, and run the function as if it were a command. Expansions in commands within the function are only processed when the command runs, not when it's defined, and you don't need to quote the individual commands."", 'Using an array:', 'Arrays allow creating multi-word variables where the individual words contain white space. Here, the individual words are stored as distinct array elements, and the ""${array[@]}"" expansion expands each element as separate shell words:', 'The syntax is slightly horrible, but arrays also allow you to build the command line piece-by-piece. For example:', 'or keep parts of the command line constant and use the array fill just a part of it, like options or filenames:', ""The downside of arrays is that they're not a standard feature, so plain POSIX shells (like dash, the default /bin/sh in Debian/Ubuntu) don't support them (but see below). Bash, ksh and zsh do, however, so it's likely your system has some shell that supports arrays."", 'Using ""$@""', 'In shells with no support for named arrays, one can still use the positional parameters (the pseudo-array ""$@"") to hold the arguments of a command.', 'The following should be portable script bits that do the equivalent of the code bits in the previous section. The array is replaced with ""$@"", the list of positional parameters.  Setting ""$@"" is done with set, and the double quotes around ""$@"" are important (these cause the elements of the list to be individually quoted).', 'First, simply storing a command with arguments in ""$@"" and running it:', 'Conditionally setting parts of the command line options for a command:', 'Only using ""$@"" for options and operands:', '(Of course, ""$@"" is usually filled with the arguments to the script itself, so you\'ll have to save them somewhere before re-purposing ""$@"".)', ""As eval introduces an additional level of quote and expansion processing, you need to be careful with user input.\nFor example, this works as long as the user doesn't type in any single quotes:"", ""But if they give the input '$(uname)'.txt, your script happily runs the command substitution."", ""A version with arrays is immune to that since the words are kept separate for the whole time, there's no quote or other processing for the contents of filename.""]","[<code>ls -l ""/tmp/test/my dir""</code>, <code>abc</code>, <code>$ abc='ls -l ""/tmp/test/my dir""'
</code>, <code>$abc</code>, <code>ls</code>, <code>-l</code>, <code>""/tmp/test/my</code>, <code>dir""</code>, <code>$ $abc
ls: cannot access '""/tmp/test/my': No such file or directory
ls: cannot access 'dir""': No such file or directory
</code>, <code>ls -l ""/tmp/test/my dir""</code>, <code>$ ""$abc""
bash: ls -l ""/tmp/test/my dir"": No such file or directory
</code>, <code>$abc</code>, <code>-c</code>, <code>ls</code>, <code>$0</code>, <code>$1</code>, <code>$ bash -c $abc
'my dir'
</code>, <code>bash -c ""$abc""</code>, <code>eval ""$abc""</code>, <code># define it
myls() {
    ls -l ""/tmp/test/my dir""
}

# run it
myls
</code>, <code>""${array[@]}""</code>, <code># define the array
mycmd=(ls -l ""/tmp/test/my dir"")

# run the command
""${mycmd[@]}""
</code>, <code>mycmd=(ls)               # initial command
if [ ""$want_detail"" = 1 ]; then
    mycmd+=(-l)          # optional flag
fi
mycmd+=(""$targetdir"")    # the filename

""${mycmd[@]}""
</code>, <code>options=(-x -v)
files=(file1 ""file name with whitespace"")
target=/somedir

transmutate ""${options[@]}"" ""${files[@]}"" ""$target""
</code>, <code>dash</code>, <code>/bin/sh</code>, <code>""$@""</code>, <code>""$@""</code>, <code>""$@""</code>, <code>""$@""</code>, <code>set</code>, <code>""$@""</code>, <code>""$@""</code>, <code>set -- ls -l ""/tmp/test/my dir""
""$@""
</code>, <code>set -- ls
if [ ""$want_detail"" = 1 ]; then
    set -- ""$@"" -l
fi
set -- ""$@"" ""$targetdir""

""$@""
</code>, <code>""$@""</code>, <code>set -- -x -v
set -- ""$@"" file1 ""file name with whitespace""
set -- ""$@"" /somedir

transmutate ""$@""
</code>, <code>""$@""</code>, <code>""$@""</code>, <code>eval</code>, <code>eval</code>, <code>read -r filename
cmd=""ls -l '$filename'""
eval ""$cmd"";
</code>, <code>'$(uname)'.txt</code>, <code>filename</code>, <code>read -r filename
cmd=(ls -ld -- ""$filename"")
""${cmd[@]}""
</code>]"
132,https://unix.stackexchange.com/questions/76481/,Can't indent heredoc to match code block's indentation,"['You can change the here-doc operator to <<-. You can then indent both the here-doc and the delimiter with tabs:', ""Note that you must use tabs, not spaces to indent the here-doc. This means the above example won't work copied (Stack Exchange replaces tabs with spaces). There can not be any quotes around the first EOF delimiter, else parameter expansion, command substitution, and arithmetic expansion are not in effect.""]","[<code>&lt;&lt;-</code>, <code>#! /bin/bash
cat &lt;&lt;-EOF
    indented
    EOF
echo Done
</code>, <code>EOF</code>]"
133,https://unix.stackexchange.com/questions/306940/,"What is the purpose of the ""do"" keyword in Bash for loops?","['Note that that syntax is inherited from the Bourne shell.', 'After the variable name, you can have either in to have the list of elements explicitly given, or do, to loop over the positional parameters.', 'Or', ""Having the do in both cases (even if it's not strictly  necessary in the first one) makes for a more consistent syntax. It's also consistent with the while/until loops where the do is necessary."", 'You need the do to tell where the list of condition commands end.', 'Note that the Bourne shell did not support for i; do. That syntax was also not POSIX until the 2016 edition of the standard (for i do has always been POSIX; see the related Austin group bug).', 'zsh has a few shorthand forms like:', 'Or support for more than one variable:', ""(though you can't use in or do as variable name in place of j above)."", 'Even if rarely documented, most Bourne-like shells (Bourne, ksh, bash, zsh, not ash nor yash) also support:', 'The Bourne shell, ksh and zsh (but not bash) also support:', 'While bash, ksh and zsh (but not the Bourne shell) support:', 'All (Bourne, bash, ksh, zsh) support:', 'ksh93, bash, zsh support:']","[<code>in</code>, <code>do</code>, <code>for i in 1 2 3
do
  echo ""$i""
done
</code>, <code>set 1 2 3
for i do
  echo ""$i""
done
</code>, <code>do</code>, <code>while</code>, <code>until</code>, <code>do</code>, <code>while
  cmd1
  cmd2
do
  cmd3
  cmd4
done
</code>, <code>do</code>, <code>for i; do</code>, <code>for i do</code>, <code>zsh</code>, <code>for i in 1 2 3; echo $i
for i (1 2 3) echo $i
for ((i=1;i&lt;=3;i++)) echo $i
</code>, <code>for i j (1 a 2 b) echo $i $j
</code>, <code>in</code>, <code>do</code>, <code>j</code>, <code>ash</code>, <code>yash</code>, <code>for i in 1 2 3; { echo ""$i"";}
</code>, <code>ksh</code>, <code>zsh</code>, <code>bash</code>, <code>for i { echo ""$i""; }
</code>, <code>bash</code>, <code>ksh</code>, <code>zsh</code>, <code>for i; { echo ""$i""; }
</code>, <code>bash</code>, <code>ksh</code>, <code>zsh</code>, <code>for i
{ echo ""$i"";}
</code>, <code>ksh93</code>, <code>bash</code>, <code>zsh</code>, <code>for ((i=1;i&lt;=3;i++)) { echo ""$i""; }
</code>]"
134,https://unix.stackexchange.com/questions/52800/,How to do an if statement from the result of an executed command,"['Use the bash [[ conditional construct and prefer the $(<command>) command substitution convention. Additionally, [[ prevents word splitting of variable values therefore there is no need to quote the command substitution bit..']","[<code>[[</code>, <code>$(</code>, <code>)</code>, <code>[[</code>, <code>if [[ $(netstat -lnp | grep ':8080') = *java* ]]; then
  echo ""Found a Tomcat!""
fi
</code>]"
135,https://unix.stackexchange.com/questions/48713/,"How can I remove duplicates in my .bash_history, preserving order?","['This command works like sort|uniq, but keeps the lines in place', 'Basically, prepends to each line its number.  After sort|uniq-ing, all lines are sorted back according to their original order (using the line number field) and the line number field is removed from the lines. ', 'This solution has the flaw that it is undefined which representative of a class of equal lines will make it in the output and therefore its position in the final output is undefined.  However, if the latest representative should be chosen you can sort the input by a second key:', 'For re-reading and writing back the history, you can use history -a and history -w respectively.']","[<code>sort|uniq</code>, <code>nl|sort -k 2|uniq -f 1|sort -n|cut -f 2
</code>, <code>sort|uniq</code>, <code>sort</code>, <code>nl|sort -k2 -k 1,1nr|uniq -f1|sort -n|cut -f2
</code>, <code>history -a</code>, <code>history -w</code>]"
136,https://unix.stackexchange.com/questions/179238/,grep inside less?,"['less has very powerful pattern matching.\xa0 From the man page:', '&pattern\n  Display only lines which match the pattern;\n  lines which do not match the pattern\n  are not displayed.\xa0 If pattern is empty\n  (if you type & immediately followed by ENTER),\n  any filtering is turned off, and all lines are displayed.\xa0\n  While filtering is in effect,\n  an ampersand is displayed at the beginning of the prompt,\n  as a reminder that some lines in the file may be hidden.', 'Certain characters are special as in the / command†:', ""^N or !\n  Display only lines which do NOT match the pattern.\n^R\n      Don't interpret regular expression metacharacters;\n  that is, do a simple textual comparison.\n  ____________\n† Certain characters are special\n  if entered at the beginning of the pattern;\n  they modify the type\xa0of search\n  rather than become part of the pattern.\n  "", '\u2001\u2001\u2001(Of course ^N and ^R represent Ctrl+N\nand Ctrl+R, respectively.)\u2001', ""So, for example, &dns will display only lines that match the pattern dns,\nand &!dns will filter out (exclude) those lines,\ndisplaying only lines that don't match the pattern."", 'It is noted in the description of the / command that', 'So', 'And the ! can invert any of the above.\xa0\nSo the command you would want to use for the example in your question is:', 'Also use /pattern and ?pattern\nto search (and n/N to go to next/previous).']","[<code>less</code>, <code>&amp;<i>pattern</i></code>, <code><i>pattern</i></code>, <code><i>pattern</i></code>, <code><i>pattern</i></code>, <code>&amp;</code>, <code>/</code>, <code>^N</code>, <code>!</code>, <code><i>pattern</i></code>, <code>^R</code>, <code><i>pattern</i></code>, <code><i>pattern</i></code>, <code>^N</code>, <code>^R</code>, <code>&amp;dns</code>, <code>dns</code>, <code>&amp;!dns</code>, <code>/</code>, <code><i>pattern</i></code>, <code>&amp;eth[01]</code>, <code>eth0</code>, <code>eth1</code>, <code>&amp;arp.*eth0</code>, <code>arp</code>, <code>eth0</code>, <code>&amp;arp|dns</code>, <code>arp</code>, <code>dns</code>, <code>!</code>, <code>&amp;!event text|something else|the other thing|foo|bar
</code>, <code>/<i>pattern</i></code>, <code>?<i>pattern</i></code>, <code>n</code>, <code>N</code>]"
137,https://unix.stackexchange.com/questions/47918/,How to grep a specific line _and_ the first line of a file?,"[""Normally you can't do this with grep but you can use other tools. AWK was already mentioned but you can also use sed, like this:"", 'Sed utility works on each line individually, running specified commands on each of them. You can have multiple commands, specifying several -e options. We can prepend each command with a range parameter that specifies if this command should be applied to specific line or not.', '""1p"" is a first command. It uses p command which normally prints all the lines. But we prepend it with a numerical value that specifies the range it should be applied to. Here, we use 1 which means first line. If you want to print more lines, you can use x,yp where x is first line to print, y is last line to print. For example to print first 3 lines, you would use 1,3p', 'Next command is d which normally deletes all the lines from buffer. Before this command we put yourpattern between two / characters. This is the other way (first was to specify which lines as we did with p command) of addressing lines that the command should be running at. This means the command will only work for the lines that match yourpattern. Except, we use ! character before d command which inverts its logic. So now it will remove all the lines that do not match specified pattern.', 'At the end, sed will print all the lines that are left in buffer. But we removed lines that do not match from the buffer so only matching lines will be printed.', 'To sum up: we print 1st line, then we delete all the lines that do not match our pattern from input. Rest of the lines are printed (so only lines that do match the pattern).', 'As mentioned in comments, there is a problem with this approach. If specified pattern matches also first line, it will be printed twice (once by p command and once because of a match). We can avoid this in two ways:', ""Adding 1d command after 1p. As I already mentioned, d command deletes lines from buffer and we specify it's range by number 1, which means it will only delete 1st line. So the command would be sed -e '1p' -e '1d' -e '/youpattern/!d'"", ""Using 1b command, instead of 1p. It's a trick. b command allows us to jump to other command specified by a label (this way some commands can be omitted). But if this label is not specified (as in our example) it just jumps to the end of commands, ignoring rest of the commands for our line. So in our case, last d command won't remove this line from buffer."", ""Some sed implementations can save you some typing by using semicolon to separate commands instead of using multiple -e options. So if you don't care about being portable the command would be ps aux | sed '1b;/syslog/!d'. It works at least in GNU sed and busybox implementations."", ""Here's, however, rather crazy way to do this with grep. It's definitely not optimal, I'm posting this just for learning purposes, but you may use it for example, if you don't have any other tool in your system:"", ""First, we use -n option to add line numbers before each line. We want to numerate all the lines we we are matching .* - anything, even empty line. As suggested in comments, we can also match '^', result is the same."", 'Then we are using extended regular expressions so we can use \\| special character which works as OR. So we match if the line starts with 1: (first line) or contains our pattern (in this case its syslog).', 'Now the problem is, we are getting this ugly line numbers in our output. If this is a problem, we can remove them with cut, like this:', ""-d option specifies delimiter, -f specifies fields (or columns) we want to print. So we want to cut each lines on every : character and print only 2nd and all subsequent columns. This effectively removes first column with it's delimiter and this is exactly what we need.""]","[<code>sed</code>, <code>sed -e '1p' -e '/youpattern/!d'
</code>, <code>-e</code>, <code>p</code>, <code>1</code>, <code>x,yp</code>, <code>x</code>, <code>y</code>, <code>1,3p</code>, <code>d</code>, <code>yourpattern</code>, <code>/</code>, <code>p</code>, <code>yourpattern</code>, <code>!</code>, <code>d</code>, <code>p</code>, <code>1d</code>, <code>1p</code>, <code>d</code>, <code>sed -e '1p' -e '1d' -e '/youpattern/!d'</code>, <code>1b</code>, <code>1p</code>, <code>b</code>, <code>d</code>, <code>ps aux | sed -e '1b' -e '/syslog/!d'
</code>, <code>sed</code>, <code>-e</code>, <code>ps aux | sed '1b;/syslog/!d'</code>, <code>GNU sed</code>, <code>busybox</code>, <code>ps aux | grep -n '.*' | grep -e '\(^1:\)\|syslog'
</code>, <code>-n</code>, <code>.*</code>, <code>\|</code>, <code>1:</code>, <code>syslog</code>, <code>cut</code>, <code>ps aux | grep -n '.*' | grep -e '\(^1:\)\|syslog' | cut -d ':' -f2-
</code>, <code>-d</code>, <code>-f</code>, <code>:</code>]"
138,https://unix.stackexchange.com/questions/75892/,keyserver timed out when trying to add a GPG public key,"[""This is usually caused by your firewall blocking the port 11371. You could unblock the port in your firewall. In case you don't have access to the firewall you could:"", 'Force it to use port 80 instead of 11371', 'Alternatively']","[<code>11371</code>, <code>80</code>, <code>11371</code>, <code>    gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 94558F59
</code>]"
139,https://unix.stackexchange.com/questions/27139/,"Script to change current directory (cd, pwd)","['It is an expected behavior. The script is run in a subshell, and cannot change the parent shell working directory. Its effects are lost when it finishes.', ""To change the current shell's directory permanently you should use the source command, also aliased simply as ., which runs a script in the current shell environment instead of a sub shell."", 'The following commands are identical:', 'or']","[<code>source</code>, <code>.</code>, <code>. script
</code>, <code>source script
</code>]"
140,https://unix.stackexchange.com/questions/93323/,List subdirectories only n level deep,"[""I'm on Fedora, and these voicepacks are in a slightly different location:"", 'You can just modify this like so:', 'Using ls in this manor is typically frowned upon because the output of ls is difficult to parse. Better to use the find command, like so:', 'This command works by producing a list of full paths to files that are exactly 2 levels deep with respect to this directory:', 'This list looks like this:', 'But we want the last part of these directories, the leaf node. So we can make use of basename to parse it out:', ""Putting it all together, we can make the find command pass each 2 level deep directory to the basename command. The notation basename {} is what is doing these basename conversions. Find calls it via it's -exec switch.""]","[<code>$ ls /usr/share/festival/lib/voices/*/ -1 | grep -vE ""/usr|^$""
kal_diphone
ked_diphone
nitech_us_awb_arctic_hts
nitech_us_bdl_arctic_hts
nitech_us_clb_arctic_hts
nitech_us_jmk_arctic_hts
nitech_us_rms_arctic_hts
nitech_us_slt_arctic_hts
</code>, <code>$ ls /usr/share/festival/voices/*/ -1 | grep -vE ""/usr|^$""
</code>, <code>ls</code>, <code>ls</code>, <code>find</code>, <code>$ find /usr/share/festival/lib/voices -maxdepth 2 -mindepth 2 \
    -type d -exec basename {} \;
nitech_us_awb_arctic_hts
nitech_us_bdl_arctic_hts
nitech_us_slt_arctic_hts
nitech_us_jmk_arctic_hts
nitech_us_clb_arctic_hts
nitech_us_rms_arctic_hts
ked_diphone
kal_diphone
</code>, <code>/usr/share/festival/lib/voices
</code>, <code>$ find /usr/share/festival/lib/voices -maxdepth 2 -mindepth 2 
/usr/share/festival/lib/voices/us/nitech_us_awb_arctic_hts
/usr/share/festival/lib/voices/us/nitech_us_bdl_arctic_hts
/usr/share/festival/lib/voices/us/nitech_us_slt_arctic_hts
/usr/share/festival/lib/voices/us/nitech_us_jmk_arctic_hts
/usr/share/festival/lib/voices/us/nitech_us_clb_arctic_hts
/usr/share/festival/lib/voices/us/nitech_us_rms_arctic_hts
/usr/share/festival/lib/voices/english/ked_diphone
/usr/share/festival/lib/voices/english/kal_diphon
</code>, <code>basename</code>, <code>$ basename /usr/share/festival/lib/voices/us/nitech_us_awb_arctic_hts
nitech_us_awb_arctic_hts
</code>, <code>find</code>, <code>basename</code>, <code>basename {}</code>, <code>-exec</code>]"
141,https://unix.stackexchange.com/questions/6094/,Is there any way to keep a command from being added to your history?,"['In ZSH:', ""First insert setopt HIST_IGNORE_SPACE to your ~/.zshrc. Now after you log in again, you can prefix any commands you don't want stored in the history with a space. Note that (unlike bash's option of the same name) the command lingers in the internal history until the next command is entered before it vanishes, allowing you to briefly reuse or edit the line."", ""From the user manual, the following 3 options can be used to say that certain lines shouldn't go into the history at all:""]","[<code>setopt HIST_IGNORE_SPACE</code>, <code>~/.zshrc</code>, <code>space</code>]"
142,https://unix.stackexchange.com/questions/207294/,Create symlink - overwrite if one exists,"['Please read the manual.', '$ man ln', '-n, --no-dereference\n  treat LINK_NAME as a normal file if it is a symbolic link to a\n  directory']","[<code>ln -sfn /new/target /path/to/symlink
</code>]"
143,https://unix.stackexchange.com/questions/11454/,What is the difference between a builtin command and one that is not?,"[""From your comments, you seem to be confused about exactly what a shell is.  The kernel is responsible for managing the system.  It's the part that actually loads and runs programs, accesses files, allocates memory, etc.  But the kernel has no user interface; you can only communicate with it by using another program as an intermediary."", 'A shell is a program that prints a prompt, reads a line of input from you, and then interprets it as one or more commands to manipulate files or run other programs.  Before the invention of the GUI, the shell was the primary user interface of an OS.  On MS-DOS, the shell was called command.com and few people ever tried to use a different one.  On Unix, however, there have long been multiple shells that users could pick from.', 'They can be divided into 3 types.  The Bourne-compatible shells use the syntax derived from the original Bourne shell.  C shells use the syntax from the original C shell.  Then there are nontraditional shells that invent their own syntax, or borrow one from some programming language, and are generally much less popular than the first two types.', ""A built-in command is simply a command that the shell carries out itself, instead of interpreting it as a request to load and run some other program.  This has two main effects.  First, it's usually faster, because loading and running a program takes time.  Of course, the longer the command takes to run, the less significant the load time is compared to the overall run time (because the load time is fairly constant)."", ""Secondly, a built-in command can affect the internal state of the shell. That's why commands like cd must be built-in, because an external program can't change the current directory of the shell.  Other commands, like echo, might be built-in for efficiency, but there's no intrinsic reason they can't be external commands."", ""Which commands are built-in depends on the shell that you're using.  You'll have to consult its documentation for a list (e.g., bash's built-in commands are listed in Chapter 4 of its manual).  The type command can tell you if a command is built-in (if your shell is POSIX-compatible), because POSIX requires that type be a built-in.  If which is not a built-in in your shell, then it probably won't know about your shell's built-ins, but will just look for external programs.""]","[<code>command.com</code>, <code>cd</code>, <code>echo</code>, <code>bash</code>, <code>type</code>, <code>type</code>, <code>which</code>]"
144,https://unix.stackexchange.com/questions/57940/,"""trap ... INT TERM EXIT"" really necessary?","[""The POSIX spec doesn't say much about the conditions resulting in executing the EXIT trap, only about what its environment must look like when it is executed."", ""In Busybox's ash shell, your trap-exit test does not echo 'TRAP' before exiting due to either SIGINT or SIGTERM. I would suspect there are other shells in existance that may not work that way as well.""]","[<code># /tmp/test.sh &amp; sleep 1; kill -INT %1
# 
[1]+  Interrupt                  /tmp/test.sh
# 
# 
# /tmp/test.sh &amp; sleep 1; kill -TERM %1
# 
[1]+  Terminated                 /tmp/test.sh
# 
</code>]"
145,https://unix.stackexchange.com/questions/30189/,"How can I make environment variables ""exported"" in a shell script stick around?","['You should source your script, with', 'or']","[<code>. ./script
</code>, <code>source ./script
</code>]"
146,https://unix.stackexchange.com/questions/55392/,"In bash, is it possible to use an integer variable in the loop control of a for loop?","['The reason for this is the order in which things occur in bash. Brace expansion occurs before variables are expanded. In order to accomplish your goal, you need to use C-style for loop:']","[<code>upperlim=10

for ((i=0; i&lt;=upperlim; i++)); do
   echo ""$i""
done
</code>]"
147,https://unix.stackexchange.com/questions/23227/,For loops in zsh and bash,"[""Several forms of complex commands such as loops have alternate forms in zsh. These forms are mostly inspired by the C shell, which was fairly common when zsh was young but has now disappeared. These alternate forms act exactly like the normal forms, they're just a different syntax. They're slightly shorter, but less clear."", 'The standard form for the for command is for x in 1 2 3; do echo $x; done, and the standard form for the while command is while test …; do somecommand; done. \nKsh, bash and zsh have an alternate form of for: for ((i = 0; i < 42; i++)); do somecommand; done, which mimics the for loops of languages like Pascal or C, to enumerate integers. Other exotic forms that exist in zsh are specific to zsh (but often inspired by csh).']","[<code>for</code>, <code>for x in 1 2 3; do echo $x; done</code>, <code>while</code>, <code>while test …; do somecommand; done</code>, <code>for</code>, <code>for ((i = 0; i &lt; 42; i++)); do somecommand; done</code>, <code>for</code>]"
148,https://unix.stackexchange.com/questions/373704/,How many shells deep I am?,"['When I read your question, my first thought was $SHLVL.\xa0\nThen I saw that you wanted to count vim levels\nin addition to shell levels.\xa0\nA simple way to do this is to define a shell function:', 'This will automatically and silently increment SHLVL\neach time you type a vim command.\xa0\nYou will need to do this for each variant of vi/vim that you ever use; e.g.,', 'The outer set of parentheses creates a subshell,\nso the manual change in the value of SHLVL\ndoesn’t contaminate the current (parent) shell environment.\xa0\nOf course the command keyword is there to prevent the functions\nfrom calling themselves (which would result in an infinite recursion loop).\xa0\nAnd of course you should put these definitions\ninto your .bashrc or other shell initialization file.', 'There’s a slight inefficiency in the above.\xa0\nIn some shells (bash being one), if you say', 'where cmdn is an external, executable program\n(i.e., not a built-in command), the shell keeps an extra process lying around,\njust to wait for cmdn to terminate.\xa0\nThis is (arguably) not necessary;\nthe advantages and disadvantages are debatable.\xa0\nIf you don’t mind tying up a bit of memory and a process slot\n(and to seeing one more shell process than you need when you do a ps),\nthen do the above and skip to the next section.\xa0\nDitto if you’re using a shell that doesn’t keep the extra process lying around.\xa0\nBut, if you want to avoid the extra process, a first thing to try is', 'The exec command is there to prevent the extra shell process from lingering.', 'But, there’s a gotcha.\xa0\nThe shell’s handling of SHLVL is somewhat intuitive:\nWhen the shell starts, it checks whether SHLVL is set.\xa0\nIf it’s not set (or set to something other than a number),\nthe shell sets it to\xa01.\xa0\nIf it is set (to a number), the shell adds\xa01 to it.', 'But, by this logic, if you say exec sh, your SHLVL should go up.\xa0\nBut that’s undesirable, because your real shell level hasn’t increased.\xa0\nThe shell handles this by subtracting one from SHLVL\nwhen you do an exec:', 'So', 'is a wash; it increments SHLVL only to decrement it again.\nYou might as well just say vim, without benefit of a function.', 'Note:\nAccording to Stéphane Chazelas (who knows everything),\n  some shells are smart enough not to do this if the exec is in a subshell.', 'To fix this, you would do', 'Then I saw that you wanted to count vim levels\nindependently of shell levels.\xa0\nWell, the exact same trick works (well, with a minor modification):', '(and so on for vi, view, etc.)\xa0\nThe export is necessary\nbecause VILVL isn’t defined as an environment variable by default.\xa0\nBut it doesn’t need to be part of the function;\nyou can just say export\u202fVILVL as a separate command (in your .bashrc).\xa0\nAnd, as discussed above, if the extra shell process isn’t an issue for you,\nyou can do command\u202fvim instead of exec\u202fvim, and leave SHLVL alone: ', 'Personal Preference:\n  You may want to rename VILVL to something like VIM_LEVEL.\xa0\n  When I look at “VILVL”, my eyes hurt;\n  they can’t tell whether it’s a misspelling of “vinyl”\n  or a malformed Roman numeral.', 'If you are using a shell that doesn’t support SHLVL (e.g., dash),\nyou can implement it yourself as long as the shell implements a startup file.\xa0\nJust do something like', 'in your .profile or applicable file.\xa0\n(You should probably not use the name SHLVL, as that will cause chaos\nif you ever start using a shell that supports SHLVL.)', 'Other answers have addressed the issue\nof embedding environment variable value(s) into your shell prompt,\nso I won’t repeat that, especially you say you already know how to do it.']","[<code>$SHLVL</code>, <code>vim</code>, <code>vim()  { ( ((SHLVL++)); command vim  ""$@"");}
</code>, <code>SHLVL</code>, <code>vim</code>, <code>vi</code>, <code>vim</code>, <code>vi()   { ( ((SHLVL++)); command vi   ""$@"");}
view() { ( ((SHLVL++)); command view ""$@"");}
</code>, <code>SHLVL</code>, <code>command</code>, <code>.bashrc</code>, <code><i>cmd<sub>n</sub></i></code>, <code><i>cmd<sub>n</sub></i></code>, <code>ps</code>, <code>vim()  { ( ((SHLVL++)); exec vim  ""$@"");}
</code>, <code>exec</code>, <code>SHLVL</code>, <code>SHLVL</code>, <code>exec sh</code>, <code>SHLVL</code>, <code>SHLVL</code>, <code>exec</code>, <code>$ echo ""$SHLVL""
1

$ set | grep SHLVL
SHLVL=1

$ env | grep SHLVL
SHLVL=1

$ (env | grep SHLVL)
SHLVL=1

$ (env) | grep SHLVL
SHLVL=1

$ (exec env) | grep SHLVL
SHLVL=0
</code>, <code>vim()  { ( ((SHLVL++)); exec vim  ""$@"");}
</code>, <code>SHLVL</code>, <code>vim</code>, <code>exec</code>, <code>vim()  { ( ((SHLVL+=2)); exec vim  ""$@"");}
</code>, <code>vim</code>, <code>vim() { ( ((SHLVL++, VILVL++)); export VILVL; exec vim ""$@"");}
</code>, <code>vi</code>, <code>view</code>, <code>export</code>, <code>VILVL</code>, <code>export VILVL</code>, <code>.bashrc</code>, <code>command vim</code>, <code>exec vim</code>, <code>SHLVL</code>, <code>vim() { ( ((VILVL++)); command vim ""$@"");}
</code>, <code>VILVL</code>, <code>VIM_LEVEL</code>, <code>VILVL</code>, <code>SHLVL</code>, <code>if [ ""$SHELL_LEVEL"" = """" ]
then
    SHELL_LEVEL=1
else
    SHELL_LEVEL=$(expr ""$SHELL_LEVEL"" + 1)
fi
export SHELL_LEVEL
</code>, <code>.profile</code>, <code>SHLVL</code>, <code>SHLVL</code>]"
149,https://unix.stackexchange.com/questions/164025/,Exclude one pattern from glob match,"['This is ""foo."" followed by anything NOT ""org""', 'ref: https://www.gnu.org/software/bash/manual/bashref.html#Pattern-Matching']","[<code>shopt -s extglob
echo rm foo.!(org)
</code>]"
150,https://unix.stackexchange.com/questions/139089/,How to read first and last line from cat output?,"['sed Solution:', 'When reading from stdin if would look like this (for example ps -ef):', 'head & tail Solution:', 'When data is coming from a command (ps -ef):', 'awk Solution:', 'And also the piped example with ps -ef:']","[<code>sed -e 1b -e '$!d' file
</code>, <code>stdin</code>, <code>ps -ef</code>, <code>ps -ef | sed -e 1b -e '$!d'
UID        PID  PPID  C STIME TTY          TIME CMD
root      1931  1837  0 20:05 pts/0    00:00:00 sed -e 1b -e $!d
</code>, <code>(head -n1 &amp;&amp; tail -n1) &lt;file
</code>, <code>ps -ef</code>, <code>ps -ef 2&gt;&amp;1 | (head -n1 &amp;&amp; tail -n1)
UID        PID  PPID  C STIME TTY          TIME CMD
root      2068  1837  0 20:13 pts/0    00:00:00 -bash
</code>, <code>awk 'NR==1; END{print}' file
</code>, <code>ps -ef</code>, <code>ps -ef | awk 'NR==1; END{print}'
UID        PID  PPID  C STIME TTY          TIME CMD
root      1935  1837  0 20:07 pts/0    00:00:00 awk NR==1; END{print}
</code>]"
151,https://unix.stackexchange.com/questions/43527/,Kill all background jobs,"['To just kill all background jobs managed by bash, do', ""Note that since both jobs and kill are built into bash, you shouldn't run into any errors of the Argument list too long type.""]","[<code>kill</code>, <code>bash</code>, <code>kill $(jobs -p)
</code>, <code>jobs</code>, <code>kill</code>, <code>bash</code>]"
152,https://unix.stackexchange.com/questions/42728/,"What does ""3>&1 1>&2 2>&3"" do in a script?","['The numbers are file descriptors and only the first three (starting with zero) have a standardized meaning:', 'So each of these numbers in your command refer to a file descriptor. You can either redirect a file descriptor to a file with > or redirect it to another file descriptor with >&', 'The 3>&1 in your command line will create a new file descriptor and redirect it to 1 which is STDOUT.  Now 1>&2 will redirect the file descriptor 1 to STDERR and 2>&3 will redirect file descriptor 2 to 3 which is STDOUT.', 'So basically you switched STDOUT and STDERR, these are the steps:', 'Now if the program prints something to the file descriptor 1, it will be printed to the file descriptor 2 and vice versa.']","[<code>0 - stdin
1 - stdout
2 - stderr
</code>, <code>&gt;</code>, <code>&gt;&amp;</code>, <code>3&gt;&amp;1</code>, <code>1</code>, <code>STDOUT</code>, <code>1&gt;&amp;2</code>, <code>STDERR</code>, <code>2&gt;&amp;3</code>, <code>STDOUT</code>, <code>STDOUT</code>, <code>STDERR</code>]"
153,https://unix.stackexchange.com/questions/72864/,"How to avoid the need to issue ""y"" several times when removing protected file","['Edit based on updated question:', 'To avoid being asked about removing files, add the -f (""force"") option:', 'This has one side effect you should be aware of: If any of the given paths do not exist, it will not report this, and it will return successfully:', 'Original answer:', ""Here's one simple solution:"", 'yes repeats any string you give it infinitely, separated by newlines. head stops it after $number times, and tr translates the newlines to carriage returns. You might not see any output because of the carriage returns, but passing it to this command (in bash) should illustrate it:', 'Users without bash can pipe the result to od, hexdump or xxd to see the actual characters returned.']","[<code>-f</code>, <code>rm -f /path/to/file
</code>, <code>$ rm -f /nonexistent/path
$ echo $?
0
</code>, <code>yes ""$string"" | head -n $number | tr $'\n' $'\r'
</code>, <code>yes</code>, <code>head</code>, <code>$number</code>, <code>tr</code>, <code>bash</code>, <code>printf %q ""$(yes ""$string"" | head -n $number | tr $'\n' $'\r')""
</code>, <code>bash</code>, <code>od</code>, <code>hexdump</code>, <code>xxd</code>]"
154,https://unix.stackexchange.com/questions/40708/,"What is the difference between ~/.profile, ~/.bashrc, ~/.bash_profile, ~/.gnomerc, /etc/bash_bashrc, /etc/screenrc ...?","['The organization of configuration files is much less uniform than your questions seem to imply.  There is no ""class"", there is no ""hierarchy"", and there is no global ""configuration czar"" nor committee that decrees a common syntax or other nice clean generalizations like the ones you are seeking.  There is only a multitude of separate applications like R, bash, screen and the GNOME desktop environment, all of whom have their own ways of doing things, so you should look at the documentation for each  individual program to answer any specific questions about a particular file.  If it seems ad-hoc, that\'s because it is: most of Unix / Linux software out there was developed for different purposes by different people who all went about configuration slightly differently.', 'To answer your other questions pointwise:', '*rc and *profile do not mean very much, so this question can\'t really be answered.  ""rc"" is merely a commonly used abbreviation or suffix for configuration files.  Its etymology goes back to ancient times (in computer years), and probably means run commands (from runcom).  Just because applications use the same word does not mean they agree on conventions.  ""profile"" is a much less common suffix.', 'Define ""scope"".  Most applications do not share configuration files with other non-related applications.  The one possible exception is /etc/profile and .profile, which may be used by multiple different shells (including at least sh and bash).  There is something called an environment associated with every running process which can contain variables that may affect the behavior of said process.  Generally, environment variables are set by the appropriate shell configuration files, or perhaps the configuration files of whatever graphical desktop environment you are using.  There are also configuration files for ""libraries"", like .inputrc for readline and .gtkrc* for GTK, which will affect every application that uses the library.  ', 'No, there is no global hierarchy for configuration files.  Again, refer to the documentation for the specific program in question, for example, the bash manual for bash.  A general convention you can usually rely on is that user settings in $HOME override system-wide configuration in /etc.  This is typically accomplished by reading the user file after the system one, so that later settings overwrite earlier ones.  However, this is not a guarantee, and for definitive answers you should refer to the documentation for the specific program you are using.', 'There is no ""class"", at least none general enough to encompass all the files you\'ve listed in your question, so the question of a reference for such a ""class"" is moot.  Again, refer to the documentation of the specific program you are using.']","[<code>R</code>, <code>bash</code>, <code>screen</code>, <code>*rc</code>, <code>*profile</code>, <code>/etc/profile</code>, <code>.profile</code>, <code>sh</code>, <code>bash</code>, <code>.inputrc</code>, <code>.gtkrc*</code>, <code>bash</code>, <code>bash</code>, <code>$HOME</code>, <code>/etc</code>]"
155,https://unix.stackexchange.com/questions/28827/,Why is my bash prompt getting bugged when I browse the history?,"['Use \\[...\\] around the parts of PS1 that have length 0. It helps bash to get the length of the prompt right. Even with this measure, your command line can get spoiled when using multibyte characters (at least mine does). Hitting Ctrl+L also helps in such cases (but clears the screen at the same time).']",[<code>\[...\]</code>]
156,https://unix.stackexchange.com/questions/111508/,bash: test if $WORD is in set,"['This is a Bash-only (>= version 3) solution that uses regular expressions:', 'If your word list is long, you can store it in a file (one word per line) and do this:', 'One caveat with the file approach:', 'It will break if the file has whitespace. This can be remedied by something like:', 'Thanks to @terdon for reminding me to properly anchor the pattern with ^ and $.']","[<code>if [[ ""$WORD"" =~ ^(cat|dog|horse)$ ]]; then
    echo ""$WORD is in the list""
else
    echo ""$WORD is not in the list""
fi
</code>, <code>if [[ ""$WORD"" =~ $(echo ^\($(paste -sd'|' /your/file)\)$) ]]; then
    echo ""$WORD is in the list""
else
    echo ""$WORD is not in the list""
fi
</code>, <code>sed 's/[[:blank:]]//g' /your/file | paste -sd '|' /dev/stdin
</code>, <code>^</code>, <code>$</code>]"
157,https://unix.stackexchange.com/questions/136351/,Autocomplete server names for SSH and SCP,"['Found it!!', 'It seems that in Ubuntu the entries in ~/.ssh/known_hosts are hashed, so SSH completion cannot read them. This is a feature, not a bug. Even by adding HashKnownHosts no to ~/.ssh/config and /etc/ssh/ssh_config I was unable to prevent the host hashing.', 'However, the hosts that I am interested in are also found in ~/.ssh/config. Here is a script for Bash Completion that reads the entries from that file:', 'Put that script in /etc/bash_completion.d/ssh and then source it with the following command:', 'I found this guide invaluable and I would not have been able to script this without it. Thank you Steve Kemp  for writing that terrific guide!']","[<code>~/.ssh/known_hosts</code>, <code>HashKnownHosts no</code>, <code>~/.ssh/config</code>, <code>/etc/ssh/ssh_config</code>, <code>~/.ssh/config</code>, <code>_ssh() 
{
    local cur prev opts
    COMPREPLY=()
    cur=""${COMP_WORDS[COMP_CWORD]}""
    prev=""${COMP_WORDS[COMP_CWORD-1]}""
    opts=$(grep '^Host' ~/.ssh/config ~/.ssh/config.d/* 2&gt;/dev/null | grep -v '[?*]' | cut -d ' ' -f 2-)

    COMPREPLY=( $(compgen -W ""$opts"" -- ${cur}) )
    return 0
}
complete -F _ssh ssh
</code>, <code>/etc/bash_completion.d/ssh</code>, <code>$ . /etc/bash_completion.d/ssh
</code>]"
158,https://unix.stackexchange.com/questions/4079/,put history command onto command line without executing it,"['To request that the command be printed rather than executed after history substitution, add the :p modifier, e.g. !42:p. The resulting command will also be entered in the history, so you can press Up to edit it.', 'If you have the histverify option set (shopt -s histverify), you will always have the opportunity to edit the result of history substitutions.', 'The fc builtin gives limited access to history expansion (no word designators), and lets you edit a previous command in an external editor.', ""You can use !prefix to refer to the last command beginning with prefix, and !?substring to refer to the last command beginning with substring. When you know what you're looking for, this can save a lot of time over history | less."", ""Another way to search through previous history is incremental search: press Ctrl+R and start entering a substring of what you're looking for. Press Ctrl+R to go to the previous occurence of the search string so far and Ctrl+S if you've gone too far. Most keys other than Ctrl+R, Ctrl+S, Backspace and ordinary characters terminate the incremental search and have their usual effect (e.g. arrow keys to move the cursor in the line you've reached, Enter to run the command).""]","[<code>:p</code>, <code>!42:p</code>, <code>histverify</code>, <code>shopt -s histverify</code>, <code>fc</code>, <code>!prefix</code>, <code>prefix</code>, <code>!?substring</code>, <code>substring</code>, <code>history | less</code>]"
159,https://unix.stackexchange.com/questions/257571/,Why does bashrc check whether the current shell is interactive?,"['This is a question that I was going to post here a few weeks ago. Like terdon, I understood that a .bashrc is only sourced for interactive Bash shells so there should be no need for .bashrc to check if it is running in an interactive shell. Confusingly, all the distributions I use (Ubuntu, RHEL and Cygwin) had some type of check (testing $- or $PS1) to ensure the current shell is interactive.  I don’t like cargo cult programming so I set about understanding the purpose of this code in my .bashrc.', 'After researching the issue, I discovered that remote shells are treated differently. While non-interactive Bash shells don’t normally run ~/.bashrc commands at start-up, a special case is made when the shell is Invoked by remote shell daemon:', 'Bash attempts to determine when it is being run with its standard input\n  connected to a network connection, as when executed by the remote shell\n  daemon, usually rshd, or the secure shell daemon sshd. If Bash\n  determines it is being run in this fashion, it reads and executes commands\n  from ~/.bashrc, if that file exists and is readable. It will not do this if\n  invoked as sh.  The --norc option may be used to inhibit this behavior,\n  and the --rcfile option may be used to force another file to be read, but\n  neither rshd nor sshd generally invoke the shell with those options or\n  allow them to be specified.', 'Insert the following at the start of a remote .bashrc. (If .bashrc is sourced by .profile or .bash_profile, temporarily disable this while testing):', 'Run the following commands locally:', 'Shell functions defined in the remote .bashrc can also be run:', 'I noticed that the ~/.bashrc is only sourced when a command is specified as the argument for ssh. This makes sense: when ssh is used to start a regular login shell, .profile or .bash_profile are run (and .bashrc is only sourced if explicitly done so by one of these files).', 'The main benefit I can see to having .bashrc sourced when running a (non-interactive) remote command is that shell functions can be run. However, most of the commands in a typical .bashrc are only relevant in an interactive shell, e.g., aliases aren’t expanded unless the shell is interactive.', 'This isn’t usually a problem when rsh or ssh are used to start an interactive login shell or when non-interactive shells are used to run commands. However, it can be a problem for programs such as rcp, scp and sftp that use remote shells for transferring data.', 'It turns out that the remote user’s default shell (like Bash) is implicitly started when using the scp command. There’s no mention of this in the man page – only a mention that scp uses ssh for its data transfer.  This has the consequence that if the .bashrc contains any commands that print to standard output, file transfers will fail, e.g, \nscp fails without error.', ""See also this related Red Hat bug report from 15 years ago, scp breaks when there's an echo command in /etc/bashrc (which was eventually closed as WONTFIX)."", 'SCP (Secure copy) and SFTP (Secure File Transfer Protocol) have their own protocols for the local and remote ends to exchange information about the file(s) being transferred. Any unexpected text from the remote end is (wrongly) interpreted as part of the protocol and the transfer fails.  According to a FAQ from the Snail Book', 'What often happens, though, is that there are statements in either the\n  system or per-user shell startup files on the server (.bashrc, .profile,\n  /etc/csh.cshrc, .login, etc.) which output text messages on login,\n  intended to be read by humans (like fortune, echo ""Hi there!"", etc.).', ""Such code should only produce output on interactive logins, when there is a\n  tty attached to standard input. If it does not make this test, it will\n  insert these text messages where they don't belong: in this case, polluting\n  the protocol stream between scp2/sftp and sftp-server."", 'The reason the shell startup files are relevant at all, is that sshd\n  employs the user\'s shell when starting any programs on the user\'s behalf\n  (using e.g.  /bin/sh -c ""command""). This is a Unix tradition, and has\n  advantages:', 'For those interested in the details of how SCP works, I found interesting information in How the SCP protocol works which includes details on Running scp with talkative shell profiles on the remote side?:', 'For example, this can happen if you add this to your shell profile on the\n  remote system:', 'echo """"', ""Why it just hangs? That comes from the way how scp in source mode\n  waits for the confirmation of the first protocol message. If it's not binary\n  0, it expects that it's a notification of a remote problem and waits for\n  more characters to form an error message until the new line arrives. Since\n  you didn't print another new line after the first one, your local scp just\n  stays in a loop, blocked on read(2). In the meantime, after the shell\n  profile was processed on the remote side, scp in sink mode was started,\n  which also blocks on read(2), waiting for a binary zero denoting the start\n  of the data transfer."", 'Most of the statements in a typical .bashrc are only useful for an interactive shell – not when running remote commands with rsh or ssh. In most such situations, setting shell variables, aliases and defining functions isn’t desired – and printing any text to standard out is actively harmful if transferring files using programs such as scp or sftp. Exiting after verifying that the current shell is non-interactive is the safest behaviour for .bashrc.']","[<code>.bashrc</code>, <code>.bashrc</code>, <code>$-</code>, <code>$PS1</code>, <code>.bashrc</code>, <code>~/.bashrc</code>, <code>rshd</code>, <code>sshd</code>, <code>sh</code>, <code>--norc</code>, <code>--rcfile</code>, <code>rshd</code>, <code>sshd</code>, <code>.bashrc</code>, <code>.bashrc</code>, <code>.profile</code>, <code>.bash_profile</code>, <code>echo bashrc
fun()
{
    echo functions work
}
</code>, <code>$ ssh remote_host 'echo $- $0'
bashrc
hBc bash
</code>, <code>i</code>, <code>$-</code>, <code>-</code>, <code>$0</code>, <code>.bashrc</code>, <code>$ ssh remote_host fun
bashrc
functions work
</code>, <code>~/.bashrc</code>, <code>ssh</code>, <code>ssh</code>, <code>.profile</code>, <code>.bash_profile</code>, <code>.bashrc</code>, <code>.bashrc</code>, <code>.bashrc</code>, <code>rsh</code>, <code>ssh</code>, <code>rcp</code>, <code>scp</code>, <code>sftp</code>, <code>scp</code>, <code>scp</code>, <code>ssh</code>, <code>.bashrc</code>, <code>WONTFIX</code>, <code>scp</code>, <code>sftp</code>, <code>.bashrc</code>, <code>.profile</code>, <code>/etc/csh.cshrc</code>, <code>.login</code>, <code>fortune</code>, <code>echo ""Hi there!""</code>, <code>tty</code>, <code>scp2</code>, <code>sftp</code>, <code>sftp-server</code>, <code>sshd</code>, <code>scp</code>, <code>scp</code>, <code>read(2)</code>, <code>scp</code>, <code>read(2)</code>, <code>.bashrc</code>, <code>rsh</code>, <code>ssh</code>, <code>scp</code>, <code>sftp</code>, <code>.bashrc</code>]"
160,https://unix.stackexchange.com/questions/23452/,Set a network range in the no_proxy environment variable,"[""You're looking at it the wrong way. The no_proxy environment variable lists the domain suffixes, not the prefixes. From the documentation:"", 'no_proxy: This variable should contain a comma-separated list of domain extensions proxy should not be used for.', 'So for IPs, you have two options:', '1) Add each IP in full:', ""2) Rename wget to wget-original and write a wrapper script (called wget) that looks up the IP for the given URL's host, and determines if it should use the proxy or not:""]","[<code>no_proxy</code>, <code>no_proxy</code>, <code>printf -v no_proxy '%s,' 10.1.{1..255}.{1..255};
export no_proxy=""${no_proxy%,}"";
</code>, <code>wget</code>, <code>wget-original</code>, <code>wget</code>, <code>#!/bin/bash
ip='';
for arg; do
   # parse arg; if it's a URL, determine the IP address
done;
if [[ ""$ip"" =~ ^10\.1\. ]]; then
   wget-original --no-proxy ""$@"";
else
   wget-original ""$@"";
fi;
</code>]"
161,https://unix.stackexchange.com/questions/91684/,Use & (ampersand) in single line bash loop,['Drop the ; after &. This is a syntactic requirement'],"[<code>;</code>, <code>&amp;</code>, <code>for((i=114;i&lt;=255;i+=1)); do echo $i &gt; numbers.txt;python DoMyScript.py &amp; done
</code>]"
162,https://unix.stackexchange.com/questions/12068/,How to measure time of program execution and store that inside a variable,"['To get the output of time into a var use the following:', 'You can also just ask for a single time type, e.g. utime:', 'To get the time you can also use date +%s.%N, so take it before and after execution and calculate the diff:']","[<code>time</code>, <code>usr@srv $ mytime=""$(time ( ls ) 2&gt;&amp;1 1&gt;/dev/null )""
usr@srv $ echo ""$mytime""

real    0m0.006s
user    0m0.001s
sys     0m0.005s
</code>, <code>usr@srv $ utime=""$( TIMEFORMAT='%lU';time ( ls ) 2&gt;&amp;1 1&gt;/dev/null )""
usr@srv $ echo ""$utime""
0m0.000s
</code>, <code>date +%s.%N</code>, <code>START=$(date +%s.%N)
command
END=$(date +%s.%N)
DIFF=$(echo ""$END - $START"" | bc)
# echo $DIFF
</code>]"
163,https://unix.stackexchange.com/questions/67940/,"cron ignores variables defined in "".bashrc"" and "".bash_profile""","['You can source the file you want at the top of the script or beginning of the job for the user that is executing the job. The ""source"" command is a built-in. You\'d do the same thing if you made edits to those files to load the changes.', 'or']","[<code>* * * * * source /home/user/.bash_profile; &lt;command&gt;
</code>, <code>#!/bin/bash
source /home/user/.bash_profile

&lt;commands&gt;
</code>]"
164,https://unix.stackexchange.com/questions/313256/,Why write an entire bash script in functions?,"['I\'ve started using this same style of bash programming after reading Kfir Lavi\'s blog post ""Defensive Bash Programming"". He gives quite a few good reasons, but personally I find these the most important:', 'procedures become descriptive: it\'s much easier to figure out what a particular part of code is supposed to do.  Instead of wall of code, you see ""Oh, the find_log_errors function reads that log file for errors "". Compare it with finding whole lot of awk/grep/sed lines that use god knows what type of regex in the middle of a lengthy script - you\'ve no idea what\'s it doing there unless there\'s comments.', ""you can debug functions by enclosing into set -x and set +x. Once you know the rest of the code works alright , you can use this trick to focus on debugging only that specific function. Sure, you can enclose parts of script, but what if it's a lengthy portion ? It's easier to do something like this:"", ""printing usage with cat <<- EOF . . . EOF. I've used it quite a few times to make my code much more professional. In addition, parse_args() with getopts function is quite convenient. Again, this helps with readability, instead of shoving everything into script as giant wall of text. It's also convenient to reuse these."", ""And obviously, this is much more readable for someone who knows C or Java, or Vala, but has limited bash experience. As far as efficiency goes, there's not a lot of what you can do - bash itself isn't the most efficient language and people prefer perl and python when it comes to speed and efficiency. However, you can nice a function:"", 'Compared to calling nice on each and every line of code, this decreases whole lot of typing AND can be conveniently used when you want only a part of your script to run with lower priority.', 'Running functions in background, in my opinion, also helps when you want to have whole bunch of statements to run in background.', ""Some of the examples where I've used this style:""]","[<code>find_log_errors</code>, <code>set -x</code>, <code>set +x</code>, <code> set -x
 parse_process_list
 set +x
</code>, <code>cat &lt;&lt;- EOF . . . EOF</code>, <code>parse_args()</code>, <code>getopts</code>, <code>nice</code>, <code>nice -10 resource_hungry_function
</code>]"
165,https://unix.stackexchange.com/questions/88452/,Concatenating two variables with an underscore,"['You can use something like this:', 'This works as well:']","[<code>NAME=$(echo ${FILENAME}_${EXTENSION})
</code>, <code>NAME=${FILENAME}_${EXTENSION}
</code>]"
166,https://unix.stackexchange.com/questions/87605/,"Is there a way to make ""mv"" fail silently?",['Are you looking for this? '],"[<code>$ mv  file dir/
mv: cannot stat ‘file’: No such file or directory
$ mv  file dir/ 2&gt;/dev/null
# &lt;---- Silent -----&gt;
</code>]"
167,https://unix.stackexchange.com/questions/217905/,Restart bash from terminal without restarting the terminal application (mac)?,['exec bash should replace the current shell process with (a new instance of) bash.'],[<code>exec bash</code>]
168,https://unix.stackexchange.com/questions/23026/,How can I get bash to exit on backtick failure in a similar way to pipefail?,"['If you are running Bash 4.4 or later, you can use the shopt option inherit_errexit to do just that. You can check compatibility from within Bash using echo $BASH_VERSION.', 'Here is the shebang you would use if Bash 4.4 or later were installed and came before /bin in your $PATH:', 'The -S is there to coax Linux’s env into accepting more than one argument for bash, as kindly pointed out by @UVV and explained further on StackOverflow.', 'inherit_errexit is an option to shopt, while the rest of the arguments are options to set. In most modern iterations, they can be passed directly to bash when invoking the shell.', 'Let’s review the options you have already been using:', 'Now for the options I’ve added:']","[<code>shopt</code>, <code>inherit_errexit</code>, <code>echo $BASH_VERSION</code>, <code>/bin</code>, <code>$PATH</code>, <code>#!/usr/bin/env -S bash -euET -o pipefail -O inherit_errexit
</code>, <code>-S</code>, <code>env</code>, <code>bash</code>, <code>inherit_errexit</code>, <code>shopt</code>, <code>set</code>, <code>bash</code>, <code>-u</code>, <code>-o nounset</code>, <code>$IJUSTMADETHISUP</code>, <code>-e</code>, <code>-o errexit</code>, <code>-o pipefail</code>, <code>|</code>, <code>-O inherit_errexit</code>, <code>$(...)</code>, <code>-E</code>, <code>-o errtrace</code>, <code>-T</code>, <code>-o functrace</code>, <code>trap</code>, <code>ERR</code>, <code>DEBUG</code>, <code>RETURN</code>]"
169,https://unix.stackexchange.com/questions/157477/,how can shellshock be exploited over SSH?,"['One example where this can be exploited is on servers with an authorized_keys forced command. When adding an entry to ~/.ssh/authorized_keys, you can prefix the line with command=""foo"" to force foo to be run any time that ssh public key is used. With this exploit, if the target user\'s shell is set to bash, they can take advantage of the exploit to run things other than the command that they are forced to.', 'This would probably make more sense in example, so here is an example:', 'Here we set up a user testuser, that forces any ssh connections using your ssh key to run echo starting sleep; sleep 1.', 'We can test this with:', ""Notice how our echo something else doesn't get run, but the starting sleep shows that the forced command did run."", 'Now lets show how this exploit can be used:', 'This works because sshd sets the SSH_ORIGINAL_COMMAND environment variable to the command passed. So even though sshd ran sleep, and not the command I told it to, because of the exploit, my code still gets run.']","[<code>authorized_keys</code>, <code>~/.ssh/authorized_keys</code>, <code>command=""foo""</code>, <code>foo</code>, <code>bash</code>, <code>sudo useradd -d /testuser -s /bin/bash testuser
sudo mkdir -p /testuser/.ssh
sudo sh -c ""echo command=\\\""echo starting sleep; sleep 1\\\"" $(cat ~/.ssh/id_rsa.pub) &gt; /testuser/.ssh/authorized_keys""
sudo chown -R testuser /testuser
</code>, <code>testuser</code>, <code>echo starting sleep; sleep 1</code>, <code>$ ssh testuser@localhost echo something else
starting sleep
</code>, <code>echo something else</code>, <code>starting sleep</code>, <code>$ ssh testuser@localhost '() { :;}; echo MALICIOUS CODE'
MALICIOUS CODE
starting sleep
</code>, <code>sshd</code>, <code>SSH_ORIGINAL_COMMAND</code>, <code>sshd</code>, <code>sleep</code>]"
170,https://unix.stackexchange.com/questions/26695/,Refresh env variables after editing bashrc file,"['Within the same window, you can simply type bash to start a new one. This is equivalent to closing the window and re-opening a new one.', 'Alternatively, you can type source ~/.bashrc to source the .bashrc file.']","[<code>bash</code>, <code>source ~/.bashrc</code>, <code>.bashrc</code>]"
171,https://unix.stackexchange.com/questions/12439/,Can I configure my shell to print STDERR and STDOUT in different colors?,"['This is a harder version of Show only stderr on screen but write both stdout and stderr to file.', ""The applications running in the terminal use a single channel to communicate with it; the applications have two output ports, stdout and stderr, but they're both connected to the same channel."", 'You can connect one of them to a different channel, add color to that channel, and merge the two channels, but this will cause two problems:', ""In principle, it would be possible to write a program that listens on two ptys¹, synchronously (i.e. won't accept input on one channel while it's processing output on the other channel), and immediately outputs to the terminal with appropriate color changing instructions. You'd lose the ability to run programs that interact with the terminal. I don't know of any implementation of this method."", ""Another possible approach would be to cause the program to output the proper color changing sequences, by hooking around all the libc functions that call the write system call in a library loaded with LD_PRELOAD. See sickill's answer for an existing implementation, or Stéphane Chazelas's answer for a mixed approach that leverages strace."", ""In practice, if that's applicable, I suggest redirecting stderr to stdout and piping into a pattern-based colorizer such as colortail or multitail, or special-purpose colorizers such as colorgcc or colormake."", ""¹  pseudo-terminals. Pipes wouldn't work because of buffering: the source could write to the buffer, which would break the synchronicity with the colorizer. ""]","[<code>␛[31m</code>, <code>write</code>, <code>LD_PRELOAD</code>, <code>strace</code>]"
172,https://unix.stackexchange.com/questions/281309/,Shell Syntax: How to correctly use \ to break lines?,"[""If the statement would be correct without continuation, you need to use \\. Therefore, the following works without a backslash, as you can't end a command with a &&:"", 'Here, you need the backslash:', 'or', 'Otherwise, bash would execute the command right after processing the first line without waiting for the next one.']","[<code>\</code>, <code>&amp;&amp;</code>, <code>echo 1 &amp;&amp;
echo 2
</code>, <code>echo 1 2 3 \
4
</code>, <code>echo 1 \
&amp;&amp; echo 2
</code>]"
173,https://unix.stackexchange.com/questions/256149/,"What does ""esac"" mean at the end of a bash case statement? Is it required?","['Like fi for if and done for for, esac is the required way to end a case statement.', ""esac is case spelled backward, rather like fi is if spelled backward.  I don't know why the token ending a for block is not rof.""]","[<code>fi</code>, <code>if</code>, <code>done</code>, <code>for</code>, <code>esac</code>, <code>case</code>, <code>esac</code>, <code>case</code>, <code>fi</code>, <code>if</code>, <code>for</code>, <code>rof</code>]"
174,https://unix.stackexchange.com/questions/57590/,Appending a current date from a variable to a filename,"['More than likely it is your use of set.  That will assign \'today\', \'=\' and the output of the date program to positional parameters (aka command-line arguments).  You want to just use C shell (which you are tagging this as ""bash"", so likely not), you will want to use:', 'Notice the lack of spaces around the equal sign.', 'You also do not want to use & at the end of your statements; which causes the shell to not wait for the command to finish.  Especially when one relies on the next.  The find command could fail because it is started before the mkdir. ']","[<code>set</code>, <code>date</code>, <code>today=`date +%Y-%m-%d.%H:%M:%S` # or whatever pattern you desire
</code>, <code>&amp;</code>, <code>find</code>, <code>mkdir</code>]"
175,https://unix.stackexchange.com/questions/99185/,"What do square brackets mean without the ""if"" on the left?","['Square brackets are a shorthand notation for performing a conditional test. The brackets [, as well as [[ are actual commands within Unix, believe it or not.', 'Think:', 'In Bash the [ is a builtin command as well as an executable. [[ is just a keyword to Bash.', 'You can confirm this using type:', 'You can see the physical executable here:', ""If you take a look at the Bash man page, man bash, you'll find the following definitions for the 2:"", 'keywords - Reserved words are words that have a special meaning to the shell.  The following words are recognized as reserved when unquoted and either the first word of a  simple  command  (see  SHELL GRAMMAR below) or the third word of a case or for command:', 'builtins - If the command name contains no slashes, the shell attempts to locate it.  If there exists a shell function by that name, that function is invoked as described above in FUNCTIONS.   If  the name does not match a function, the shell searches for it in the list of shell builtins.  If a match is found, that builtin is invoked.', ""If the name is neither a shell function nor a builtin, and contains no slashes, bash searches each element of the PATH for a directory containing an executable file by that name.  Bash uses a hash table to remember the full pathnames of executable files (see hash under SHELL BUILTIN COMMANDS below).  A full search of the directories in PATH is performed only if the command  is not found in the hash table.  If the search is unsuccessful, the shell searches for a defined shell function named command_not_found_handle.  If that function exists, it is invoked with the original command and the original command's arguments as its arguments, and the function's exit status becomes the exit status of the shell.  If that function  is  not  defined,  the  shell prints an error message and returns an exit status of 127."", ""If you look through the Bash man page you'll find the details on it."", 'Lastly from the man page:', 'Follow-up question from the OP.', 'Ok, so why is there a need for an ""if"" then? I mean, why ""if"" even exists if ""["" would suffice.', 'The if is part of a conditional. The test command or [ ... ] command simply evaluate the conditional, and return a 0 or a 1. The 0 or 1 is then acted on by the if statement. The 2 are working together when you use them.']","[<code>[</code>, <code>[[</code>, <code>$ [ -f /etc/rc.local ] &amp;&amp; echo ""real file""
real file

-and-

$ test -f /etc/rc.local &amp;&amp; echo ""real file""
real file
</code>, <code>[</code>, <code>[[</code>, <code>type</code>, <code>$ type -a [
[ is a shell builtin
[ is /usr/bin/[

$ type -a [[
[[ is a shell keyword
</code>, <code>$ ls -l /usr/bin/[
-rwxr-xr-x 1 root root 37000 Nov  3  2010 /usr/bin/[
</code>, <code>man bash</code>, <code>! case  do done elif else esac fi for function if in select then until while { } time [[ ]]
</code>, <code>test expr
[ expr ]
          Return a status of 0 or 1 depending on the evaluation of the 
          conditional expression expr.  Each operator and operand must be
          a separate argument.  Expressions are composed of the  primaries 
          described  above  under  CONDITIONAL EXPRESSIONS.   test does not 
          accept any options, nor does it accept and ignore an argument of 
          -- as signifying the end of options.
</code>, <code>          test and [ evaluate conditional expressions using a set of rules
          based on the number of arguments.
</code>, <code>if</code>, <code>test</code>, <code>[ ... ]</code>, <code>if [ ... ]; then
   ... do this ...
else 
   ... do that ...
fi
</code>]"
176,https://unix.stackexchange.com/questions/50220/,Using OR patterns in shell wildcards,"[""You don't even need extended globbing enabled to do what you want.  This will work in bash:""]","[<code>ls {day*,night*}
</code>]"
177,https://unix.stackexchange.com/questions/180985/,How to copy files from the folder without the folder itself,"['advanced cp', 'This is especially great because it works no matter whether the target directory already exists.', 'shell globbing', 'If there are not too many objects in the directory then you can use shell globbing:', 'rsync', 'The / at the end of the source path is important; works no matter whether the target directory already exists.', 'find', ""or if you don't need empty subdirectories:"", '(without mkdir)']","[<code>cp -r /home/username/A/. /usr/lib/B/
</code>, <code>mkdir -p /usr/lib/B/
shopt -s dotglob
cp -r /home/username/A/* /usr/lib/B/
</code>, <code>rsync -a /home/username/A/ /usr/lib/B/
</code>, <code>/</code>, <code>mkdir -p /usr/lib/B/
find /home/username/A/ -mindepth 1 -maxdepth 1 -exec cp -r -t /usr/lib/B/ {} +
</code>, <code>find /home/username/A/ -mindepth 1 -type f -exec cp --parents -t /usr/lib/B/ {} +
</code>, <code>mkdir</code>]"
178,https://unix.stackexchange.com/questions/176997/,sudo as another user with their environment,"[""To invoke a login shell using sudo just use -i. When command is not specified you'll get a login shell prompt, otherwise you'll get the output of your command."", 'Example (login shell):', 'Example (with a specified user):', 'Example (with a command):', ""Example (print user's $HOME):"", ""Note: The backslash character ensures that the dollar sign reaches the target user's shell and is not interpreted in the calling user's shell."", ""I have just checked the last example with strace which tells you exactly what's happening. The output bellow shows that the shell is being called with --login and with the specified command, just as in your explicit call to bash, but in addition sudo can do its own work like setting the $HOME."", ""I noticed that you are using -S and I don't think it is generally a good technique. If you want to run commands as a different user without performing authentication from the keyboard, you might want to use SSH instead. It works for localhost as well as for other hosts and provides public key authentication that works without any interactive input."", ""Note: You don't need any special options with SSH as the SSH server always creates a login shell to be accessed by the SSH client.""]","[<code>sudo</code>, <code>-i</code>, <code>sudo -i
</code>, <code>sudo -i -u user
</code>, <code>sudo -i -u user whoami
</code>, <code>$HOME</code>, <code>sudo -i -u user echo \$HOME
</code>, <code>--login</code>, <code>$HOME</code>, <code># strace -f -e process sudo -S -i -u user echo \$HOME
execve(""/usr/bin/sudo"", [""sudo"", ""-S"", ""-i"", ""-u"", ""user"", ""echo"", ""$HOME""], [/* 42 vars */]) = 0
...
[pid 12270] execve(""/bin/bash"", [""-bash"", ""--login"", ""-c"", ""echo \\$HOME""], [/* 16 vars */]) = 0
...
</code>, <code>-S</code>, <code>localhost</code>, <code>ssh user@localhost echo \$HOME
</code>]"
179,https://unix.stackexchange.com/questions/4782/,How to pass the output of one command as the command-line argument to another?,"[""You can use backticks (`) to evaluate a command and substitute in the command's output, like:"", 'In your case:']","[<code>echo ""Number of files in this directory: `ls | wc -l`""
</code>, <code>wget `echo http://maps.google.be/maps?saddr\=$1\&amp;daddr\=$2 | sed 's/ /%/g'`
</code>]"
180,https://unix.stackexchange.com/questions/53310/,Splitting string by the first occurrence of a delimiter,"['cut sounds like a suitable tool for this:', 'But read is even more suitable:']","[<code>cut</code>, <code>bash-4.2$ s='id;some text here with possible ; inside'

bash-4.2$ id=""$( cut -d ';' -f 1 &lt;&lt;&lt; ""$s"" )""; echo ""$id""
id

bash-4.2$ string=""$( cut -d ';' -f 2- &lt;&lt;&lt; ""$s"" )""; echo ""$string""
some text here with possible ; inside
</code>, <code>read</code>, <code>bash-4.2$ IFS=';' read -r id string &lt;&lt;&lt; ""$s""

bash-4.2$ echo ""$id""
id

bash-4.2$ echo ""$string""
some text here with possible ; inside
</code>]"
181,https://unix.stackexchange.com/questions/30454/,Advantages of using set -o vi,"['By setting your readline editing to either emacs (the default) or vi (set -o vi) you are essentially standardizing your editing commands, across the shell and your editor of choice1.', 'Thus, if you want to edit a command in the shell you use the same commands2 that you would if you were in your text editor. This means only having to remember one command syntax and (if that were not advantage enough) would probably make your editing in both environments faster and less error prone...', 'You can further leverage this relationship in vi-mode by pulling up any command from your shell history, hitting Escape to enter command mode and then hitting v, which will open your $EDITOR with the command loaded for more complex editing with the full power of vim. Once you have finished editing the command to your satisfaction, :wq and the command is executed back in your shell.', '\n1. Assuming, of course, that you use Emacs or Vi/m as your editor.\n2. Or, more accurately, a subset thereof...']",[<code>set -o vi</code>]
182,https://unix.stackexchange.com/questions/330876/,"Difference between ""cd -"" and ""cd ~-""","['There are two things at play here. First, the - alone is expanded to your previous directory. This is explained in the cd section of man bash (emphasis mine):', 'An argument of - is converted to  $OLDPWD\n                before  the directory change is attempted.  If a non-empty directory name from CDPATH is used, or if - is the first\n  argument, and the directory change is successful, the absolute pathname of the new working directory is written to the \n  standard output.  The return value is true if the directory was successfully changed; false otherwise.', 'So, a simple cd - will move you back to your previous directory and print the directory\'s name out. The other command is documented in the ""Tilde Expansion"" section:', 'If  the  tilde-prefix  is  a  ~+, the value of the shell variable\n  PWD replaces the tilde-prefix.  If the tilde-prefix is a ~-, the\n  value of the  shell variable OLDPWD, if it is set, is substituted. \n  If the characters following the tilde in the tilde-prefix consist\n  of a  number  N,    optionally  prefixed  by  a  + or a -, the\n  tilde-prefix is replaced    with the corresponding element from the\n  directory stack, as it would be    displayed by the dirs builtin\n  invoked with the tilde-prefix as an argument.  If the characters\n  following the tilde in the  tilde-prefix  consist of a number\n  without a leading + or -, + is assumed.', 'This might be easier to understand with an example:', 'So, in general, the - means ""the previous directory"". That\'s why cd - by itself will move you back to wherever you were. ', 'The main difference is that cd - is specific to the cd builtin. If you try to echo - it will just print a -. The ~- is part of the tilde expansion functionality and behaves similarly to a variable. That\'s why you can echo ~- and get something meaningful. You can also use it in cd ~- but you could just as well use it in any other command. For example cp ~-/* . which would be equivalent to cp ""$OLDPWD""/* .']","[<code>-</code>, <code>cd</code>, <code>man bash</code>, <code>-</code>, <code>-</code>, <code>cd -</code>, <code>~+</code>, <code>~-</code>, <code>+</code>, <code>-</code>, <code>+</code>, <code>-</code>, <code>+</code>, <code>$ pwd
/home/terdon
$ cd ~/foo
$ pwd
/home/terdon/foo
$ cd /etc
$ pwd
/etc
$ echo ~        ## prints $HOME
/home/terdon
$ echo ~+       ## prints $PWD
/etc
$ echo ~-       ## prints $OLDPWD
/home/terdon/foo
</code>, <code>-</code>, <code>cd -</code>, <code>cd -</code>, <code>cd</code>, <code>echo -</code>, <code>-</code>, <code>~-</code>, <code>echo ~-</code>, <code>cd ~-</code>, <code>cp ~-/* .</code>, <code>cp ""$OLDPWD""/* .</code>]"
183,https://unix.stackexchange.com/questions/119894/,Single command to login to SSH and run program?,"['Have you tried ssh -t user@server ""mail && bash"" (or replace bash with whatever shell you like)?', 'The -t is necessary in order to create a pseudo-tty for bash to use as an interactive shell.']","[<code>ssh -t user@server ""mail &amp;&amp; bash""</code>, <code>bash</code>, <code>-t</code>]"
184,https://unix.stackexchange.com/questions/41693/,"How to copy some, but not all files?","['In bash you can use extglob:', 'where !(b*) exclude all b* files.', 'You can later disable extglob with']","[<code>bash</code>, <code>extglob</code>, <code> $ shopt -s extglob  # to enable extglob
 $ cp !(b*) new_dir/
</code>, <code>!(b*)</code>, <code>b*</code>, <code>extglob</code>, <code> $ shopt -u extglob
</code>]"
185,https://unix.stackexchange.com/questions/203371/,Run ./script.sh vs bash script.sh - permission denied,"[""It means you don't have the execute permission bit set for script.sh. When running bash script.sh, you only need read permission for script.sh.  See What is the difference between running “bash script.sh” and “./script.sh”? for more info."", 'You can verify this by running ls -l script.sh.', 'You may not even need to start a new Bash process. In many cases, you can simply run source script.sh or . script.sh to run the script commands in your current interactive shell. You would probably want to start a new Bash process if the script changes current directory or otherwise modifies the environment of the current process.', 'If the POSIX permission bits are set correctly, the Access Control List (ACL) may have been configured to prevent you or your group from executing the file.  E.g. the POSIX permissions would indicate that the test shell script is\nexecutable.', 'However, attempting to execute the file results in:', 'The getfacl command shows the reason why:', ""In this case, my primary group is domain users which has had execute permissions revoked by restricting the ACL with sudo setfacl -m 'g:domain\\040users:rw-' t.sh. This restriction can be lifted by either of the following commands:"", 'See:', 'Finally, the reason in this specific case for not being able to run the script is that the filesystem the script resides on was mounted with the noexec option. This option overrides POSIX permissions to prevent any file on that filesystem from being executed.', 'This can be checked by running mount to list all mounted filesystems; the mount options are listed in parentheses in the entry corresponding to the filesystem, e.g.', 'You can either move the script to another mounted filesystem or remount the filesystem allowing execution:', 'Note: I’ve used /tmp as an example here since there are good security reasons for keeping /tmp mounted with the noexec,nodev,nosuid set of options.']","[<code>script.sh</code>, <code>bash script.sh</code>, <code>script.sh</code>, <code>ls -l script.sh</code>, <code>source script.sh</code>, <code>. script.sh</code>, <code>$ ls -l t.sh
-rwxrwxrwx+ 1 root root 22 May 14 15:30 t.sh
</code>, <code>$ ./t.sh
bash: ./t.sh: Permission denied
</code>, <code>getfacl</code>, <code>$ getfacl t.sh
# file: t.sh
# owner: root
# group: root
user::rwx
group::r--
group:domain\040users:rw-
mask::rwx
other::rwx
</code>, <code>domain users</code>, <code>sudo setfacl -m 'g:domain\040users:rw-' t.sh</code>, <code>sudo setfacl -m 'g:domain\040users:rwx' t.sh
sudo setfacl -b t.sh
</code>, <code>noexec</code>, <code>mount</code>, <code>/dev/sda3 on /tmp type ext3 (rw,noexec)
</code>, <code>sudo mount -o remount,exec /dev/sda3 /tmp
</code>, <code>/tmp</code>, <code>/tmp</code>, <code>noexec,nodev,nosuid</code>]"
186,https://unix.stackexchange.com/questions/79571/,"Symbolic link recursion - what makes it ""reset""?","[""Patrice identified the source of the problem in his answer, but if you want to know how to get from there to why you get that, here's the long story."", ""The current working directory of a process is nothing you'd think too complicated. It is an attribute of the process which is a handle to a file of type directory where relative paths (in system calls made by the process) start from. When resolving a relative path, the kernel doesn't need to know the (a) full path to that current directory, it just reads the directory entries in that directory file to find the first component of the relative path (and .. is like any other file in that regard) and continues from there."", ""Now, as a user, you sometimes like to know where that directory lies in the directory tree. With most Unices, the directory tree is a tree, with no loop. That is, there's only one path from the root of the tree (/) to any given file. That path is generally called the canonical path."", 'To get the path of the current working directory, what a process has to do is just walk up (well down if you like to see a tree with its root at the bottom) the tree back to the root, finding the names of the nodes on the way.', ""For instance, a process trying to find out that its current directory is /a/b/c, would open the .. directory (relative path, so .. is the entry in the current directory) and look for a file of type directory with the same inode number as ., find out that c matches, then opens ../.. and so on until it finds /. There's no ambiguity there."", ""That's what the getwd() or getcwd() C functions do or at least used to do."", ""On some systems like modern Linux, there's a system call to return the canonical path to the current directory which does that lookup in kernel space (and allows you to find your current directory even if you don't have read access to all its components), and that's what getcwd() calls there. On modern Linux, you can also find the path to the current directory via a readlink() on /proc/self/cwd."", ""That's what most languages and early shells do when returning the path to the current directory."", ""In your case, you can call cd a as may times as you want, because it's a symlink to ., the current directory doesn't change so all of getcwd(), pwd -P, python -c 'import os; print os.getcwd()', perl -MPOSIX -le 'print getcwd' would return your ${HOME}."", 'Now, symlinks went complicating all that.', 'symlinks allow jumps in the directory tree. In /a/b/c, if /a or /a/b or /a/b/c is a symlink, then the canonical path of /a/b/c would be something completely different. In particular, the .. entry in /a/b/c is not necessarily /a/b.', 'In the Bourne shell, if you do:', 'Or even:', ""There's no guarantee you'll end up in /a/b."", 'Just like:', 'is not necessarily the same as:', 'ksh introduced a concept of a logical current working directory to somehow work around that. People got used to it and POSIX ended up specifying that behaviour which means most shells nowadays do it as well:', ""For the cd and pwd builtin commands (and only for them (though also for popd/pushd on shells that have them)), the shell maintains its own idea of the current working directory. It's stored in the $PWD special variable."", 'When you do:', 'even if c or c/d are symlinks, while $PWD containes /a/b, it appends c/d to the end so $PWD becomes /a/b/c/d. And when you do:', 'Instead of doing chdir(""../e""), it does chdir(""/a/b/c/e"").', 'And the pwd command only returns the content of the $PWD variable.', ""That's useful in interactive shells because pwd outputs a path to the current directory that gives information on how you got there and as long as you only use .. in arguments to cd and not other commands, it's less likely to surprise you, because cd a; cd .. or cd a/.. would generally get you back to where you were."", ""Now, $PWD is not modified unless you do a cd. Until the next time you call cd or pwd, a lot of things could happen, any of the components of $PWD could be renamed. The current directory never changes (it's always the same inode, though it could be deleted), but its path in the directory tree could change completely. getcwd() computes the current directory each time it's called by walking down the directory tree so its information is always accurate, but for the logical directory implemented by POSIX shells, the information in $PWD might become stale. So upon running cd or pwd, some shells may want to guard against that."", 'In that particular instance, you see different behaviours with different shells.', ""Some like ksh93 ignore the problem completely, so will return incorrect information even after you call cd (and you wouldn't see the behaviour that you're seeing with bash there)."", 'Some like bash or zsh do check that $PWD is still a path to the current directory upon cd, but not upon pwd.', 'pdksh does check upon both pwd and cd (but upon pwd, does not update $PWD)', 'ash (at least the one found on Debian) does not check, and when you do cd a, it actually does cd ""$PWD/a"", so if the current directory has changed and $PWD no longer points to the current directory, it will actually not change to the a directory in the current directory, but the one in $PWD (and return an error if it doesn\'t exist).', 'If you want to play with it, you can do:', 'in various shells.', ""In your case, since you're using bash, after a cd a, bash checks that $PWD still points to the current directory. To do that, it calls stat() on the value of $PWD to check its inode number and compare it with that of .."", 'But when the looking up of the $PWD path involves resolving too many symlinks, that stat() returns with an error, so the shell cannot check whether $PWD still corresponds to the current directory, so it computes it a again with getcwd() and updates $PWD accordingly.', ""Now, to clarify Patrice's answer, that check of number of symlinks encountered while looking up a path is to guard against symlink loops. The simplest loop can be made with"", ""Without that safe guard, upon a cd a/x, the system would have to find where a links to, finds it's b and is a symlink which links to a, and that would go on indefinitely. The simplest way to guard against that is to give up after resolving more than an arbitrary number of symlinks."", ""Now back to the logical current working directory and why it's not so good a feature. It's important to realise that it's only for cd in the shell and not other commands."", 'For instance:', 'is not always the same as:', ""That's why you'll sometimes find that people recommend to always use cd -P in scripts to avoid confusion (you don't want your software to handle an argument of ../x differently from other commands just because it's written in shell instead of another language)."", 'The -P option is to disable the logical directory handling so cd -P -- ""$var"" actually does call chdir() on the content of $var (at least as long as $CDPATH it not set, and except when $var is - (or possibly -2, +3... in some shells) but that\'s another story). And after a cd -P, $PWD will contain a canonical path.']","[<code>..</code>, <code>/</code>, <code>/a/b/c</code>, <code>..</code>, <code>..</code>, <code>.</code>, <code>c</code>, <code>../..</code>, <code>/</code>, <code>getwd()</code>, <code>getcwd()</code>, <code>getcwd()</code>, <code>/proc/self/cwd</code>, <code>cd a</code>, <code>.</code>, <code>getcwd()</code>, <code>pwd -P</code>, <code>python -c 'import os; print os.getcwd()'</code>, <code>perl -MPOSIX -le 'print getcwd'</code>, <code>${HOME}</code>, <code>symlinks</code>, <code>/a/b/c</code>, <code>/a</code>, <code>/a/b</code>, <code>/a/b/c</code>, <code>/a/b/c</code>, <code>..</code>, <code>/a/b/c</code>, <code>/a/b</code>, <code>cd /a/b/c
cd ..
</code>, <code>cd /a/b/c/..
</code>, <code>/a/b</code>, <code>vi /a/b/c/../d
</code>, <code>vi /a/b/d
</code>, <code>ksh</code>, <code>cd</code>, <code>pwd</code>, <code>popd</code>, <code>pushd</code>, <code>$PWD</code>, <code>cd c/d
</code>, <code>c</code>, <code>c/d</code>, <code>$PWD</code>, <code>/a/b</code>, <code>c/d</code>, <code>$PWD</code>, <code>/a/b/c/d</code>, <code>cd ../e
</code>, <code>chdir(""../e"")</code>, <code>chdir(""/a/b/c/e"")</code>, <code>pwd</code>, <code>$PWD</code>, <code>pwd</code>, <code>..</code>, <code>cd</code>, <code>cd a; cd ..</code>, <code>cd a/..</code>, <code>$PWD</code>, <code>cd</code>, <code>cd</code>, <code>pwd</code>, <code>$PWD</code>, <code>getcwd()</code>, <code>$PWD</code>, <code>cd</code>, <code>pwd</code>, <code>ksh93</code>, <code>cd</code>, <code>bash</code>, <code>bash</code>, <code>zsh</code>, <code>$PWD</code>, <code>cd</code>, <code>pwd</code>, <code>pwd</code>, <code>cd</code>, <code>pwd</code>, <code>$PWD</code>, <code>ash</code>, <code>cd a</code>, <code>cd ""$PWD/a""</code>, <code>$PWD</code>, <code>a</code>, <code>$PWD</code>, <code>cd
mkdir -p a/b
cd a
pwd
mv ~/a ~/b 
pwd
echo ""$PWD""
cd b
pwd; echo ""$PWD""; pwd -P # (and notice the bug in ksh93)
</code>, <code>bash</code>, <code>cd a</code>, <code>bash</code>, <code>$PWD</code>, <code>stat()</code>, <code>$PWD</code>, <code>.</code>, <code>$PWD</code>, <code>stat()</code>, <code>$PWD</code>, <code>getcwd()</code>, <code>$PWD</code>, <code>rm -f a b
ln -s a b
ln -s b a
</code>, <code>cd a/x</code>, <code>a</code>, <code>b</code>, <code>a</code>, <code>cd</code>, <code>cd -- ""$dir"" &amp;&amp;  vi -- ""$file""
</code>, <code>vi -- ""$dir/$file""
</code>, <code>cd -P</code>, <code>../x</code>, <code>-P</code>, <code>cd -P -- ""$var""</code>, <code>chdir()</code>, <code>$var</code>, <code>$CDPATH</code>, <code>$var</code>, <code>-</code>, <code>-2</code>, <code>+3</code>, <code>cd -P</code>, <code>$PWD</code>]"
187,https://unix.stackexchange.com/questions/48425/,How to stop the loop bash script in terminal?,"[""The program sl purposely ignores SIGINT, which is what gets sent when you press Ctrl+C.  So, firstly, you'll need to tell sl not to ignore SIGINT by adding the -e argument."", 'If you try this, you\'ll notice that you can stop each individual sl, but they still repeat.  You need to tell bash to exit after SIGINT as well.  You can do this by putting a trap ""exit"" INT before the loop. ']","[<code>sl</code>, <code>SIGINT</code>, <code>sl</code>, <code>SIGINT</code>, <code>-e</code>, <code>sl</code>, <code>bash</code>, <code>SIGINT</code>, <code>trap ""exit"" INT</code>, <code>#!/bin/bash
trap ""exit"" INT
while :
do
    sl -e
done
</code>]"
188,https://unix.stackexchange.com/questions/33049/,How to check if a pipe is empty and run a command on the data if it isn't?,"[""There's no way to peek at the content of a pipe using commonly available shell utilities, nor is there a way to read a character from the pipe then put it back. The only way to know that a pipe has data is to read a byte, and then you have to get that byte to its destination."", 'So do just that: read one byte; if you detect an end of file, then do what you want to do when the input is empty; if you do read a byte then fork what you want to do when the input is not empty, pipe that byte into it, and pipe the rest of the data.', ""The ifne utility from Joey Hess's moreutils runs a command if its input is not empty. It usually isn't installed by default, but it should be available or easy to build on most unix variants. If the input is empty, ifne does nothing and returns the status 0, which cannot be distinguished from the command running successfully. If you want to do something if the input is empty, you need to arrange for the command not to return 0, which can be done by having the success case return a distinguishable error status:"", ""test -t 0 has nothing to do with this; it tests whether standard input is a terminal. It doesn't say anything one way or the other as to whether any input is available.""]","[<code>first_byte=$(dd bs=1 count=1 2&gt;/dev/null | od -t o1 -A n | tr -dc 0-9)
if [ -z ""$first_byte"" ]; then
  # stuff to do if the input is empty
else
  {
    printf ""\\$first_byte""
    cat
  } | {
    # stuff to do if the input is not empty
  }      
fi
</code>, <code>ifne</code>, <code>ifne</code>, <code>ifne sh -c 'do_stuff_with_input &amp;&amp; exit 255'
case $? in
  0) echo empty;;
  255) echo success;;
  *) echo failure;;
esac
</code>, <code>test -t 0</code>]"
189,https://unix.stackexchange.com/questions/983/,"What features are in zsh and missing from bash, or vice versa?","[""There's already been quite a bit of activity on the topic on other Stack Exchange sites. My experience of switching from bash to zsh, as far as can remember (it was years ago²), is that I didn't miss a single thing. I gained a lot; here are what I think are the simple zsh-specific features that I use most:"", 'The zsh feature I most miss when I occasionally use bash is autocd: in zsh, executing a directory means changing to it, provided you turn on the autocd option.⁴', ""Another very useful feature is the fancy globbing. The hieroglyphscharacters are a bit hard to remember but extremely convenient (as in, it's often faster to look them up than to write the equivalent find command). A few of the simpler examples:\n\xa0\xa0\xa0\xa0foo*~*.bak = all matches for foo* except those matching *.bak\n\xa0\xa0\xa0\xa0foo*(.) = only regular files matching foo*\n\xa0\xa0\xa0\xa0foo*(/) = only directories matching foo*\n\xa0\xa0\xa0\xa0foo*(-@) = only dangling symbolic links matching foo*\n\xa0\xa0\xa0\xa0foo*(om[1,10]) = the 10 most recent files matching foo*\n\xa0\xa0\xa0\xa0foo*(Lm+1) = only files of size > 1MB\n\xa0\xa0\xa0\xa0dir/**/foo* = foo* in the directory dir and all its subdirectories, recursively⁴ "", ""For fancy renames, the zmv builtin can be handy. For example, to copy every file to file.bak: zmv -C '(*)(#q.)' '$1.bak'"", ""Both bash and zsh have a decent completion system that needs to be turned on explicitly (. /etc/bash_completion or autoload -U compinit; compinit). Zsh's is much more configurable and generally fancier."", 'If you run zsh without a .zshrc, it starts an interactive menu that lets you choose configuration options. (Some distributions may disable this; in that case, run autoload zsh-newuser-install; zsh-newuser-install.) I recommend enabling the recommended history options, turning on (“new-style”) completion, and turning on the “common shell options” except beep. Later, configure more options as you discover them.', ""²At the time programmable completion was zsh's killer feature, but bash acquired it soon after.\n⁴Features that bash acquired only in version 4 (so are still not available on many systems) are in smaller type.""]","[<code>autocd</code>, <code>find</code>, <code>foo*~*.bak</code>, <code>foo*</code>, <code>*.bak</code>, <code>foo*(.)</code>, <code>foo*</code>, <code>foo*(/)</code>, <code>foo*</code>, <code>foo*(-@)</code>, <code>foo*</code>, <code>foo*(om[1,10])</code>, <code>foo*</code>, <code>foo*(Lm+1)</code>, <code>dir/**/foo*</code>, <code>foo*</code>, <code>dir</code>, <code>zmv</code>, <code><em>file</em></code>, <code><em>file</em>.bak</code>, <code>zmv -C '(*)(#q.)' '$1.bak'</code>, <code>. /etc/bash_completion</code>, <code>autoload -U compinit; compinit</code>, <code>.zshrc</code>, <code>autoload zsh-newuser-install; zsh-newuser-install</code>, <code>beep</code>]"
190,https://unix.stackexchange.com/questions/84445/,Is there a way to cd back multiple times in bash?,"[""In zsh, there's an auto_pushd option. This option makes cd behave like pushd. Then you can just use popd to go back to previous directories."", 'In Bash, you can alias cd to pushd.', ""The one downside of this is that you will lose cd's three flags. From the cd help entry:"", '-L      force symbolic links to be followed\n  -P      use the physical directory structure without following symbolic links\n  -e      if the -P option is supplied, and the current working directory\n              cannot be determined successfully, exit with a non-zero status', 'If you ever have to use the actual cd builtin instead of the alias, you can use one of these:']","[<code>auto_pushd</code>, <code>cd</code>, <code>pushd</code>, <code>popd</code>, <code>~ $ setopt auto_pushd
~ $ cd /
/ $ cd /var
/var $ cd /usr
/usr $ dirs
/usr /var / ~
/usr $ popd
/var $ popd
/ $ popd
~ $
</code>, <code>cd</code>, <code>pushd</code>, <code>alias cd=pushd
</code>, <code>cd</code>, <code>cd</code>, <code>cd</code>, <code>'cd'</code>, <code>\cd</code>, <code>builtin cd</code>]"
191,https://unix.stackexchange.com/questions/10689/,How can I tell if I'm in a tmux session from a bash script?,"[""Tmux sets the TMUX environment variable in tmux sessions, and sets TERM to screen. This isn't a 100% reliable indicator (for example, you can't easily tell if you're running screen inside tmux or tmux inside screen), but it should be good enough in practice."", ""If you need to integrate that in a complex prompt set via PROMPT_COMMAND (which is a bash setting, by the way, so shouldn't be exported):"", 'If you ever need to test whether tmux is installed:', ""By the way, this should all go into ~/.bashrc, not ~/.bash_profile (see Difference between .bashrc and .bash_profile). ~/.bashrc is run in every bash instance and contains shell customizations such as prompts and aliases. ~/.bash_profile is run when you log in (if your login shell is bash). Oddly, bash doesn't read ~/.bashrc in login shells, so your ~/.bash_profile should contain""]","[<code>TMUX</code>, <code>TERM</code>, <code>screen</code>, <code>screen</code>, <code>tmux</code>, <code>tmux</code>, <code>screen</code>, <code>if ! { [ ""$TERM"" = ""screen"" ] &amp;&amp; [ -n ""$TMUX"" ]; } then
  PS1=""@$HOSTNAME $PS1""
fi
</code>, <code>PROMPT_COMMAND</code>, <code>if [ ""$TERM"" = ""screen"" ] &amp;&amp; [ -n ""$TMUX"" ]; then
  PS1_HOSTNAME=
else
  PS1_HOSTNAME=""@$HOSTNAME""
fi
PROMPT_COMMAND='PS1=""$PS1_HOSTNAME…""'
</code>, <code>if type tmux &gt;/dev/null 2&gt;/dev/null; then
  # you can start tmux if you want
fi
</code>, <code>~/.bashrc</code>, <code>~/.bash_profile</code>, <code>~/.bashrc</code>, <code>~/.bash_profile</code>, <code>~/.bashrc</code>, <code>~/.bash_profile</code>, <code>case $- in *i*) . ~/.bashrc;; esac
</code>]"
192,https://unix.stackexchange.com/questions/291404/,Why does Bash's source not need the execution bit?,"[""Bash is an interpreter; it accepts input and does whatever it wants to.  It doesn't need to heed the executable bit.  In fact, Bash is portable, and can run on operating systems and filesystems that don't have any concept of an executable bit."", 'What does care about the executable bit is the operating system kernel.  When the Linux kernel performs an exec, for example, it checks that the filesystem is not mounted with a noexec option, it checks the executable bit of the program file, and enforces any requirements imposed by security modules (such as SELinux or AppArmor).', ""Note that the executable bit is a rather discretionary kind of control.  On a Linux x86-64 system, for example, you can bypass the kernel's verification of the executable bit by explicitly invoking /lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 as the interpreter:"", 'This is somewhat analogous to sourcing Bash source code in Bash, except that ld.so is the interpreter, and the code that it executes is machine code in ELF format.']","[<code>exec</code>, <code>noexec</code>, <code>/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2</code>, <code>cp /bin/ls /tmp/
chmod -x /tmp/ls
/lib/x86_64-linux-gnu/ld-linux-x86-64.so.2 /tmp/ls
</code>, <code>ld.so</code>]"
193,https://unix.stackexchange.com/questions/105876/,"What does ""rm is hashed"" mean?","[""It's a performance thing; instead of searching the whole path for the binary every time it is called, it's put into a hash table for quicker lookup. So any binary that's already in this hash table, is hashed. If you move binaries around when they're already hashed, it will still try to call them in their old location."", 'See also help hash, or man bash and search for hash under builtin commands there.']","[<code>help hash</code>, <code>man bash</code>, <code>hash</code>]"
194,https://unix.stackexchange.com/questions/148035/,"Is dash or some other shell ""faster"" than bash?","[""Probably a useful means of bench-marking a shell's performance is to do a lot of very small, simple evaluations repetitively. It is important, I think, not just to loop, but to loop over input, because a shell needs to read <&0. "", ""I thought this would complement the tests @cuonglm already posted because it demonstrates a single shell process's performance once invoked, as opposed to his which demonstrates how quickly a shell process loads when invoked. In this way, between us, we cover both sides of the coin.  "", ""Here's a function to facilitate the demo:"", 'It either increments a variable once per newline read or, as a slight-optimization, if it can, it increments 50 times per newline read. Every time the variable is incremented it is printed to stdout. It behaves a lot like a sort of seq cross nl. ', ""And just to make it very clear what it does - here's some truncated set -x; output after inserting it just before time in the function above:"", 'So each shell is first called like:', '...to generate the input that it will need to loop over when it reads in 3<<\\SCRIPT - or when cat does, anyway. And on the other side of that |pipe it calls itself again like:', ""So aside from the initial call to env (because cat is actually called in the previous line); no other processes are invoked from the time it is called until it exits. At least, I hope that's true. "", 'I should make some notes on portability. ', ""posh doesn't like $((n=n+1)) and insists on $((n=$n+1))"", ""mksh doesn't have a printf builtin in most cases. Earlier tests had it lagging a great deal - it was invoking /usr/bin/printf for every run. Hence the echo -n above."", 'maybe more as I remember it...', ""That'll get 'em all in one go..."", 'Still, this is a rather arbitrary test, but it does test reading input, arithmetic evaluation, and variable expansion. Maybe not comprehensive, but possibly near to there.', 'EDIT by Teresa e Junior: @mikeserv and I have done many other tests (see our chat for details), and we found the results could be summarized like this:']","[<code>&lt;&amp;0</code>, <code>sh_bench() (                                               #dont copy+paste comments
    o=-c sh=$(command -v ""$1"") ; shift                     #get shell $PATH; toss $1
    [ -z ""${sh##*busybox}"" ] &amp;&amp; o='ash -c'                 #cause its weird
    set -- ""$sh"" $o ""'$(cat &lt;&amp;3)'"" -- ""$@""                 #$@ = invoke $shell
    time env - ""$sh"" $o ""while echo; do echo; done|$*""     #time (env - sh|sh) AC/DC
) 3&lt;&lt;-\SCRIPT                                                                      
#Everything from here down is run by the different shells    
    i=""${2:-1}"" l=""${1:-100}"" d=""${3:-                     
}""; set -- ""\$((n=\$n\${n:++\$i}))\$d""                     #prep loop; prep eval
    set -- $1$1$1$1$1$1$1$1$1$1                            #yup
    while read m                                           #iterate on input
    do  [ $(($i*50+${n:=-$i})) -gt ""$(($l-$i))"" ] ||       #eval ok?
            eval echo -n \""""$1$1$1$1$1""\""                  #yay!
        [ $((n=$i+$n)) -gt ""$(($l-$i))"" ] &amp;&amp;               #end game?
            echo ""$n"" &amp;&amp; exit                              #and EXIT
        echo -n ""$n$d""                                     #damn - maybe next time
    done                                                   #done 
#END
SCRIPT                                                     #end heredoc
</code>, <code>stdout</code>, <code>seq</code>, <code>nl</code>, <code>set -x;</code>, <code>time</code>, <code>time env - /usr/bin/busybox ash -c '
     while echo; do echo; done |
     /usr/bin/busybox ash -c '""'$(
         cat &lt;&amp;3
     )'""' -- 20 5 busybox'
</code>, <code> env - $shell -c ""while echo; do echo; done |...""
</code>, <code>3&lt;&lt;\SCRIPT</code>, <code>cat</code>, <code>|pipe</code>, <code>""...| $shell -c '$(cat &lt;&lt;\SCRIPT)' -- $args""
</code>, <code>env</code>, <code>cat</code>, <code>posh</code>, <code>$((n=n+1))</code>, <code>$((n=$n+1))</code>, <code>mksh</code>, <code>printf</code>, <code>/usr/bin/printf</code>, <code>echo -n</code>, <code>for sh in dash busybox posh ksh mksh zsh bash
do  sh_bench $sh 20 5 $sh 2&gt;/dev/null
    sh_bench $sh 500000 | wc -l
echo ; done
</code>, <code>0dash5dash10dash15dash20

real    0m0.909s
user    0m0.897s
sys     0m0.070s
500001

0busybox5busybox10busybox15busybox20

real    0m1.809s
user    0m1.787s
sys     0m0.107s
500001

0posh5posh10posh15posh20

real    0m2.010s
user    0m2.060s
sys     0m0.067s
500001

0ksh5ksh10ksh15ksh20

real    0m2.019s
user    0m1.970s
sys     0m0.047s
500001

0mksh5mksh10mksh15mksh20

real    0m2.287s
user    0m2.340s
sys     0m0.073s
500001

0zsh5zsh10zsh15zsh20

real    0m2.648s
user    0m2.223s
sys     0m0.423s
500001

0bash5bash10bash15bash20

real    0m3.966s
user    0m3.907s
sys     0m0.213s
500001
</code>, <code>grep</code>, <code>sed</code>, <code>sort</code>]"
195,https://unix.stackexchange.com/questions/39314/,su does not change user but does not respond with an error either,"['Check what shell the user has in /etc/passwd. If the shell is /bin/false (a common shell to disallow logins), then you will see the behavior you describe. Alternatively, it may be some other immediately-terminating program that gives the same effective result.']","[<code>/etc/passwd</code>, <code>/bin/false</code>]"
196,https://unix.stackexchange.com/questions/17499/,Get path of current script when executed through a symlink,"['Try this as a general purpose solution:', 'In the specific case of following symlinks, you could also do this:']","[<code>DIR=""$(cd ""$(dirname ""$0"")"" &amp;&amp; pwd)""
</code>, <code>DIR=""$(dirname ""$(readlink -f ""$0"")"")""
</code>]"
197,https://unix.stackexchange.com/questions/18087/,Can I get individual man pages for the bash builtin commands?,"['Try this:', 'You may have to hit n a couple of times to get to the actual command instead of a paragraph that happens to have the command name as the first word.', 'Explanation: this pipes the entire output of man bash, i.e. bash\'s entire man page (which is a huge document, and has subsections explaining each bash builtin command) to the reading program less. less\' -p flag stands for ""pattern""; what it does is automatically scroll to the first point in the input text that matches the pattern. The pattern here is a regex which matches ""The start of a line (^), followed by a specific number of spaces, followed by ..."" – and here, bash inserts the first argument provided to the bashman function, because bash sees the special $1 token (which means ""the first argument"") in a string delimited with double-quotes (single quotes would tell bash that you literally mean the characters $1). So, if you run bashman cd, you will effectively be searching for any line in bash\'s man page with starts with a bunch of spaces, then the string ""cd"". Because there might be other points in bash\'s entire man page that also match this pattern besides the actual heading of the section that explains, eg., ""cd"", this function may not actually take you to the correct part of the bash man page.']","[<code>bashman () { man bash | less -p ""^       $1 ""; }
</code>, <code>man bash</code>, <code>less</code>, <code>-p</code>, <code>^</code>, <code>bashman</code>, <code>$1</code>, <code>$1</code>, <code>bashman cd</code>]"
198,https://unix.stackexchange.com/questions/136423/,Making zsh default shell without root access,"['Create .bash_profile in your home directory and add these lines:', ""Update: .profile may work as a general solution when default shell is not bash. I'm not sure if .profile may be called by Zsh as well that it could go redundant but we can do it safely with a simple check:"", 'We can also use which to get the dynamic path of zsh which relies on the value of $PATH:']","[<code>.bash_profile</code>, <code>export SHELL=/bin/zsh
exec /bin/zsh -l
</code>, <code>.profile</code>, <code>.profile</code>, <code>export SHELL=/bin/zsh
[ -z ""$ZSH_VERSION"" ] &amp;&amp; exec /bin/zsh -l
</code>, <code>which</code>, <code>zsh</code>, <code>$PATH</code>, <code>export SHELL=`which zsh`
[ -z ""$ZSH_VERSION"" ] &amp;&amp; exec ""$SHELL"" -l
</code>]"
199,https://unix.stackexchange.com/questions/3510/,How to print only defined variables (shell and/or environment variables) in bash,"['""Are there other commands which prints only the shell variables, without the functions?""', 'In man bash, in section SHELL BUILTIN COMMANDS (in the set section) it says:\n""In posix mode,  only  shell variables  are listed.""', ""note: () syntax spawns a subshell, if you don't like forking just use the more verbose version""]","[<code>(set -o posix; set)
</code>, <code>()</code>, <code>set -o posix; set; set +o posix
</code>]"
200,https://unix.stackexchange.com/questions/22919/,Refresh aliases and functions after defining new aliases and functions?,"['Sourcing the changed file will provide access to the newly written alias or function in the current terminal, for example:', 'An alternative syntax:', 'Note that if you have many instances of bash running in your terminal (you mentionned multiple tabs), you will have to run this in every instance.']","[<code>source ~/.bashrc</code>, <code>. ~/.bashrc
</code>]"
201,https://unix.stackexchange.com/questions/178162/,Why does bash think: 016 + 1 = 15?,"[""The misunderstanding is that the numbers don't mean what you expect."", 'A leading zero denotes a number with base 8. I.e. 016 is the same as 8#16. If you want to keep the leading zero then you need 10#016.']","[<code>016</code>, <code>8#16</code>, <code>10#016</code>, <code>&gt; num=016
&gt; echo $((num))
14
&gt; echo $((10#$num))
16
</code>]"
202,https://unix.stackexchange.com/questions/3051/,How to echo a bang!,"['Try using single quotes.', 'The problem is occurring because bash is searching its history for !/bin/bash. Using single quotes escapes this behaviour.']","[<code>echo -e '#!/bin/bash \n /usr/bin/command args'  &gt; .scripts/command

echo '#!'

echo '#!/bin/bash'
</code>]"
203,https://unix.stackexchange.com/questions/15415/,Bash: run command2 if command1 fails,"['These should do what you need:', 'or']","[<code>cmd1 &amp;&amp; cmd2 &amp;&amp; echo success || echo epic fail
</code>, <code>if cmd1 &amp;&amp; cmd2; then
    echo success
else
    echo epic fail
fi
</code>]"
204,https://unix.stackexchange.com/questions/84686/,How to create custom commands in Unix/Linux?,"['Create a bash script in your /usr/bin folder, it should look something like this', 'Its really that easy.', ""Just name the bash script what you want to type in to the terminal, and make it excecutable: chmod +x filename and you're good to go!""]","[<code>#!/bin/bash
Whatever combination of commands you want to run when you type this thing.
</code>, <code>chmod +x filename</code>]"
205,https://unix.stackexchange.com/questions/42287/,Terminating an infinite loop,"['Check the exit status of the command.  If the command was terminated by a signal the exit code will be 128 + the signal number.  From the GNU online documentation for bash:', 'For the shell’s purposes, a command which exits with a zero exit status has succeeded. A non-zero exit status indicates failure. This seemingly counter-intuitive scheme is used so there is one well-defined way to indicate success and a variety of ways to indicate various failure modes. When a command terminates on a fatal signal whose number is N, Bash uses the value 128+N as the exit status.', 'POSIX also specifies that the value of a command that terminated by a signal is greater than 128, but does not seem to specify its exact value like GNU does:', 'The exit status of a command that terminated because it received a signal shall be reported as greater than 128.', 'For example if you interrupt a command with control-C the exit code will be 130, because SIGINT is signal 2 on Unix systems.  So:']","[<code>while [ 1 ]; do COMMAND; test $? -gt 128 &amp;&amp; break; done
</code>]"
206,https://unix.stackexchange.com/questions/37181/,cd by just typing the directory's name?,"[""Also, 'autojump' is a useful tool.  Once installed it remembers directories so that you can type j abc and if you've visited abc before, say x/d/f/g/t/abc then it will cd to there!\nhttps://github.com/joelthelion/autojump""]","[<code>shopt -s autocd</code>, <code>setopt autocd</code>, <code>set implicitcd</code>]"
207,https://unix.stackexchange.com/questions/184804/,suppress stderr messages in a bash script,"[""You're right; pkill isn't generating the message, bash is.\xa0\nYou suggest that"", 'is a possible solution.\xa0\nAs UVV points out, the equivalent action from within the script is', 'This redirects the stderr for the script to /dev/null\nfrom this statement until it is changed back.\xa0\nClumsy ways of changing it back include', 'which redirects stderr to the terminal.\xa0\nThis is probably (but not necessarily) where it was originally.', 'Or', 'which sets stderr to be the same as stdout, and is likely to be wrong.', 'A more reliable way is', 'which saves the original stderr in file descriptor 3, and later restores it.', 'Other ways to suppress just the announcement of the process death include', 'and', 'which change the stderr for only the grouped commands.']","[<code>$ ./test1.sh 2&gt; /dev/null
</code>, <code>exec 2&gt; /dev/null
</code>, <code>/dev/null</code>, <code>exec 2&gt; /dev/tty
</code>, <code>exec 2&gt;&amp;1
</code>, <code>(sleep 10 &amp; pkill sleep) 2&gt; /dev/null
</code>, <code>{ sleep 10 &amp; pkill sleep;} 2&gt; /dev/null
</code>]"
208,https://unix.stackexchange.com/questions/115917/,Why is bash not storing commands that start with spaces?,"['man bash:', 'HISTCONTROL', 'A  colon-separated  list  of values controlling how commands are saved on the history list.  If the list of values includes ignorespace, lines which begin with a space character are not saved in the history list. A value of ignoredups causes lines matching the previous history entry to not be saved. A value of ignoreboth is shorthand for ignorespace and ignoredups.']","[<code>echo $HISTCONTROL
ignoreboth
</code>, <code>ignorespace</code>, <code>ignoredups</code>, <code>ignoreboth</code>, <code>ignorespace</code>, <code>ignoredups</code>]"
209,https://unix.stackexchange.com/questions/104094/,Is there any way to enable Ctrl+L to clear screen when 'set -o vi' is set?,"[""Ctrl+L is also bound in vi command mode but not in insert mode. There's no default binding for clear-screen in insert mode. Readline bindings should be specified in ~/.inputrc, like so:"", 'This will bind Ctrl+L to clear the screen in both normal and insert mode. Naturally, if you prefer to only use it in one mode, just remove the relevant option.', 'If you prefer to set this just for bash use the following equivalents in ~/.bashrc:', 'There is an extensive list of readline commands that you can use to customize your bash shell with.']","[<code>vi</code>, <code>clear-screen</code>, <code>~/.inputrc</code>, <code>set editing-mode vi
$if mode=vi

set keymap vi-command
# these are for vi-command mode
Control-l: clear-screen

set keymap vi-insert
# these are for vi-insert mode
Control-l: clear-screen 
$endif
</code>, <code>bash</code>, <code>~/.bashrc</code>, <code>set -o vi
bind -m vi-command 'Control-l: clear-screen'
bind -m vi-insert 'Control-l: clear-screen'
</code>]"
210,https://unix.stackexchange.com/questions/257297/,How does `yes` write to file so quickly?,"[""yes exhibits similar behavior to most other standard utilities which typically write to a FILE STREAM with output buffered by the libC via stdio. These only do the syscall write() every some 4kb (16kb or 64kb) or whatever the output block BUFSIZ is . echo is a write() per GNU. That's a lot of mode-switching (which is not, apparently, as costly as a context-switch)."", ""And that's not at all to mention that, besides its initial optimization loop, yes is a very simple, tiny, compiled C loop and your shell loop is in no way comparable to a compiler optimized program."", 'When I said before that yes used stdio, I only assumed it did because it behaves a lot like those that do. This was not correct - it only emulates their behavior in this way. What it actually does is very like an analog to the thing I did below with the shell: it first loops to conflate its arguments (or y if none) until they might grow no more without exceeding BUFSIZ.', 'A comment from the source immediately preceding the relevant for loop states:', 'yes does its does its own write()s thereafter.', '(As originally included in the question and retained for context to a possibly informative explanation already written here):', 'I\'ve tried timeout 1 $(while true; do echo ""GNU"">>file2; done;) but unable to stop loop.', ""The timeout problem you have with the command substitution - I think I get it now, and can explain why it doesn't stop. timeout doesn't start because its command-line is never run. Your shell forks a child shell, opens a pipe on its stdout, and reads it. It will stop reading when the child quits, and then it will interpret all the child wrote for $IFS mangling and glob expansions, and with the results it will replace everything from $( to the matching )."", ""But if the child is an endless loop that never writes to the pipe, then the child never stops looping, and timeout's command-line is never completed before (as I guess) you do CTRL-C and kill the child loop. So timeout can  never kill the loop which needs to complete before it can start.   "", ""...simply aren't as relevant to your performance issues as the amount of time your shell program must spend switching between user- and kernel-mode to handle output. timeout, though, is not as flexible as a shell might be for this purpose: where shells excel is in their ability to mangle arguments and manage other processes."", ""As is noted elsewhere, simply moving your [fd-num] >> named_file redirection to the loop's output target rather than only directing output there for the command looped over can substantially improve performance because that way at least the open() syscall need only be done the once. This also is done below with the | pipe targeted as output for the inner loops."", 'You might do like:', ""Which is kind of like the command sub relationship described before, but there's no pipe and the child is backgrounded until it kills the parent. In the yes case the parent has actually been replaced since the child was spawned, but the shell calls yes by overlaying its own process with the new one and so the PID remains the same and its zombie child still knows who to kill after all."", ""Now lets see about increasing the shell's write() buffer."", ""I chose that number because output strings any longer than 1kb were getting split out into separate write()'s for me. And so here's the loop again:"", ""That's 300 times the amount of data written by the shell in the same amount of time for this test than the last. Not too shabby. But it's not yes."", 'As requested, there is a more thorough description than the mere code comments on what is done here at this link.']","[<code>yes</code>, <code>write()</code>, <code>echo</code>, <code>write()</code>, <code>GNU</code>, <code>yes</code>, <code>yes</code>, <code>y</code>, <code>BUFSIZ</code>, <code>for</code>, <code>/* Buffer data locally once, rather than having the
large overhead of stdio buffering each item.  */
</code>, <code>yes</code>, <code>write()</code>, <code>timeout 1 $(while true; do echo ""GNU""&gt;&gt;file2; done;)</code>, <code>timeout</code>, <code>timeout</code>, <code>$IFS</code>, <code>$(</code>, <code>)</code>, <code>timeout</code>, <code>CTRL-C</code>, <code>timeout</code>, <code>timeout</code>, <code>timeout</code>, <code>[fd-num] &gt;&gt; named_file</code>, <code>open()</code>, <code>|</code>, <code>for cmd in  exec\ yes 'while echo y; do :; done'
do      set +m
        sh  -c '{ sleep 1; kill ""$$""; }&amp;'""$cmd"" | wc -l
        set -m
done
</code>, <code>256659456
505401
</code>, <code>yes</code>, <code>yes</code>, <code>write()</code>, <code>IFS=""
"";    set y """"              ### sets up the macro expansion       
until [ ""${512+1}"" ]        ### gather at least 512 args
do    set ""$@$@"";done       ### exponentially expands ""$@""
printf %s ""$*""| wc -c       ### 1 write of 512 concatenated ""y\n""'s  
</code>, <code>1024
</code>, <code>write()</code>, <code>for cmd in 'exec  yes' \
           'until [ ""${512+:}"" ]; do set ""$@$@""; done
            while printf %s ""$*""; do :; done'
do      set +m
        sh  -c $'IFS=""\n""; { sleep 1; kill ""$$""; }&amp;'""$cmd"" shyes y """"| wc -l
        set -m
done
</code>, <code>268627968
15850496
</code>, <code>yes</code>]"
211,https://unix.stackexchange.com/questions/442692/,Is $() a subshell?,"[""$(…) is a subshell by definition: it's a copy of the shell runtime state¹, and changes to the state made in the subshell have no impact on the parent. A subshell is typically implemented by forking a new process (but some shells may optimize this in some cases)."", ""It isn't a subshell that you can retrieve variable values from. If changes to variables had an impact on the parent, it wouldn't be a subshell. It's a subshell whose output the parent can retrieve. The subshell created by $(…) has its standard output set to a pipe, and the parent reads from that pipe and collects the output."", 'There are several other constructs that create a subshell. I think this is the full list for bash:', '¹  As opposed to running a separate shell.  ']","[<code>$(…)</code>, <code>$(…)</code>, <code>( … )</code>, <code>{ … }</code>, <code>… &amp;</code>, <code>… | …</code>, <code>lastpipe</code>, <code>$(…)</code>, <code>`…`</code>, <code>&lt;(…)</code>, <code>&gt;(…)</code>, <code>coproc …</code>]"
212,https://unix.stackexchange.com/questions/254367/,"In bash scripting, what's the different between declare and a normal variable?","['From help -m declare:', 'NAME\ndeclare - Set variable values and attributes.', 'SYNOPSIS\ndeclare [-aAfFgilnrtux] [-p] [name[=value] ...]', 'DESCRIPTION\n          Set variable values and attributes.', 'Declare variables and give them attributes.  If no NAMEs are given,\n          display the attributes and values of all variables.', 'Options:\n-f  restrict action or display to function names and definitions\n-F  restrict display to function names only (plus line number and\n              source file when debugging)\n-g  create global variables when used in a shell function; otherwise\n              ignored\n-p  display the attributes and value of each NAME', 'Options which set attributes:\n-a  to make NAMEs indexed arrays (if supported)\n-A  to make NAMEs associative arrays (if supported)\n-i  to make NAMEs have the ‘integer’ attribute\n-l  to convert NAMEs to lower case on assignment\n-n  make NAME a reference to the variable named by its value\n-r  to make NAMEs readonly\n-t  to make NAMEs have the ‘trace’ attribute\n-u  to convert NAMEs to upper case on assignment\n-x  to make NAMEs export', 'Using ‘+’ instead of ‘-’ turns off the given attribute.', 'Variables with the integer attribute have arithmetic evaluation (see\n          the let command) performed when the variable is assigned a value.', 'When used in a function, declare makes NAMEs local, as with the local\n          command.  The ‘-g’ option suppresses this behavior.', 'Exit Status:\n          Returns success unless an invalid option is supplied or a variable\n          assignment error occurs.', 'SEE ALSO\n          bash(1)', 'IMPLEMENTATION\n          GNU bash, version 4.3.11(1)-release (i686-pc-linux-gnu)\n          Copyright (C) 2013 Free Software Foundation, Inc.\n          License GPLv3+: GNU GPL version 3 or later <http&colon//gnu.org/licenses/gpl.html>', 'So, declare is used for setting variable values and attributes.', 'Let me show the use of two attributes with a very simple example:', 'From the above example, I think you should understand the usage of declare variable over normal variable! This type of declareation is useful in functions, loops with scripting.', 'Also visit Typing variables: declare or typeset']","[<code>help -m declare</code>, <code>declare</code>, <code>declare</code>, <code>-aAfFgilnrtux</code>, <code>-p</code>, <code>name</code>, <code>=<i>value</i></code>, <code>-f</code>, <code>-F</code>, <code>-g</code>, <code>-p</code>, <code>-a</code>, <code>-A</code>, <code>-i</code>, <code>-l</code>, <code>-n</code>, <code>-r</code>, <code>-t</code>, <code>-u</code>, <code>-x</code>, <code>+</code>, <code>-</code>, <code>let</code>, <code>declare</code>, <code>local</code>, <code>-g</code>, <code>declare</code>, <code>$ # First Example:
$ declare -r abc=ok
$ echo $abc
ok
$ abc=not-ok
bash: abc: readonly variable


$ # Second Example:
$ declare -i x=10
$ echo $x
10
$ x=ok
$ echo $x
0
$ x=15
$ echo $x
15
$ x=15+5
$ echo $x
20
</code>, <code>declare</code>, <code>declare</code>]"
213,https://unix.stackexchange.com/questions/417052/,"With BASH after ""scrolling"" up to a previous command... how to then move on to the next in this history?",['Running the command with Ctrl+o instead of Enter will run a command from history and then queue up the next one instead of returning to the front of the bash history. '],[]
214,https://unix.stackexchange.com/questions/90106/,What's the most resource efficient way to count how many files are in a directory?,"['Short answer:', '(This includes . and .., so subtract 2.)', 'When you list the files in a directory, three common things might happen:', '#3 is the most expensive by far, because it requires loading an inode for each file. In comparison all the file names needed for #1 are compactly stored in a few blocks. #2 wastes some CPU time but it is often not a deal breaker.', 'If there are no newlines in file names, a simple ls -A | wc -l tells you how many files there are in the directory. Beware that if you have an alias for ls, this may trigger a call to stat (e.g. ls --color or ls -F need to know the file type, which requires a call to stat), so from the command line, call command ls -A | wc -l or \\ls -A | wc -l to avoid an alias.', ""If there are newlines in the file name, whether newlines are listed or not depends on the Unix variant. GNU coreutils and BusyBox default to displaying ? for a newline, so they're safe."", ""Call ls -f to list the entries without sorting them (#2). This automatically turns on -a (at least on modern systems). The -f option is in POSIX but with optional status; most implementations support it, but not BusyBox. The option -q replaces non-printable characters including newlines by ?; it's POSIX but isn't supported by BusyBox, so omit it if you need BusyBox support at the expense of overcounting files whose name contains a newline character."", ""If the directory has no subdirectories, then most versions of find will not call stat on its entries (leaf directory optimization: a directory that has a link count of 2 cannot have subdirectories, so find doesn't need to look up the metadata of the entries unless a condition such as -type requires it). So find . | wc -l is a portable, fast way to count files in a directory provided that the directory has no subdirectories and that no file name contains a newline."", ""If the directory has no subdirectories but file names may contain newlines, try one of these (the second one should be faster if it's supported, but may not be noticeably so)."", ""On the other hand, don't use find if the directory has subdirectories: even find . -maxdepth 1 calls stat on every entry (at least with GNU find and BusyBox find). You avoid sorting (#2) but you pay the price of an inode lookup (#3) which kills performance."", ""In the shell without external tools, you can run count the files in the current directory with set -- *; echo $#. This misses dot files (files whose name begins with .) and reports 1 instead of 0 in an empty directory. This is the fastest way to count files in small directories because it doesn't require starting an external program, but (except in zsh) wastes time for larger directories due to the sorting step (#2)."", 'In bash, this is a reliable way to count the files in the current directory:', 'In ksh93, this is a reliable way to count the files in the current directory:', 'In zsh, this is a reliable way to count the files in the current directory:', 'If you have the mark_dirs option set, make sure to turn it off: a=(*(DNoN^M)).', 'In any POSIX shell, this is a reliable way to count the files in the current directory:', 'All of these methods sort the file names, except for the zsh one.']","[<code>\ls -afq | wc -l
</code>, <code>.</code>, <code>..</code>, <code>ls</code>, <code>stat</code>, <code>ls -A | wc -l</code>, <code>ls</code>, <code>stat</code>, <code>ls --color</code>, <code>ls -F</code>, <code>stat</code>, <code>command ls -A | wc -l</code>, <code>\ls -A | wc -l</code>, <code>?</code>, <code>ls -f</code>, <code>-a</code>, <code>-f</code>, <code>-q</code>, <code>?</code>, <code>find</code>, <code>stat</code>, <code>find</code>, <code>-type</code>, <code>find . | wc -l</code>, <code>find -print0 | tr -dc \\0 | wc -c
find -printf a | wc -c
</code>, <code>find</code>, <code>find . -maxdepth 1</code>, <code>stat</code>, <code>set -- *; echo $#</code>, <code>.</code>, <code>shopt -s dotglob nullglob
a=(*)
echo ${#a[@]}
</code>, <code>FIGNORE='@(.|..)'
a=(~(N)*)
echo ${#a[@]}
</code>, <code>a=(*(DNoN))
echo $#a
</code>, <code>mark_dirs</code>, <code>a=(*(DNoN^M))</code>, <code>total=0
set -- *
if [ $# -ne 1 ] || [ -e ""$1"" ] || [ -L ""$1"" ]; then total=$((total+$#)); fi
set -- .[!.]*
if [ $# -ne 1 ] || [ -e ""$1"" ] || [ -L ""$1"" ]; then total=$((total+$#)); fi
set -- ..?*
if [ $# -ne 1 ] || [ -e ""$1"" ] || [ -L ""$1"" ]; then total=$((total+$#)); fi
echo ""$total""
</code>]"
215,https://unix.stackexchange.com/questions/350240/,"Why is printf ""shrinking"" umlaut?","[""POSIX requires printf's %-20s to count those 20 in terms of bytes not characters even though that makes little sense as printf is to print text, formatted (see discussion at the Austin Group (POSIX) and bash mailing lists)."", 'The printf builtin of bash and most other POSIX shells honour that.', ""zsh ignores that silly requirement (even in sh emulation) so printf works as you'd expect there. Same for the printf builtin of fish (not a POSIX-like shell)."", 'The ü character (U+00FC), when encoded in UTF-8 is made of two bytes (0xc3 and 0xbc), which explains the discrepancy.', 'That string is made of 18 characters, is 18 columns wide (-L being a GNU wc extension to report the display width of the widest line in the input) but is encoded on 20 bytes.', 'In zsh or fish, the text would be aligned correctly.', ""Now, there are also characters that have 0-width (like combining characters such as U+0308, the combining diaresis) or have double-width like in many Asiatic scripts (not to mention control characters like Tab) and even zsh wouldn't align those properly."", 'Example, in zsh:', 'In bash:', 'ksh93 has a %Ls format specification to count the width in terms of display width.', ""That still doesn't work if the text contains control characters like TAB (how could it? printf would have to know how far apart the tab stops are in the output device and what position it starts printing at). It does work by accident with backspace characters (like in the roff output where X (bold X) is written as X\\bX) though as ksh93 considers all control characters as having a width of -1."", 'In zsh, you can use its padding parameter expansion flags (l for left-padding, r for right-padding), which when combined with the m flag considers the display width of characters (as opposed to the number of characters in the string):', 'With expand:', ""That works with some expand implementations (not GNU's though)."", 'On GNU systems, you could use GNU awk whose printf counts in chars (not bytes, not display-widths, so still not OK for the 0-width or 2-width characters, but OK for your sample):', 'If the output goes to a terminal, you can also use cursor positioning escape sequences. Like:']","[<code>printf</code>, <code>%-20s</code>, <code>printf</code>, <code>bash</code>, <code>printf</code>, <code>bash</code>, <code>zsh</code>, <code>sh</code>, <code>printf</code>, <code>printf</code>, <code>fish</code>, <code>ü</code>, <code>$ printf %s 'Früchte und Gemüse' | wc -mcL
    18      20      18
</code>, <code>-L</code>, <code>wc</code>, <code>zsh</code>, <code>fish</code>, <code>zsh</code>, <code>zsh</code>, <code>$ printf '%3s|\n' u ü $'u\u308' $'\u1100'
  u|
  ü|
 ü|
  ᄀ|
</code>, <code>bash</code>, <code>$ printf '%3s|\n' u ü $'u\u308' $'\u1100'
  u|
 ü|
ü|
ᄀ|
</code>, <code>ksh93</code>, <code>%Ls</code>, <code>$ printf '%3Ls|\n' u ü $'u\u308' $'\u1100'
  u|
  ü|
  ü|
 ᄀ|
</code>, <code>printf</code>, <code>roff</code>, <code>X</code>, <code>X</code>, <code>X\bX</code>, <code>ksh93</code>, <code>-1</code>, <code>zsh</code>, <code>l</code>, <code>r</code>, <code>m</code>, <code>$ () { printf '%s|\n' ""${(ml[3])@}""; } u ü $'u\u308' $'\u1100'
  u|
  ü|
  ü|
 ᄀ|
</code>, <code>expand</code>, <code>printf '%s\t|\n' u ü $'u\u308' $'\u1100' | expand -t3
</code>, <code>expand</code>, <code>awk</code>, <code>printf</code>, <code>gawk 'BEGIN {for (i = 1; i &lt; ARGC; i++) printf ""%-3s|\n"", ARGV[i]}
     ' u ü $'u\u308' $'\u1100'
</code>, <code>forward21=$(tput cuf 21)
printf '%s\r%s%s\n' \
  ""Früchte und Gemüse""    ""$forward21"" ""foo"" \
  ""Milchprodukte""         ""$forward21"" ""bar"" \
  ""12345678901234567890""  ""$forward21"" ""baz""
</code>]"
216,https://unix.stackexchange.com/questions/71144/,What do the bash-builtins 'set' and 'export' do?,"['export exports to children of the current process, by default they are not exported. For example:', 'set, on the other hand, sets shell attributes, for example, the positional parameters.', 'Note that baz is not assigned to foo, it simply becomes a literal positional parameter. There are many other things set can do (mostly shell options), see help set.', ""As for printing, export called with no arguments prints all of the variables in the shell's environment. set also prints variables that are not exported. It can also export some other objects (although you should note that this is not portable), see help export.""]","[<code>export</code>, <code>$ foo=bar
$ echo ""$foo""
bar
$ bash -c 'echo ""$foo""'

$ export foo
$ bash -c 'echo ""$foo""'
bar
</code>, <code>set</code>, <code>$ set foo=baz
$ echo ""$1""
foo=baz
</code>, <code>baz</code>, <code>foo</code>, <code>set</code>, <code>help set</code>, <code>export</code>, <code>set</code>, <code>help export</code>]"
217,https://unix.stackexchange.com/questions/68322/,How can I remove an element from an array completely?,"['Just use array syntax on the assignment and quote your variable:', 'Edit according to question in comment. For $@ you can use it like this:']","[<code>array=(""${array[@]:1}"") #removed the 1st element
</code>, <code>$@</code>, <code>set -- ""${@:2}"" #removed the 1st parameter
</code>]"
218,https://unix.stackexchange.com/questions/89712/,How to convert floating point number to integer?,"[""In bash, that's probably as good as it gets. That uses a shell builtin. If you need the result in a variable, you could use command substitution, or the bash specific (though now also supported by zsh):"", 'You could do:', ""But that would remove the fractional part instead of giving you the nearest integer and that wouldn't work for values of $float like 1.2e9 or .12 for instance."", 'Also note the possible limitations due to the internal representation of floats:', ""You do get an integer, but chances are that you won't be able to use that integer anywhere."", 'Also, as noted by @BinaryZebra, in several printf implementations (bash, ksh93, yash, not GNU, zsh, dash), it is affected by the locale (the decimal separator which can be . or ,).', ""So, if your floats are always expressed with the period as the decimal separator and you want it to be treated as such by printf regardless of the locale of the user invoking your script, you'd need to fix the locale to C:"", 'With yash, you can also do:', '(see below).', 'is not POSIX as %f is not required to be supported by POSIX.', 'POSIXly, you can do:', ""That one is not affected by the locale (the comma cannot be a decimal separator in awk since it's already a special character in the syntax there (print 1,2, same as print 1, 2 to pass two arguments to print)"", 'In zsh (which supports floating point arithmetic (decimal separator is always the period)), you have the rint() math function to give you the nearest integer as a float (like in C) and int() to give you an integer from a float (like in awk). So you can do:', 'Or:', 'However note that while doubles can represent very large numbers, integers are much more limited.', 'ksh93 was the first Bourne-like shell to support floating point arithmetic. ksh93 optimises command substitution by not using a pipe or forking when the commands are only builtin commands. So', ""doesn't fork. Or even better:"", ""which doesn't fork either but also doesn't go all the trouble of creating a fake subshell environment."", 'You can also do:', 'But beware of:', 'You could also do:', 'But like for zsh:', 'Beware that ksh93 floating point arithmetic honour the decimal separator setting in the locale (even though , is otherwise a math operator ($((1,2)) would be 6/5 in a French/German... locale, and the same as $((1, 2)), that is 2 in an English locale).', ""yash also supports floating point arithmetic but doesn't have math functions like ksh93/zsh's rint(). You can convert a number to integer though by using the binary or operator for instance (also works in zsh but not in ksh93). Note however that it truncates the decimal part, it doesn't give you the nearest integer:"", ""yash honours the locale's decimal separator on output, but not for the floating point literal constants in its arithmetic expressions, which can cause surprises:"", ""It's good in a way in that you can use floating point constants in your scripts that use the period and not have to worry that it will stop working in other locales, but still be able to deal with the numbers as expressed by the user as long as you remember to do:""]","[<code>bash</code>, <code>bash</code>, <code>zsh</code>, <code>printf -v int %.0f ""$float""
</code>, <code>float=1.23
int=${float%.*}
</code>, <code>$float</code>, <code>1.2e9</code>, <code>.12</code>, <code>$ printf '%.0f\n' 1e50
100000000000000007629769841091887003294964970946560
</code>, <code>printf</code>, <code>.</code>, <code>,</code>, <code>printf</code>, <code>LC_ALL=C printf '%.0f' ""$float""
</code>, <code>yash</code>, <code>printf '%.0f' ""$(($float))""
</code>, <code>printf ""%.0f\n"" 1.1
</code>, <code>%f</code>, <code>f2i() {
  awk 'BEGIN{for (i=1; i&lt;ARGC;i++)
   printf ""%.0f\n"", ARGV[i]}' ""$@""
}
</code>, <code>awk</code>, <code>print 1,2</code>, <code>print 1, 2</code>, <code>print</code>, <code>zsh</code>, <code>rint()</code>, <code>C</code>, <code>int()</code>, <code>awk</code>, <code>$ zmodload zsh/mathfunc
$ i=$((int(rint(1.234e2))))
$ echo $i
123
</code>, <code>$ integer i=$((rint(5.678e2)))
$ echo $i
568
</code>, <code>double</code>, <code>$ printf '%.0f\n' 1e123
999999999999999977709969731404129670057984297594921577392083322662491290889839886077866558841507631684757522070951350501376
$ echo $((int(1e123)))
-9223372036854775808
</code>, <code>i=$(printf '%.0f' ""$f"")
</code>, <code>i=${ printf '%.0f' ""$f""; }
</code>, <code>i=$((rint(f)))
</code>, <code>$ echo ""$((rint(1e18)))""
1000000000000000000
$ echo ""$((rint(1e19)))""
1e+19
</code>, <code>integer i=$((rint(f)))
</code>, <code>zsh</code>, <code>$ integer i=1e18
$ echo ""$i""
1000000000000000000
$ integer i=1e19
$ echo ""$i""
-9223372036854775808
</code>, <code>ksh93</code>, <code>,</code>, <code>$((1,2))</code>, <code>$((1, 2))</code>, <code>ksh93</code>, <code>zsh</code>, <code>rint()</code>, <code>zsh</code>, <code>ksh93</code>, <code>$ echo ""$((0.237e2 | 0))""
23
$ echo ""$((1e19 | 0))""
-9223372036854775808
</code>, <code>yash</code>, <code>$ LC_ALL=fr_FR.UTF-8 ./yash -c 'a=$((1e-2)); echo $(($a + 1))'
./yash: arithmetic: `,' is not a valid number or operator
</code>, <code>var=$((10.3)) # and not var=10.3
... ""$((a + 0.1))"" # and not ""$(($a + 0.1))"".

printf '%.0f\n' ""$((10.3))"" # and not printf '%.0f\n' 10.3
</code>]"
219,https://unix.stackexchange.com/questions/204480/,Run multiple commands and kill them as one in bash,"['To run commands concurrently you can use the & command separator.', 'This will start command1, then runs it in the background. The same with command2. Then it starts command3 normally.', 'The output of all commands will be garbled together, but if that is not a problem for you, that would be the solution.', 'If you want to have a separate look at the output later, you can pipe the output of each command into tee, which lets you specify a file to mirror the output to.', 'The output will probably be very messy. To counter that, you could give the output of every command a prefix using sed.', 'So if we put all of that together we get:', 'This is a highly idealized version of what you are probably going to see. But its the best I can think of right now.', 'If you want to stop all of them at once, you can use the build in trap.', 'This will execute command1 and command2 in the background and command3 in the foreground, which lets you kill it with Ctrl+C.  ', 'When you kill the last process with Ctrl+C the kill %1; kill %2 commands are executed, because we connected their execution with the reception of an INTerupt SIGnal, the thing sent by pressing Ctrl+C. ', ""They respectively kill the 1st and 2nd background process (your command1 and command2). Don't forget to remove the trap, after you're finished with your commands using trap - SIGINT."", 'Complete monster of a command:', 'You could, of course, have a look at screen. It lets you split your console into as many separate consoles as you want. So you can monitor all commands separately, but at the same time.']","[<code>&amp;</code>, <code>~$ command1 &amp; command2 &amp; command3
</code>, <code>command1</code>, <code>command2</code>, <code>command3</code>, <code>tee</code>, <code>~$ command1 | tee 1.log &amp; command2 | tee 2.log &amp; command3 | tee 3.log
</code>, <code>sed</code>, <code>~$ echo 'Output of command 1' | sed -e 's/^/[Command1] /' 
[Command1] Output of command 1
</code>, <code>~$ command1 | tee 1.log | sed -e 's/^/[Command1] /' &amp; command2 | tee 2.log | sed -e 's/^/[Command2] /' &amp; command3 | tee 3.log | sed -e 's/^/[Command3] /'
[Command1] Starting command1
[Command2] Starting command2
[Command1] Finished
[Command3] Starting command3
</code>, <code>trap</code>, <code>~$ trap 'kill %1; kill %2' SIGINT
~$ command1 &amp; command2 &amp; command3
</code>, <code>command1</code>, <code>command2</code>, <code>command3</code>, <code>kill %1; kill %2</code>, <code>command1</code>, <code>command2</code>, <code>trap - SIGINT</code>, <code>~$ trap 'kill %1; kill %2' SIGINT
~$ command1 | tee 1.log | sed -e 's/^/[Command1] /' &amp; command2 | tee 2.log | sed -e 's/^/[Command2] /' &amp; command3 | tee 3.log | sed -e 's/^/[Command3] /'
</code>]"
220,https://unix.stackexchange.com/questions/52026/,Bash: How to read one line at a time from output of a command?,"[""There's a mistake, you need < <(command) not <<<$(command)"", '< <( ) is a Process Substitution, $() is a command substitution and <<< is a here-string. ']","[<code>&lt; &lt;(command)</code>, <code>&lt;&lt;&lt;$(command)</code>, <code>&lt; &lt;( )</code>, <code>$()</code>, <code>&lt;&lt;&lt;</code>]"
221,https://unix.stackexchange.com/questions/12283/,"unix, difference between path starting with '/' and '//'","['For the most part, repeated slahes in a path are equivalent to a single slash. This behavior is mandated by POSIX and most applications follow suit. The exception is that “a pathname that begins with two successive slashes may be interpreted in an implementation-defined manner” (but ///foo is equivalent to /foo).', ""Most unices don't do anything special with two initial slashes. Linux, in particular, doesn't. Cygwin does: //hostname/path accesses a network drive (SMB)."", ""What you're seeing is not, in fact, Linux doing anything special with //: it's bash's current directory tracking. Compare:"", ""Bash is taking the precaution that the OS might be treating // specially and keeping it. Dash does the same. Ksh and zsh don't when they're running on Linux, I guess (I haven't checked) they have a compile-time setting.""]","[<code>///foo</code>, <code>/foo</code>, <code>//hostname/path</code>, <code>//</code>, <code>$ bash -c 'cd //; pwd'
//
$ bash -c 'cd //; /bin/pwd'
/
</code>, <code>//</code>]"
222,https://unix.stackexchange.com/questions/14895/,Duplicate entries in $PATH a problem?,"[""Having more entries in $PATH doesn't directly slow your startup, but it does slow each time you first run a particular command in a shell session (not every time you run the command, because bash maintains a cache). The slowdown is rarely perceptible unless you have a particularly slow filesystem (e.g. NFS, Samba or other network filesystem, or on Cygwin)."", 'Duplicate entries are also a little annoying when you review your $PATH visually, you have to wade through more cruft.', ""It's easy enough to avoid adding duplicate entries."", ""Side note: sourcing someone else's shell script means executing code that he's written. In other words, you're giving your friends access to your account whenever they want."", 'Side note: .bashrc is not the right place to set $PATH or any other environment variable. Environment variables should be set in ~/.profile. See Which setup files should be used for setting up environment variables with bash?, Difference between .bashrc and .bash_profile.']","[<code>$PATH</code>, <code>$PATH</code>, <code>case "":$PATH:"" in
  *"":$new_entry:""*) :;; # already there
  *) PATH=""$new_entry:$PATH"";; # or PATH=""$PATH:$new_entry""
esac
</code>, <code>.bashrc</code>, <code>$PATH</code>, <code>~/.profile</code>]"
223,https://unix.stackexchange.com/questions/207957/,Assigning exit code to a shell local variable,"['local t1=$(exit 1) tells the shell to:', ""It's thus normal that t1 ends up being empty."", '($() is known as command substitution.)', 'The exit code is always assigned to $?, so you can do', ""to get the effect you're looking for. You can of course assign $? to another variable:""]","[<code>local t1=$(exit 1)</code>, <code>exit 1</code>, <code>t1</code>, <code>t1</code>, <code>$()</code>, <code>$?</code>, <code>function0()
{
  (exit 1)
  echo ""$?""
}
</code>, <code>$?</code>, <code>function0()
{
  (exit 1)
  local t1=$?
  echo ""$t1""
}
</code>]"
224,https://unix.stackexchange.com/questions/310957/,How to restore the value of shell options like `set -x`?,"['To reverse a set -x just execute a set +x. Most of the time, the reverse of an string set -str is the same string with a +: set +str.', 'In general, to restore all (read below about bash errexit) shell options (changed with set command) you could do (also read below about bash shopt options):', ""Should be enough, but bash has two groups of options accessed via set (or shopt -po) and some others accessed via shopt -p. Also, bash doesn't preserve set -e (errexit) on entering subshells. Note that the list of options that results from expanding $- might not be valid to re-enter in a shell."", 'To capture the whole present state (in bash) use:', ""Or, if you don't mind setting the inherit_errexit flag (and your bash is ≥4.4):"", 'This command:', 'is used to generate an executable string that reflects the state of the option(s).\nThe p flag means print, and the o flag specifies that we are asking about option(s) set by the set command (as opposed to option(s) set only by the shopt command).\nYou can assign this string to a variable, and execute the variable at the end of your script to restore the initial state.', 'This solution also works for multiple options simultaneously:', 'Adding set +vx avoids the printing of a long list of options.', 'If you don’t list any option names,', 'it gives you the values of all (set) options.\nAnd, if you leave out the o flag,\nyou can do the same things with shopt options:', 'If you need to test whether a set option is set,\nthe most idiomatic (Bash) way to do it is:', 'which is better than the other two similar tests:', 'With any of the tests, this works:', 'Here’s how to test the state of a shopt option:', 'A simple, POSIX-compliant solution to store all set options is:', 'which is described in the POSIX standard as:', '+o\nWrite the current option settings to standard output in a format\nthat is suitable for reinput to the\xa0shell\nas commands that achieve the same options settings.', 'So, simply:', 'will preserve values for all options set using the set command (in some shells).', 'Again, restoring the options to their original values is a matter of executing the variable:', ""This is exactly equivalent to using Bash's shopt -po. Note that it will not cover all possible Bash options, as some of those are set (only) by shopt."", 'There are many other shell options listed with shopt in bash:', 'Those could be appended to the variable set above and restored in the same way:', 'In bash, the value of set -e (errexit) is reset inside sub-shells, that makes it difficult to capture its value with set +o inside a $(…) sub-shell.', 'As a workaround, use:', ""Or (if it doesn't contradict your goals and your bash supports it) you can use the inherit_errexit option."", 'Note: each shell has a slightly different way to build the list of options that are set or unset (not to mention different options that are defined), so the strings are not portable between shells, but are valid for the same shell.', ""zsh also works correctly (following POSIX) since version 5.3. In previous versions it followed POSIX only partially with set +o in that it printed options in a format that was suitable for reinput to the shell as commands, but only for set options (it didn't print un-set options)."", 'The mksh (and by consequence lksh) is not yet (MIRBSD KSH R54 2016/11/11) able to do this. The mksh manual contains this:', 'In a future version, set +o will behave POSIX compliant and print commands to restore the current options instead.']","[<code>set -x</code>, <code>set +x</code>, <code>set -str</code>, <code>+</code>, <code>set +str</code>, <code>errexit</code>, <code>set</code>, <code>shopt</code>, <code>oldstate=""$(set +o)""                # POSIXly store all set options.
.
.
set -vx; eval ""$oldstate""         # restore all options stored.
</code>, <code>set</code>, <code>shopt -po</code>, <code>shopt -p</code>, <code>set -e</code>, <code>$-</code>, <code>oldstate=""$(shopt -po; shopt -p)""; [[ -o errexit ]] &amp;&amp; oldstate=""$oldstate; set -e""
</code>, <code>inherit_errexit</code>, <code>shopt -s inherit_errexit;    oldstate=""$(shopt -po; shopt -p)""
</code>, <code>shopt -po xtrace
</code>, <code>p</code>, <code>o</code>, <code>set</code>, <code>shopt</code>, <code># store state of xtrace option.
tracestate=""$(shopt -po xtrace)""

# change xtrace as needed
echo ""some commands with xtrace as externally selected""
set -x
echo ""some commands with xtrace set""

# restore the value of xtrace to its original value.
eval ""$tracestate""
</code>, <code>oldstate=""$(shopt -po xtrace noglob errexit)""

# change options as needed
set -x
set +x
set -f
set -e
set -x

# restore to recorded state:
set +vx; eval ""$oldstate""
</code>, <code>set +vx</code>, <code>oldstate=""$(shopt -po)""
</code>, <code>o</code>, <code>shopt</code>, <code># store state of dotglob option.
dglobstate=""$(shopt -p dotglob)""

# store state of all options.
oldstate=""$(shopt -p)""
</code>, <code>set</code>, <code>[[ -o xtrace ]]
</code>, <code>[[ $- =~ x ]]</code>, <code>[[ $- == *x* ]]</code>, <code># record the state of the xtrace option in ts (tracestate):
[ -o xtrace ] &amp;&amp; ts='set -x' || ts='set +x'

# change xtrace as needed
echo ""some commands with xtrace as externally selected""
set -x
echo ""some commands with xtrace set""

# set the xtrace option back to what it was.
eval ""$ts""
</code>, <code>shopt</code>, <code>if shopt -q dotglob
then
        # dotglob is set, so “echo .* *” would list the dot files twice.
        echo *
else
        # dotglob is not set.  Warning: the below will list “.” and “..”.
        echo .* *
fi
</code>, <code>set</code>, <code>set +o
</code>, <code>oldstate=$(set +o)
</code>, <code>set</code>, <code>set +vx; eval ""$oldstate""
</code>, <code>shopt -po</code>, <code>shopt</code>, <code>shopt</code>, <code>$ shopt
autocd          off
cdable_vars     off
cdspell         off
checkhash       off
checkjobs       off
checkwinsize    on
cmdhist         on
compat31        off
compat32        off
compat40        off
compat41        off
compat42        off
compat43        off
complete_fullquote  on
direxpand       off
dirspell        off
dotglob         off
execfail        off
expand_aliases  on
extdebug        off
extglob         off
extquote        on
failglob        off
force_fignore   on
globasciiranges off
globstar        on
gnu_errfmt      off
histappend      on
histreedit      off
histverify      on
hostcomplete    on
huponexit       off
inherit_errexit off
interactive_comments    on
lastpipe        on
lithist         off
login_shell     off
mailwarn        off
no_empty_cmd_completion off
nocaseglob      off
nocasematch     off
nullglob        off
progcomp        on
promptvars      on
restricted_shell    off
shift_verbose   off
sourcepath      on
xpg_echo        off
</code>, <code>$ oldstate=""$oldstate;$(shopt -p)""
.
.                                   # change options as needed.
.
$ eval ""$oldstate"" 
</code>, <code>set -e</code>, <code>set -e</code>, <code>errexit</code>, <code>set +o</code>, <code>oldstate=""$(set +o)""; [[ -o errexit ]] &amp;&amp; oldstate=""$oldstate; set -e""
</code>, <code>inherit_errexit</code>, <code>zsh</code>, <code>set +o</code>]"
225,https://unix.stackexchange.com/questions/32096/,Why is bash's prompt variable called PS1?,"['PS1 stands for ""Prompt String One"" or ""Prompt Statement One"", the first prompt string (that you see at a command line).', 'Yes, there is a PS2 and more! Please read this article and the Arch wiki and of course The Bash Reference Manual.']",[]
226,https://unix.stackexchange.com/questions/9784/,How can I read line by line from a variable in bash?,"['You can use a while loop with process substitution:', 'An optimal way to read a multiline variable is to set a blank IFS variable and printf the variable in with a trailing newline:', 'Note: As per shellcheck sc2031, the use of process substition is preferable to a pipe to avoid [subtly] creating an subshell.', 'Also, please realize that by naming the variable jobs it may cause confusion since that is also the name of a common shell command.']","[<code>while read -r line
do
    echo ""$line""
done &lt; &lt;(jobs)
</code>, <code>IFS</code>, <code>printf</code>, <code># Printf '%s\n' ""$var"" is necessary because printf '%s' ""$var"" on a
# variable that doesn't end with a newline then the while loop will
# completely miss the last line of the variable.
while IFS= read -r line
do
   echo ""$line""
done &lt; &lt;(printf '%s\n' ""$var"")
</code>, <code>jobs</code>]"
227,https://unix.stackexchange.com/questions/197792/,Joining bash arguments into single string with spaces,"['I believe that this does what you want.  It will put all the arguments in one string, separated by spaces, with single quotes around all:', '$* produces all the scripts arguments separated by the first character of $IFS which, by default, is a space.', 'Inside a double quoted string, there is no need to escape single-quotes.', 'Let us put the above in a script file:', 'Now, run the script with sample arguments:', 'This script is POSIX.  It will work with bash but it does not require bash.', 'We can change from spaces to another character by adjusting IFS:', 'For example:']","[<code>str=""'$*'""
</code>, <code>$*</code>, <code>$IFS</code>, <code>$ cat script.sh 
#!/bin/sh
str=""'$*'""
echo ""$str""
</code>, <code>$ sh script.sh one two three four 5
'one two three four 5'
</code>, <code>bash</code>, <code>bash</code>, <code>IFS</code>, <code>$ cat script.sh 
#!/bin/sh
old=""$IFS""
IFS='/'
str=""'$*'""
echo ""$str""
IFS=$old
</code>, <code>$ sh script.sh one two three four       
'one/two/three/four'
</code>]"
228,https://unix.stackexchange.com/questions/10421/,Output from ls has newlines but displays on a single line. Why?,"['When you pipe the output, ls acts differently.', 'This fact is hidden away in the info documentation:', 'If standard output is a terminal, the output is in columns (sorted vertically) and control characters are output as question marks; otherwise, the output is listed one per line and control characters are output as-is.', 'To prove it, try running', 'and then', 'This means that if you want the output to be guaranteed to be one file per line, regardless of whether it is being piped or redirected, you have to run', '(-1 is the number one)', 'Or, you can force ls | less to output in columns by running', '(-C is a capital C)']","[<code>ls</code>, <code>ls
</code>, <code>ls | less
</code>, <code>ls -1
</code>, <code>-1</code>, <code>ls | less</code>, <code>ls -C
</code>, <code>-C</code>]"
229,https://unix.stackexchange.com/questions/92447/,Bash script to get ASCII values for alphabet,"['Define these two functions (usually available in other languages):', 'Usage:']","[<code>chr() {
  [ ""$1"" -lt 256 ] || return 1
  printf ""\\$(printf '%03o' ""$1"")""
}

ord() {
  LC_CTYPE=C printf '%d' ""'$1""
}
</code>, <code>chr 65
A

ord A
65
</code>]"
230,https://unix.stackexchange.com/questions/22764/,Dashes in printf,"['The -- is used to tell the program that whatever follows should not be interpreted as a command line option to printf.', 'Thus the printf ""--"" you tried basically ended up as ""printf with no arguments"" and therefore failed.']","[<code>--</code>, <code>printf</code>, <code>printf ""--""</code>, <code>printf</code>]"
231,https://unix.stackexchange.com/questions/260630/,How do you list number of lines of every file in a directory in human readable format.,"['How many lines are in each file.', 'Use wc, originally for word count, I believe, but it can do lines, words, characters, bytes, and the longest line length. The -l option tells it to count lines.', 'This will output the number of lines in :', 'You can also pipe data to wc as well:', 'How many lines are in directory.', 'Try:', 'another one-liner:', 'BTW, wc command counts new lines codes, not lines. When last line in the file does not end with new line code, this will not counted.', 'You may use grep -c ^ , full example:', 'How many lines in total', 'Not sure that I understood you request correctly. e.g. this will output results in the following format, showing the number of lines for each file:', 'Alternatively, to output just the total number of new line characters without the file by file counts to following command can prove useful:', ""Most importantly, I need this in 'human readable format' eg.\n  12,345,678 rather than 12345678"", 'Bash has a printf function built in:', 'As always, there are many different methods that could be used to achieve the same results mentioned here.']","[<code>wc</code>, <code>-l</code>, <code>wc -l &lt;filename&gt;
</code>, <code>$ wc -l /dir/file.txt
32724 /dir/file.txt
</code>, <code>wc</code>, <code>$ cat /dir/file.txt | wc -l
32724
$ curl google.com --silent | wc -l
63
</code>, <code>find . -name '*.pl' | xargs wc -l
</code>, <code>( find ./ -name '*.pl' -print0 | xargs -0 cat ) | wc -l
</code>, <code>wc</code>, <code>#this example prints line count for all found files
total=0
find /path -type f -name ""*.php"" | while read FILE; do
     #you see use grep instead wc ! for properly counting
     count=$(grep -c ^ &lt; ""$FILE"")
     echo ""$FILE has $count lines""
     let total=total+count #in bash, you can convert this for another shell
done
echo TOTAL LINES COUNTED:  $total
</code>, <code># wc -l `find /path/to/directory/ -type f`
 103 /dir/a.php
 378 /dir/b/c.xml
 132 /dir/d/e.xml
 613 total
</code>, <code># find /path/to/directory/ -type f -exec wc -l {} \; | awk '{total += $1} END{print total}'
 613
</code>, <code>printf ""%0.2f\n"" $T
</code>]"
232,https://unix.stackexchange.com/questions/28791/,Prompt for sudo password and programmatically elevate privilege in bash script?,['I run sudo directly from the script:'],"[<code>sudo</code>, <code>if [ $EUID != 0 ]; then
    sudo ""$0"" ""$@""
    exit $?
fi
</code>]"
233,https://unix.stackexchange.com/questions/41292/,Variable substitution with an exclamation mark in bash,"['That is an indirect expansion, documented in man bash section EXPANSION, subsection Parameter Expansion:', 'If the first character of parameter is an exclamation point (!), a\n  level of variable indirection is introduced.  Bash uses the value of\n  the variable formed from the rest of parameter as the name of the\n  variable; this variable is then expanded and that value is used in the\n  rest of the substitution, rather than the value of parameter itself. \n  This is known as indirect expansion.']","[<code>man bash</code>, <code>bash-4.2$ DDF_SOURCE=""siebel_DATA_DATE_FORMAT""

bash-4.2$ siebel_DATA_DATE_FORMAT='Hello Indirect Redirection'

bash-4.2$ DATA_DATE_FORMAT=${!DDF_SOURCE} # siebel_DATA_DATE_FORMAT must get value before this line

bash-4.2$ echo $DATA_DATE_FORMAT
Hello Indirect Redirection
</code>]"
234,https://unix.stackexchange.com/questions/225943/,$@ except the 1st argument,"['First, note that $@ without quotes makes no sense and should not be used. $@ should only be used quoted (""$@"") and in list contexts.', 'for i in ""$@"" qualifies as a list context, but here, to loop over the positional parameters, the canonical, most portable and simpler form is:', 'Now, to loop over the elements starting from the second one, the canonical and most portable way is to use shift:', ""After shift, what used to be $1 has been removed from the list (but we've saved it in $first_arg) and what used to be in $2 is now in $1. The positional parameters have been shifted 1 position to the left (use shift 2 to shift by 2...). So basically, our loop is looping from what used to be the second argument to the last."", ""With bash (and zsh and ksh93, but that's it), an alternative is to do:"", ""But note that it's not standard sh syntax so should not be used in a script that starts with #! /bin/sh -."", 'In zsh or yash, you can also do:', 'to loop from the 3rd to the 3rd last argument.', 'In zsh, $@ is also known as the $argv array. So to pop elements from the beginning or end of the arrays, you can also do:', '(shift can also be written 1=() in zsh)', 'In bash, you can only assign to the $@ elements with the set builtin, so to pop 3 elements off the end, that would be something like:', 'And to loop from the 3rd to the 3rd last:', 'POSIXly, to pop the last 3 elements of ""$@"", you\'d need to use a loop:']","[<code>$@</code>, <code>$@</code>, <code>""$@""</code>, <code>for i in ""$@""</code>, <code>for i
do something with ""$i""
done
</code>, <code>shift</code>, <code>first_arg=$1
shift # short for shift 1
for i
do something with ""$i""
done
</code>, <code>shift</code>, <code>$1</code>, <code>$first_arg</code>, <code>$2</code>, <code>$1</code>, <code>1</code>, <code>shift 2</code>, <code>bash</code>, <code>zsh</code>, <code>ksh93</code>, <code>for i in ""${@:2}""
do something with ""$i""
done
</code>, <code>sh</code>, <code>#! /bin/sh -</code>, <code>zsh</code>, <code>yash</code>, <code>for i in ""${@[3,-3]}""
do something with ""$i""
done
</code>, <code>zsh</code>, <code>$@</code>, <code>$argv</code>, <code>argv[1,3]=() # remove the first 3 elements
argv[-3,-1]=()
</code>, <code>shift</code>, <code>1=()</code>, <code>zsh</code>, <code>bash</code>, <code>$@</code>, <code>set</code>, <code>set -- ""${@:1:$#-3}""
</code>, <code>for i in ""${@:3:$#-5}""
do something with ""$i""
done
</code>, <code>""$@""</code>, <code>n=$(($# - 3))
for arg do
  [ ""$n"" -gt 0 ] &amp;&amp; set -- ""$@"" ""$arg""
  shift
  n=$((n - 1))
done
</code>]"
235,https://unix.stackexchange.com/questions/85352/,How can I `alias sudo !!`?,"[""!! is expanded by bash when you type it. It's not expanded by alias substitution."", 'You can use the history built-in to do the expansion:', 'If the command is more than a simple command (e.g. it contains redirections or pipes), you need to invoke a shell under sudo:']","[<code>!!</code>, <code>history</code>, <code>alias sbb='sudo $(history -p !!)'
</code>, <code>alias sbb='sudo ""$BASH"" -c ""$(history -p !!)""'
</code>]"
236,https://unix.stackexchange.com/questions/368318/,Does the Bash star * wildcard always produce an (ascending) sorted list?,"[""In all shells, globs are sorted by default. They were already by the /etc/glob helper called by Ken Thompson's shell to expand globs in the first version of Unix in the early 70s (and which gave globs their name)."", ""For sh, POSIX does require them to be sorted by way of strcoll(), that is using the sorting order in the user's locale, like for ls though some still do it via strcmp(), that is based on byte values only."", 'You may notice above that for those shells that do sorting based on locale, here on a GNU system with a en_GB.UTF-8 locale, the - in the file names is ignored for sorting (most punctuation characters would). The ó is sorted in a more expected way (at least to British people), and case is ignored (except when it comes to decide ties).', ""However, you'll notice some inconsistencies for log① log②. That's because the sorting order of ① and ② is not defined in GNU locales (currently; hopefully it will be fixed some day). They sort the same, so you get random results."", 'Changing the locale will affect the sorting order. You can set the locale to C to get a strcmp()-like sort:', 'Note that some locales can cause some confusions even for all-ASCII all-alnum strings. Like Czech ones (on GNU systems at least) where ch is a collating element that sorts after h:', 'Or, as pointed out by @ninjalj, even weirder ones in Hungarian locales:', 'In zsh, you can choose the sorting with glob qualifiers. For instance:', 'The numeric sort of echo *(n) can also be enabled globally with the numericglobsort option:', 'If you (as I was) are confused by that order in that particular instance (here using my British locale), see here for details.']","[<code>/etc/glob</code>, <code>sh</code>, <code>strcoll()</code>, <code>ls</code>, <code>strcmp()</code>, <code>$ dash -c 'echo *'
Log01B log-0D log00 log01 log02 log0A log0B log0C log4E log4F log50 log① log② lóg01
$ bash -c 'echo *'
log① log② log00 log01 lóg01 Log01B log02 log0A log0B log0C log-0D log4E log4F log50
$ zsh -c 'echo *'
log① log② log00 log01 lóg01 Log01B log02 log0A log0B log0C log-0D log4E log4F log50
$ ls
log②  log①  log00  log01  lóg01  Log01B  log02  log0A  log0B  log0C  log-0D  log4E  log4F  log50
$ ls | sort
log②
log①
log00
log01
lóg01
Log01B
log02
log0A
log0B
log0C
log-0D
log4E
log4F
log50
</code>, <code>en_GB.UTF-8</code>, <code>-</code>, <code>ó</code>, <code>strcmp()</code>, <code>$ bash -c 'echo *'
log① log② log00 log01 lóg01 Log01B log02 log0.2 log0A log0B log0C log-0D log4E log4F log50
$ bash -c 'LC_ALL=C; echo *'
Log01B log-0D log0.2 log00 log01 log02 log0A log0B log0C log4E log4F log50 log① log② lóg01
</code>, <code>ch</code>, <code>h</code>, <code>$ LC_ALL=cs_CZ.UTF-8 bash -c 'echo *'
log0Ah log0Bh log0Dh log0Ch
</code>, <code>$ LC_ALL=hu_HU.UTF-8 bash -c 'echo *'
logX LOGx LOGX logZ LOGz LOGZ logY LOGY LOGy
</code>, <code>zsh</code>, <code>echo *(om) # to sort by modification time
echo *(oL) # to sort by size
echo *(On) # for a *reverse* sort by name
echo *(o+myfunction) # sort using a user-defined function
echo *(N)  # to NOT sort
echo *(n)  # sort by name, but numerically, and so on.
</code>, <code>echo *(n)</code>, <code>numericglobsort</code>, <code>$ zsh -c 'echo *'
log① log② log00 log01 lóg01 Log01B log02 log0.2 log0A log0B log0C log-0D log4E log4F log50
$ zsh -o numericglobsort -c 'echo *'
log① log② log00 lóg01 Log01B log0.2 log0A log0B log0C log01 log02 log-0D log4E log4F log50
</code>]"
237,https://unix.stackexchange.com/questions/23961/,How do I exit a script in a conditional statement?,"['You could do that this way:', '(""ordinary"" conditional expression with an arithmetic binary operator in the first statement), or:', '(arithmetic evaluation for the first test).', 'Notice the change () -> {} - the curly brackets do not spawn a subshell. (Search man bash for ""subshell"".)']","[<code>[[ $(id -u) -eq 0 ]] || { echo &gt;&amp;2 ""Must be root to run script""; exit 1; }
</code>, <code>(( $(id -u) == 0 )) || { echo &gt;&amp;2 ""Must be root to run script""; exit 1; }
</code>, <code>()</code>, <code>{}</code>, <code>man bash</code>]"
238,https://unix.stackexchange.com/questions/6035/,When do you use brace expansion?,"['Brace expansion is very useful if you have long path names. I use it as a quick way to backup a file:', 'will copy /a/really/long/path/to/some/file.txt to /a/really/long/path/to/some/file.txt.bak', 'You can also use it in a sequence. I once did so to download lots of pages from the web:', 'or']","[<code>cp /a/really/long/path/to/some/file.txt{,.bak}
</code>, <code>/a/really/long/path/to/some/file.txt</code>, <code>/a/really/long/path/to/some/file.txt.bak</code>, <code>wget http://domain.com/book/page{1..5}.html
</code>, <code>for i in {1..100}
do
   #do something 100 times
done
</code>]"
239,https://unix.stackexchange.com/questions/131801/,"Closing a file descriptor, >&- vs <&-","['You can close file descriptor using both <&- and >&-, bash will parse two syntax as the same.', 'From file y.tab.c in bash source code:']","[<code>&lt;&amp;-</code>, <code>&gt;&amp;-</code>, <code>bash</code>, <code>bash</code>, <code>5385   /* Hack &lt;&amp;- (close stdin) case.  Also &lt;&amp;N- (dup and close). */                
5386   if MBTEST(character == '-' &amp;&amp; (last_read_token == LESS_AND || last_read_token == GREATER_AND))
5387     return (character);
</code>]"
240,https://unix.stackexchange.com/questions/107851/,Using export in .bashrc,"['You only need export for variables that should be ""seen"" by other programs which you launch in the shell, while the ones that are only used inside the shell itself don\'t need to be exported.', 'This is what the man page says:', 'This can be demonstrated with the following:', 'Explanation:', 'So to answer your question:', 'It depends where a variable is going to be used, whether you have to export it or not.']","[<code>export</code>, <code>export</code>, <code>The  supplied  names are marked for automatic export to the environ‐
ment of subsequently executed commands.  If the -f option is  given,
the  names  refer to functions.  If no names are given, or if the -p
option is supplied, a list of all names that are  exported  in  this
shell  is  printed.   The -n option causes the export property to be
removed from each name.  If a variable name is  followed  by  =word,
the  value  of  the variable is set to word.  export returns an exit
status of 0 unless an invalid option  is  encountered,  one  of  the
names  is  not a valid shell variable name, or -f is supplied with a
name that is not a function.
</code>, <code>$ MYVAR=""value""
$ echo ${MYVAR}
value
$ echo 'echo ${MYVAR}' &gt; echo.sh
$ chmod +x echo.sh
$ ./echo.sh

$ export MYVAR=""value-exported""
$ ./echo.sh
value-exported
</code>, <code>${MYVAR}</code>, <code>MYVAR=""value""</code>, <code>echo</code>, <code>echo.sh</code>, <code>${MYVAR}</code>, <code>echo.sh</code>, <code>${MYVAR}</code>, <code>${MYVAR}</code>, <code>export</code>, <code>echo.sh</code>, <code>${MYVAR}</code>]"
241,https://unix.stackexchange.com/questions/90990/,less command and syntax highlighting,"['Syntax highlighting of less, works just fine on most *nix systems. ', 'On Fedora/RedHat based distros use /usr/bin/src-hilite-lesspipe.sh instead.', 'Even on Cygwin you can do it with the minor adjustment of the shell script path and installing with apt-cyg instead of apt.', 'However, using this drastically slows down browsing of large files. I suggest to use alias in such a way to only implement the LESSOPEN export above when needed, like this:', 'where the -M flag is convenient to also show filename and line number.', 'Also remember to copy the script into your bin path: ', 'UPDATE: 2019-07-24', 'Apparently, on more recent Cygwin installs, you have the following files in your path: ', 'So now you also need to execute the source-highlight-settings.exe that will add the configuration file:\n$HOME/.source-highlight/source-highlight.conf. ']","[<code>less</code>, <code>apt install source-highlight
export LESSOPEN=""| /usr/share/source-highlight/src-hilite-lesspipe.sh %s""
export LESS=' -R '
</code>, <code>/usr/bin/src-hilite-lesspipe.sh</code>, <code>apt-cyg</code>, <code>apt</code>, <code>alias</code>, <code>LESSOPEN</code>, <code>alias lessh='LESSOPEN=""| /usr/bin/src-hilite-lesspipe.sh %s"" less -M '
</code>, <code>-M</code>, <code>cp /usr/share/source-highlight/src-hilite-lesspipe.sh /usr/bin/src-hilite-lesspipe.sh
</code>, <code>source-highlight.exe
source-highlight-esc.sh
source-highlight-settings.exe
</code>, <code>source-highlight-settings.exe</code>, <code>$HOME/.source-highlight/source-highlight.conf</code>]"
242,https://unix.stackexchange.com/questions/60257/,How to create a sequence with leading zeroes using brace expansion,"['Prefix the first number with a 0 to force each term to have the same  width.', 'From the bash man page section on Brace Expansion:', 'Supplied integers may be prefixed with 0 to force each term to have\n  the same  width.  When  either  x or y begins with a zero, the shell\n  attempts to force all generated terms to contain the same number of\n  digits, zero-padding where necessary.', 'Also note that you can use seq with the -w option to equalize width by padding with leading zeroes:', 'If you want more control, you can even specify a printf style format:']","[<code>0</code>, <code>$ echo {08..10}
08 09 10
</code>, <code>seq</code>, <code>-w</code>, <code>$ seq -w 8 10
08
09
10

$ seq -s "" "" -w 8 10
08 09 10
</code>, <code>$ seq -s "" "" -f %02g 8 10
08 09 10
</code>]"
243,https://unix.stackexchange.com/questions/2897/,CLICOLOR and LS_COLORS in bash,"[""There are several different implementations of color for ls, and you've conflated some of them."", 'On FreeBSD and Mac\xa0OS\xa0X, ls shows colors if the CLICOLOR environment variable is set or if -G is passed on the command line. The actual colors are configured through the LSCOLORS environment variable (built-in defaults are used if this variable is not set). To show directories in light blue, use', 'With GNU ls, e.g. on Linux, ls shows colors if --color is passed on the command line. The actual colors are configured through the LS_COLORS environment variable, which can be set with the dircolors command (built-in defaults are used if this variable is not set).']","[<code>ls</code>, <code>CLICOLOR</code>, <code>-G</code>, <code>LSCOLORS</code>, <code>export LSCOLORS=Exfxcxdxbxegedabagacad
</code>, <code>ls</code>, <code>--color</code>, <code>LS_COLORS</code>, <code>dircolors</code>]"
244,https://unix.stackexchange.com/questions/250913/,Is there any reason to have a shebang pointing at /bin/sh rather than /bin/bash?,[],[<code>/bin</code>]
245,https://unix.stackexchange.com/questions/79068/,"How to export variables that are set, all at once?","['Run the following command, before setting the variables:', 'man page : ', '-a\n      When this option is on, the export attribute shall be set for each variable to which an assignment is performed;', 'To turn this option off, run set +a afterwards. ', 'Example:', 'Where environment contains:']","[<code>set -a 
</code>, <code>-a</code>, <code>set +a</code>, <code>set -a
. ./environment
set +a
</code>, <code>environment</code>, <code>FOO=BAR
BAS='quote when using spaces'
</code>]"
246,https://unix.stackexchange.com/questions/85021/,"In Bash scripting, what's the meaning of "" $! ""?","['$! contains the process ID of the most recently executed background pipeline. From man bash:', 'The shell treats several parameters specially.  These parameters may only be referenced; assignment to them is not allowed.', '...', '! - Expands to the process ID of the  most  recently  executed  background (asynchronous) command.', 'For example:']","[<code>$!</code>, <code>man bash</code>, <code>!</code>, <code>$ sleep 60 &amp;
[1] 6238
$ echo ""$!""
6238
</code>]"
247,https://unix.stackexchange.com/questions/475353/,Change permisions of a file with my cat's help,"[""There are several possibilities, all depending on the exact parameters of your situation right now. I'm going to assume Linux in the following examples where applicable, but similar functionality exists on other platforms in most cases."", ""You might be able to get the dynamic loader to run an executable for you. Assuming cat is dynamically-linked, your platform's equivalent of /lib/ld-linux.so.2 will likely also be in memory and thus usable to run a binary:"", 'You may have multiple of these (32- and 64-bit are likely) and there may be multiple copies available, or symlinks that need resolving. One of those may work.', 'If you have a mounted vfat or NTFS filesystem, or another that treats all files as 777, you can create your executable on there.', ""If there's a mounted partition you don't care about the contents of, on a drive that is still mostly working, you can replace the contents with a new image of the same filesystem type containing executables you want - cat should be fine for this in the role people usually use dd for, and you can provide the image over the network."", 'This one is plausible, but has a lot of places not to work depending on what exactly is still in memory from that partition.', 'If there is any accessible file that has execute permission on any writable filesystem, you can cat > into it to replace the contents with a binary of your choosing.', 'You could bring in a dynamic library file foo.so of your construction and then have cat load it on your behalf by way of LD_PRELOAD, allowing you to execute arbitrary code.', 'If you intercept, for example, open:', 'then you can do whatever you need to do in there.', ""My suggestion would be to bring in a statically-linked busybox executable as the first item (or really, only item) so that you've got the full range of commands available without reusing whatever hack got you to that point to exhaustion.""]","[<code>cat</code>, <code>/lib/ld-linux.so.2</code>, <code>$ /lib64/ld-linux-x86-64.so.2 ./chmod
chmod: missing operand
</code>, <code>$ cat &gt; /mnt/windows/chmod &lt; /dev/tcp/localhost/9999
</code>, <code>cat</code>, <code>dd</code>, <code>$ cat &gt; /dev/sdb1 &lt; ...
</code>, <code>cat &gt;</code>, <code>$ cat &gt; ~/test.py &lt; ...
</code>, <code>ctypes.sh</code>, <code>dlcall chmod ./netcat 511</code>, <code>foo.so</code>, <code>cat</code>, <code>LD_PRELOAD</code>, <code>$ LD_PRELOAD=./hack.so cat /dev/null
</code>, <code>open</code>, <code>int open(const char *path, int flags, ...) {
    chmod(path, 0755);
    return -1;
}
</code>, <code>busybox</code>]"
248,https://unix.stackexchange.com/questions/16109/,Bash: double equals vs -eq,"[""== is a bash-specific alias for =, which performs a string (lexical) comparison instead of the -eq numeric comparison.  (It's backwards from Perl:  the word-style operators are numeric, the symbolic ones lexical.)""]","[<code>==</code>, <code>bash</code>, <code>=</code>, <code>-eq</code>]"
249,https://unix.stackexchange.com/questions/158933/,How do I open an incognito bash session?,"['When you want bash to stop logging your commands, just unset the HISTFILE variable:', 'All further commands should then no longer be logged to .bash_history.', ""On the other hand, if you are actually supplying passwords as arguments to commands, you're already doing something wrong. .bash_history is not world-readable and therefore not the biggest threat in this situation:"", ""ps and /proc are the big problem. All users on the system can see the commands you're currently running with all of their arguments. Passing passwords as command line arguments is therefore inherently insecure. Use environment variables or config files (that you have chmodded 600) to securely supply passwords.""]","[<code>bash</code>, <code>HISTFILE</code>, <code>HISTFILE=
</code>, <code>.bash_history</code>, <code>.bash_history</code>, <code>ps</code>, <code>/proc</code>]"
250,https://unix.stackexchange.com/questions/144208/,find files without extension,"['you could use: find . -type f ! -name ""*.*""\nthe ! negates the following expression, here a filename that contains a \'.\'', 'you can also use the -maxdepth option to reduce the search depth.']","[<code>find . -type f ! -name ""*.*""</code>, <code>!</code>, <code>-maxdepth</code>]"
251,https://unix.stackexchange.com/questions/60849/,Find files in multiple folder names,"['And if you want to search three folders named foo, bar, and baz for all *.py files, use this command:', 'find foo bar baz -name ""*.py""', 'so if you want to display files from dir1 dir2 dir3 use find dir1 dir2 dir3 -type f', 'try this find . \\( -name ""dir1"" -o -name ""dir2"" \\) -exec ls \'{}\' \\;']","[<code>foo</code>, <code>bar</code>, <code>baz</code>, <code>*.py</code>, <code>find foo bar baz -name ""*.py""</code>, <code>dir1</code>, <code>dir2</code>, <code>dir3</code>, <code>find dir1 dir2 dir3 -type f</code>, <code>find . \( -name ""dir1"" -o -name ""dir2"" \) -exec ls '{}' \;</code>]"
252,https://unix.stackexchange.com/questions/76717/,Launch a background process and check when it ends,"['The key is the ""wait"" command:']","[<code>#!/bin/bash

/my/process &amp;
/another/process &amp;
wait
echo ""All processes done!""
</code>]"
253,https://unix.stackexchange.com/questions/29509/,Transform an array into arguments of a command?,"['I would prefer a plain bash way:', 'One reason for this are the spaces. For example if you have:', 'The sed based solutions will transform it in -option1 -option2 -with -space -option3 (length 5), but the above bash expansion will transform it into -option1 -option2 with space -option3 (length still 3). Rarely, but sometimes this is important, for example:']","[<code>bash</code>, <code>command ""${my_array[@]/#/-}"" ""$1""
</code>, <code>my_array=(option1 'option2 with space' option3)
</code>, <code>sed</code>, <code>-option1 -option2 -with -space -option3</code>, <code>bash</code>, <code>-option1 -option2 with space -option3</code>, <code>bash-4.2$ my_array=('Ffoo bar' 'vOFS=fiz baz')
bash-4.2$ echo 'one foo bar two foo bar three foo bar four' | awk ""${my_array[@]/#/-}"" '{print$2,$3}'
 two fiz baz three
</code>]"
254,https://unix.stackexchange.com/questions/24739/,How to execute consecutive commands from history?,"['If it refers to commands run just recently, a more efficient way is to reference them with negative numbers:', 'Also, once you do it, your last history entry will contain the whole chain of commands, so you can repeat it with !!.', ""Edit:\nIf you haven't already, get familiar with the great builtin function fc, mentioned by Gilles. (Use help fc.) It turns out that you can also use negative numbers with it, so you could do the same as above using"", ""This has one caveat, though: after this, the eval line is stored in the history as the last command. So if you run this again, you'll fall into a loop!"", 'A safer way of doing this is to use the default fc operation mode: forwarding the selected range of commands to an editor and running them once you exit from it. Try:', 'You can even reverse the order of the range of commands: fc -1 -4']","[<code>!-4; !-3; !-2; !-1
</code>, <code>!!</code>, <code>fc</code>, <code>help fc</code>, <code>eval ""`fc -ln -4 -1`""
</code>, <code>eval</code>, <code>fc</code>, <code> fc -4 -1
</code>, <code>fc -1 -4</code>]"
255,https://unix.stackexchange.com/questions/26063/,How are parentheses interpreted at the command line?,"['Parentheses denote a subshell in bash.  To quote the man bash page:', 'where a list is just a normal sequence of commands.', 'This is actually quite portable and not specific to just bash though.  The POSIX Shell Command Language spec has the following description for the (compound-list) syntax:', 'Execute compound-list in a subshell environment; see Shell Execution Environment. Variable assignments and built-in commands that affect the environment shall not remain in effect after the list finishes.']","[<code>man bash</code>, <code>(list)    list  is  executed  in  a  subshell  environment (see COMMAND
          EXECUTION ENVIRONMENT below).  Variable assignments and builtin 
          commands that affect the shell's environment do not remain in 
          effect after the command completes.  The return status is the
          exit status of list.
</code>, <code>list</code>, <code>bash</code>, <code>(compound-list)</code>]"
256,https://unix.stackexchange.com/questions/330660/,Prevent grep from exiting in case of nomatch,"['Explanation:', 'The ""||"" means ""or"". If the first part of the command ""fails"" (meaning ""grep e"" returns a non-zero exit code) then the part after the ""||"" is executed, succeeds and returns zero as the exit code  (true always returns zero).']","[<code>echo ""anything"" | { grep e || true; }
</code>, <code>$ echo ""anything"" | grep e
### error
$ echo $?
1
$ echo ""anything"" | { grep e || true; }
### no error
$ echo $?
0
### DopeGhoti's ""no-op"" version
### (Potentially avoids spawning a process, if `true` is not a builtin):
$ echo ""anything"" | { grep e || :; }
### no error
$ echo $?
0
</code>, <code>true</code>]"
257,https://unix.stackexchange.com/questions/139115/,Disable CTRL-D from closing my window with the terminator terminal emulator),"['You can also disable eof generally in bash:', 'set -o ignoreeof']",[<code>set -o ignoreeof</code>]
258,https://unix.stackexchange.com/questions/4870/,Is it possible to have vim key bindings in terminal?,"['It has insert and normal mode (the insert mode is default, and escape for normal mode) but no visual mode.', 'In bash: set -o vi You can run it at the command line for just this session or add it to your .bashrc file.', 'Many programs use readline for input, and you can make any of them use vi-style keybindings by setting up your .inputrc with', 'In zsh, if you change your EDITOR environment variable, the shell will match it.']","[<code>set -o vi</code>, <code>readline</code>, <code>.inputrc</code>, <code>set editing-mode vi
set keymap vi
</code>, <code>EDITOR</code>]"
259,https://unix.stackexchange.com/questions/9597/,giving grep output to rm,"['You need to use xargs to turn standard input into arguments for rm.', '(Beware of special characters in filenames; with GNU grep, you might prefer', ')', ""Also, while the shell doesn't use regexps, that's a simple pattern:"", '(meanwhile, I think I need more sleep.)']","[<code>xargs</code>, <code>rm</code>, <code>$ ls | grep '^Dar' | xargs rm
</code>, <code>$ ls | grep -Z '^Dar' | xargs -0 rm
</code>, <code>$ rm Dar*
</code>]"
260,https://unix.stackexchange.com/questions/58310/,Difference between printf and echo in bash,"['The difference is that echo sends a newline at the end of its output. There is no way to ""send"" an EOF.']",[<code>echo</code>]
261,https://unix.stackexchange.com/questions/65075/,Delete last N lines from bash history,"[""As of bash-5.0-alpha, the history command now takes a range for the delete (-d) option. See rastafile's answer."", 'For older versions, workaround below.', ""You can use history -d offset builtin to delete a specific line from the current shell's history, or history -c to clear the whole history."", ""It's not really practical if you want to remove a range of lines, since it only takes one offset as an argument, but you could wrap it in a function with a loop."", 'Call it with rmhist first_line_to_delete last_line_to_delete. (Line numbers according to the output of history.)', '(Use history -w to force a write to the history file.)']","[<code>bash-5.0-alpha</code>, <code>history</code>, <code>-d</code>, <code>history -d offset</code>, <code>history -c</code>, <code>rmhist() {
    start=$1
    end=$2
    count=$(( end - start ))
    while [ $count -ge 0 ] ; do
        history -d $start
        ((count--))
    done
}
</code>, <code>rmhist first_line_to_delete last_line_to_delete</code>, <code>history</code>, <code>history -w</code>]"
262,https://unix.stackexchange.com/questions/271659/,$_ vs !$. Last argument of the preceding command and output redirection,"['!$ is a word designator of history expansion, it expands to the last word of previous command in history. IOW, the last word of previous entry in history. This word is usually the last argument to command, but not in case of redirection. In:', 'the whole command \'echo ""hello"" > /tmp/a.txt\' appeared in history, and /tmp/a.txt is the last word of that command.', ""_ is a shell parameter, it expands to last argument of previous command. Here, the redirection is not a part of arguments passed to the command, so only hello is the argument passed to echo. That's why $_ expanded to hello."", '_ is not one of shell standard special parameters anymore. It works in bash, zsh, mksh and dash only when interactive, ksh93 only when two command are on separated lines:']","[<code>!$</code>, <code>echo ""hello"" &gt; /tmp/a.txt
</code>, <code>'echo ""hello"" &gt; /tmp/a.txt'</code>, <code>/tmp/a.txt</code>, <code>_</code>, <code>hello</code>, <code>echo</code>, <code>$_</code>, <code>hello</code>, <code>_</code>, <code>bash</code>, <code>zsh</code>, <code>mksh</code>, <code>dash</code>, <code>ksh93</code>, <code>$ echo 1 &amp;&amp; echo $_
1
/usr/bin/ksh

$ echo 1
1
$ echo $_
1
</code>]"
263,https://unix.stackexchange.com/questions/75046/,"why does ls -d also list files, and where is it documented?","['The a* and *a* syntax is implemented by the shell, not by the ls command.', 'When you type', 'at your shell prompt, the shell expands a* to a list of existing all files in the current directory whose names start with a. For example, it might expand a* to the sequence a1 a2 a3, and pass those as arguments to ls. The ls command itself never sees the * character; it only sees the three arguments a1, a2, and a3.', 'For purposes of wildcard expansion, ""files"" refers to all entities in the current directory. For example, a1 might be a normal file, a2 might be a directory, and a3 might be a symlink. They all have directory entries, and the shell\'s wildcard expansion doesn\'t care what kind of entity those entries refer to.', ""Practically all shells you're likely to run across (bash, sh, ksh, zsh, csh, tcsh, ...) implement wildcards. The details may vary, but the basic syntax of * matching zero or more characters and ? matching any single character is reasonably consistent."", 'For bash in particular, this is documented in the ""Filename expansion"" section of the bash manual; run info bash and search for ""Filename expansion"", or see here.', 'The fact that this is done by the shell, and not by individual commands, has some interesting (and sometimes surprising) consequences.  The best thing about it is that wildcard handling is consistent for (very nearly) all commands; if the shell didn\'t do this, inevitably some commands wouldn\'t bother, and others would do it in subtly different ways that the author thought was ""better"". (I think the Windows command shell has this problem, but I\'m not familiar enough with it to comment further.)', ""On the other hand, it's difficult to write a command to rename multiple files. If you write:"", ""it will probably fail, since*.log.bak is expanded based on the files that already exist in the current directory. There are commands that do this kind of thing, but they have to use their own syntax to specify how the files are to be renamed. Some commands (such as find) can do their own wildcard expansion; you have to quote the arguments to suppress the shell's expansion:"", ""The shell's wildcard expansion is based entirely on the syntax of the command-line argument and the set of existing files. It can't be affected by the meaning of the command. For example, if you want to move all .log files up to the parent directory, you can type:"", 'If you forget the .. :', 'and there happen to be exactly two .log files in the current directory, it will expand to:', 'which will rename one.log and clobber two.log.', 'EDIT: And after 52 upvotes, an accept, and a Guru badge, maybe I should actually answer the question in the title.', ""The -d or --directory option to ls doesn't tell it to list only directories. It tells it to list directories just as themselves, not their contents. If you give a directory name as an argument to ls, by default it will list the contents of the directory, since that's usually what you're interested in. The -d option tells it to list just the directory itself. This can be particularly useful when combined with wildcards. If you type:"", 'ls will give you a long listing of each file whose name starts with a, and of the contents of each directory whose name starts with a. If you just want a list of the files and directories, one line for each, you can use:', 'which is equivalent to:', 'Remember again that the ls command never sees the * character.', ""As for where this is documented, man ls will show you the documentation for the ls command on just about any Unix-like system. On most Linux-based systems, the ls command is part of the GNU coreutils package; if you have the info command, either info ls or info coreutils ls should give you more definitive and comprehensive documentation. Other systems, such as MacOS, may use different versions of the ls command, and may not have the info command; for those systems, use man ls. And ls --help will show a relatively short usage message (117 lines on my system) if you're using the GNU coreutils implementation."", 'And yes, even experts need to consult the documentation now and then. See also this classic joke.']","[<code>a*</code>, <code>*a*</code>, <code>ls</code>, <code>ls a*
</code>, <code>a*</code>, <code>a</code>, <code>a*</code>, <code>a1 a2 a3</code>, <code>ls</code>, <code>ls</code>, <code>*</code>, <code>a1</code>, <code>a2</code>, <code>a3</code>, <code>a1</code>, <code>a2</code>, <code>a3</code>, <code>*</code>, <code>?</code>, <code>info bash</code>, <code>mv *.log *.log.bak
</code>, <code>*.log.bak</code>, <code>find</code>, <code>find . -name '*.txt' -print
</code>, <code>.log</code>, <code>mv *.log ..
</code>, <code>..</code>, <code>mv *.log
</code>, <code>.log</code>, <code>mv one.log two.log
</code>, <code>one.log</code>, <code>two.log</code>, <code>-d</code>, <code>--directory</code>, <code>ls</code>, <code>ls</code>, <code>-d</code>, <code>ls -l a*
</code>, <code>ls</code>, <code>a</code>, <code>a</code>, <code>ls -ld a*
</code>, <code>ls -l -d a*
</code>, <code>ls</code>, <code>*</code>, <code>man ls</code>, <code>ls</code>, <code>ls</code>, <code>info</code>, <code>info ls</code>, <code>info coreutils ls</code>, <code>ls</code>, <code>info</code>, <code>man ls</code>, <code>ls --help</code>]"
264,https://unix.stackexchange.com/questions/118577/,"Changing a file's ""Date Created"" and ""Last Modified"" attributes to another file's","[""You can use the touch command along with the -r switch to apply another file's attributes to a file."", 'NOTE: There is no such thing as creation date in Unix, there are only access, modify, and change. See this U&L Q&A titled: get age of given file for further details.', ""For example purposes here's a goldenfile that was created with some arbitrary timestamp."", 'Now I make some new file:', ""Now apply goldenfile's attributes to newfile."", 'Now newfile has the same attributes.', ""I just confirmed that I'm able to do this using my Fedora 19 laptop which includes version 1.16.3-2 connected to a Thecus N12000 NAS (uses a modified version of CentOS 5.x)."", ""I was able to touch a file as I mentioned above and it worked as I described. Your issue is likely a problem with the either the mounting options being used, which may be omitting the tracking of certain time attributes, or perhaps it's related to one of these bugs:""]","[<code>touch</code>, <code>-r</code>, <code>$ touch -r goldenfile newfile
</code>, <code>goldenfile</code>, <code>$ touch -d 20120101 goldenfile
$ ls -l goldenfile 
-rw-rw-r--. 1 saml saml 0 Jan  1  2012 goldenfile
</code>, <code>$ touch newfile
$ ls -l newfile 
-rw-rw-r--. 1 saml saml 0 Mar  7 09:06 newfile
</code>, <code>goldenfile</code>, <code>newfile</code>, <code>$ touch -r goldenfile newfile 
$ ls -l goldenfile newfile
-rw-rw-r--. 1 saml saml 0 Jan  1  2012 newfile
-rw-rw-r--. 1 saml saml 0 Jan  1  2012 goldenfile
</code>, <code>newfile</code>]"
265,https://unix.stackexchange.com/questions/131180/,How to move a file without preserving permissions,"[""mv is the wrong tool for this job; you want cp and then rm.  Since you're moving the file to another filesystem this is exactly what mv is doing behind the scenes anyway, except that mv is also trying to preserve file permission bits and owner/group information.  This is because mv would preserve that information if it were moving a file within the same filesystem and mv tries to behave the same way in both situations.  Since you don't care about the preservation of file permission bits and owner/group information, don't use that tool.  Use cp --no-preserve=mode and rm instead.""]","[<code>mv</code>, <code>cp</code>, <code>rm</code>, <code>mv</code>, <code>mv</code>, <code>mv</code>, <code>mv</code>, <code>cp --no-preserve=mode</code>, <code>rm</code>]"
266,https://unix.stackexchange.com/questions/157763/,Do we have more history for cd?,"['The command you are looking for is pushd and popd.', 'You could view a practical working example of pushd and popd from here.']","[<code>pushd</code>, <code>popd</code>, <code>pushd</code>, <code>popd</code>, <code>mkdir /tmp/dir1
mkdir /tmp/dir2
mkdir /tmp/dir3
mkdir /tmp/dir4

cd /tmp/dir1
pushd .

cd /tmp/dir2
pushd .

cd /tmp/dir3
pushd .

cd /tmp/dir4
pushd .

dirs
/tmp/dir4 /tmp/dir4 /tmp/dir3 /tmp/dir2 /tmp/dir1
</code>]"
267,https://unix.stackexchange.com/questions/184508/,nvm command not available in bash script,"['nvm command is a shell function declared in ~/.nvm/nvm.sh.', 'You may source either of following scripts at the start of yours to make nvm() available:']","[<code>nvm</code>, <code>~/.nvm/nvm.sh</code>, <code>nvm()</code>, <code>. ~/.nvm/nvm.sh
. ~/.profile
. ~/.bashrc
. $(brew --prefix nvm)/nvm.sh  # if installed via Brew
</code>]"
268,https://unix.stackexchange.com/questions/254494/,How does bash differentiate between brace expansion and command grouping?,"['A simplified reason is the existence of one character: space.', 'Brace expansions do not process (un-quoted) spaces.', 'A {...} list needs (un-quoted) spaces.', 'The more detailed answer is how the shell parses a command line.', 'The first step to parse (understand) a command line is to divide it into parts.\nThese parts (usually called words or tokens) result from dividing a command line at each meta-character from the link:', 'Meta-characters: spacetabenter;,<>| and &.', 'After splitting, words may be of a type (as understood by the shell): ', 'Only if a ""brace string"" (without spaces or meta-characters) is a single word (as described above) and is not quoted, it is a candidate for ""Brace expansion"". More checks are performed on the internal structure later.', 'Thus, this: {ls,-l} qualifies as ""Brace expansion"" to become ls -l, either as first word or argument (in bash, zsh is different).', 'But this will not: {ls ,-l}. Bash will split on space and parse the line as two words: {ls and ,-l} which will trigger a command not found (the argument ,-l} is lost):', 'Your line: {ls;echo hi} will not become a ""Brace expansion"" because of the two meta-characters ; and space.', 'It will be broken into this three parts: {ls new command: echo hi}. Understand that the ; triggers the start of a new command. The command {ls will not be found, and the next command will print hi}:', 'If it is placed after some other command, it will anyway start a new command after the ;:', 'One of the ""compound commands"" is a ""Brace List"" (my words): { list; }.\nAs you can see, it is defined with spaces and a closing ;.\nThe spaces and ; are needed because both { and } are ""Reserved Words"".  ', 'And therefore, to be recognized as words, must be surrounded by meta-characters (almost always: space).', 'As described in the point 2 of the linked page', 'Your example: {ls;echo hi} is not a list.', 'It needs a closing ; and one space (at least) after {. The last } is defined by the closing ;.', 'This is a list { ls;echo hi; }. And this { ls;echo hi;} is also (less commonly used, but valid)(Thanks @choroba for the help).', 'But as argument (the shell knows the difference) to a command, it triggers an error:', 'But be careful in what you believe the shell is parsing:']","[<code>{...}</code>, <code> LC=ALL ... </code>, <code>                LC=ALL echo </code>, <code>                LC=ALL echo ""hello"" </code>, <code>                LC=ALL echo ""hello"" &gt;&amp;2 </code>, <code>{ls,-l}</code>, <code>ls -l</code>, <code>first word</code>, <code>argument</code>, <code>$ {ls,-l}            ### executes `ls -l`
$ echo {ls,-l}       ### prints `ls -l`
</code>, <code>{ls ,-l}</code>, <code>{ls</code>, <code>,-l}</code>, <code>command not found</code>, <code>,-l}</code>, <code> $ {ls ,-l}
 bash: {ls: command not found
</code>, <code>{ls;echo hi}</code>, <code>{ls</code>, <code>echo</code>, <code>hi}</code>, <code>{ls</code>, <code>hi}</code>, <code>$ {ls;echo hi}
bash: {ls: command not found
hi}
</code>, <code>$ echo {ls;echo hi}
{ls
hi}
</code>, <code>{ list; }</code>, <code>;</code>, <code>{</code>, <code>}</code>, <code>{ls;echo hi}</code>, <code>{ ls;echo hi; }</code>, <code>{ ls;echo hi;}</code>, <code>$ { ls;echo hi; }
A-list-of-files
hi
</code>, <code>$ echo { ls;echo hi; }
bash: syntax error near unexpected token `}'
</code>, <code>$ echo { ls;echo hi;
{ ls
hi
</code>]"
269,https://unix.stackexchange.com/questions/330414/,Intended use of ctrl+T in bash?,"['This is inherited (by readline) from GNU Emacs, which uses control-T for transposing characters:', 'https://www.gnu.org/software/emacs/manual/html_node/emacs/Transpose.html', ""Note that bash's line editor defaults to Emacs mode, but you can also switch it to vi mode, if you prefer.""]",[]
270,https://unix.stackexchange.com/questions/212872/,How to get last N commands from history?,"['I found it!', 'history [n]', 'An argument of n lists only the last n lines.']","[<code>$ echo ""hello
how are you""
$ history 2
1060  echo ""hello
how are you""
1061  history 2
</code>]"
271,https://unix.stackexchange.com/questions/113795/,Add thousands separator in a number,"['With sed:', '(Note that this only works for exactly 9 digits!)', 'or this with sed:', 'With printf:']","[<code>sed</code>, <code>$ echo ""123456789"" | sed 's/\([[:digit:]]\{3\}\)\([[:digit:]]\{3\}\)\([[:digit:]]\{3\}\)/\1,\2,\3/g'
123,456,789
</code>, <code>sed</code>, <code>$ echo ""123456789"" | sed ':a;s/\B[0-9]\{3\}\&gt;/,&amp;/;ta'
123,456,789
</code>, <code>printf</code>, <code>$ LC_NUMERIC=en_US printf ""%'.f\n"" 123456789
123,456,789
</code>]"
272,https://unix.stackexchange.com/questions/24509/,How to print the longest line in a file?,['UPD: summarizing all the advices in the comments'],"[<code>cat ./text | awk ' { if ( length &gt; x ) { x = length; y = $0 } }END{ print y }'
</code>, <code>awk 'length &gt; max_length { max_length = length; longest_line = $0 } END { print longest_line }' ./text 
</code>]"
273,https://unix.stackexchange.com/questions/213799/,Can bash write to its own input stream?,"['With zsh, you can use print -z to place some text into the line editor buffer for the next prompt:', 'would prime the line editor with echo test which you can edit at the next prompt.', ""I don't think bash has a similar feature, however on many systems, you can prime the terminal device input buffer with the TIOCSTI ioctl():"", 'Would insert echo test into the terminal device input buffer, as if received from the terminal.', ""A more portable variation on @mike's Terminology approach and that doesn't sacrifice security would be to send the terminal emulator a fairly standard query status report escape sequence: <ESC>[5n which terminals invariably reply (so as input) as <ESC>[0n and bind that to the string you want to insert:"", 'If within GNU screen, you can also do:', ""Now, except for the TIOCSTI ioctl approach, we're asking the terminal emulator to send us some string as if typed. If that string comes before readline (bash's line editor) has disabled terminal local echo, then that string will be displayed not at the shell prompt, messing up the display slightly."", 'To work around that, you could either delay the sending of the request to the terminal slightly to make sure the response arrives when the echo has been disabled by readline.', '(here assuming your sleep supports sub-second resolution).', ""Ideally you'd want to do something like:"", ""However bash (contrary to zsh) doesn't have support for such a wait-until-the-response-arrives that doesn't read the response."", 'However it has a has-the-response-arrived-yet feature with read -t0:', ""See @starfry's answer's that expands on the two solutions given by @mikeserv and myself with a few more detailed information.""]","[<code>zsh</code>, <code>print -z</code>, <code>print -z echo test
</code>, <code>echo test</code>, <code>bash</code>, <code>TIOCSTI</code>, <code>ioctl()</code>, <code>perl -e 'require ""sys/ioctl.ph""; ioctl(STDIN, &amp;TIOCSTI, $_)
  for split """", join "" "", @ARGV' echo test
</code>, <code>echo test</code>, <code>Terminology</code>, <code>query status report</code>, <code>&lt;ESC&gt;[5n</code>, <code>&lt;ESC&gt;[0n</code>, <code>bind '""\e[0n"": ""echo test""'; printf '\e[5n'
</code>, <code>screen</code>, <code>screen -X stuff 'echo test'
</code>, <code>readline</code>, <code>bash</code>, <code>bind '""\e[0n"": ""echo test""'; ((sleep 0.05;  printf '\e[5n') &amp;)
</code>, <code>sleep</code>, <code>bind '""\e[0n"": ""echo test""'
stty -echo
printf '\e[5n'
wait-until-the-response-arrives
stty echo
</code>, <code>bash</code>, <code>zsh</code>, <code>wait-until-the-response-arrives</code>, <code>has-the-response-arrived-yet</code>, <code>read -t0</code>, <code>bind '""\e[0n"": ""echo test""'
saved_settings=$(stty -g)
stty -echo -icanon min 1 time 0
printf '\e[5n'
until read -t0; do
  sleep 0.02
done
stty ""$saved_settings""
</code>]"
274,https://unix.stackexchange.com/questions/61931/,Redirect all subsequent commands' stderr using exec,"['As for a solution to redirect lots of command at once:', 'Why your original solution does not work: exec 2>&1 will redirect the standard error output to the standard output of your shell, which, if you run your script from the console, will be your console. the pipe redirection on commands will only redirect the standart output of the command.', 'On the point of view of somecommand, its standard output goes into a pipe connected to tee and the standard error goes into the same file/pseudofile as the standard error of the shell, which you redirect to the standard output of the shell, which will be the console if you run your program from the console.', 'The one true way to explain it is to see what really happens:', ""Your shell's original environment might look like this if you run it from the terminal:"", ""After you redirect standard error into standard output (exec 2>&1), you ... basically change nothing.  But if you redirect the script's standart output to a file, you would end up with an environment like this:"", 'Then redirecting the shell standard error into standard output would end up like this :', ""Running a command will inherit this environment. If you run a command and pipe it to tee, the command's environment would be :"", ""So your command's standard error still goes into what the shell uses as its standard error."", ""You can actually see the environment of a command by looking in /proc/[pid]/fd: use ls -l to also list the symbolic link's content.  The 0 file here is standard input, 1 is standard output and 2 is standard error. If the command opens more files (and most programs do), you will also see them.  A program can also choose to redirect or close its standard input/output and reuse 0, 1 and 2.""]","[<code>#!/bin/bash
{
    somecommand 
    somecommand2
    somecommand3
} 2&gt;&amp;1 | tee -a $DEBUGLOG
</code>, <code>somecommand</code>, <code>tee</code>, <code>stdin -&gt; /dev/pts/42
stdout -&gt; /dev/pts/42
stderr -&gt; /dev/pts/42
</code>, <code>exec 2&gt;&amp;1</code>, <code>stdin -&gt; /dev/pts/42
stdout -&gt; /your/file
stderr -&gt; /dev/pts/42
</code>, <code>stdin -&gt; /dev/pts/42
stdout -&gt; /your/file
stderr -&gt; /your/file
</code>, <code>stdin -&gt; /dev/pts/42
stdout -&gt; pipe:[4242]
stderr -&gt; /your/file
</code>, <code>/proc/[pid]/fd</code>, <code>ls -l</code>, <code>0</code>, <code>1</code>, <code>2</code>, <code>0</code>, <code>1</code>, <code>2</code>]"
275,https://unix.stackexchange.com/questions/66235/,How to display open file descriptors but not using lsof command,"[""There are two reasons lsof | wc -l doesn't count file descriptors. One is that it lists things that aren't open files, such as loaded dynamically linked libraries and current working directories; you need to filter them out. Another is that lsof takes some time to run, so can miss files that are opened or closed while it's running; therefore the number of listed open files is approximate. Looking at /proc/sys/fs/file-nr gives you an exact value at a particular point in time."", 'cat /proc/sys/fs/file-nr is only useful when you need the exact figure, mainly to check for resource exhaustion. If you want to list the open files, you need to call lsof, or use some equivalent method such as trawling /proc/*/fd manually.']","[<code>lsof | wc -l</code>, <code>lsof</code>, <code>/proc/sys/fs/file-nr</code>, <code>cat /proc/sys/fs/file-nr</code>, <code>lsof</code>, <code>/proc/*/fd</code>]"
276,https://unix.stackexchange.com/questions/119627/,Why are interactive shells on OSX login shells by default?,"[""The way it's supposed work is that, at the point when you get a shell prompt, both .profile and .bashrc have been run.  The specific details of how you get to that point are of secondary relevance, but if either of the files didn't get run at all, you'd have a shell with incomplete settings."", ""The reason terminal emulators on Linux (and other X-based systems) don't need to run .profile themselves is that it will normally have been run already when you logged in to X.  The settings in .profile are supposed to be of the kind that can be inherited by subprocesses, so as long as it's executed once when you log in (e.g. via .Xsession), any further subshells don't need to re-run it."", 'As the Debian wiki page linked by Alan Shutko explains:', '""Why is .bashrc a separate file from .bash_profile, then? This is done for mostly historical reasons, when machines were extremely slow compared to today\'s workstations. Processing the commands in .profile or .bash_profile could take quite a long time, especially on a machine where a lot of the work had to be done by external commands (pre-bash). So the difficult initial set-up commands, which create environment variables that can be passed down to child processes, are put in .bash_profile. The transient settings and aliases which are not inherited are put in .bashrc so that they can be re-read by every subshell.""', ""All the same rules hold on OSX, too, except for one thing — the OSX GUI doesn't run .profile when you log in, apparently because it has its own method of loading global settings.  But that means that a terminal emulator on OSX does need to run .profile (by telling the shell it launches that it's a login shell), otherwise you'd end up with a potentially crippled shell."", ""Now, a kind of a silly peculiarity of bash, not shared by most other shells, is that it will not automatically run .bashrc if it's started as a login shell.  The standard work-around for that is to include something like the following commands in .bash_profile:"", ""Alternatively, it's possible to have no .bash_profile at all, and just include some bash-specific code in the generic .profile file to run .bashrc if needed."", ""If the OSX default .bash_profile or .profile doesn't do this, then that's arguably a bug.  In any case, the proper work-around is to simply add those lines to .bash_profile."", 'Edit: As strugee notes, the default shell on OSX used to be tcsh, whose behavior is much saner in this respect: when run as an interactive login shell, tcsh automatically reads both .profile and .tcshrc / .cshrc, and thus does not need any workarounds like the .bash_profile trick shown above.', ""Based on this, I'm 99% sure that the failure of OSX to supply an appropriate default .bash_profile is because, when they switched from tcsh to bash, the folks at Apple simply didn't notice this little wart in bash's startup behavior.  With tcsh, no such tricks were needed — starting tcsh as a login shell from an OSX terminal emulator Just Plain Works and does the right thing without such kluges.""]","[<code>.profile</code>, <code>.bashrc</code>, <code>.profile</code>, <code>.profile</code>, <code>.Xsession</code>, <code>.bashrc</code>, <code>.bash_profile</code>, <code>.profile</code>, <code>.bash_profile</code>, <code>.bash_profile</code>, <code>.bashrc</code>, <code>.profile</code>, <code>.profile</code>, <code>.bashrc</code>, <code>.bash_profile</code>, <code>[[ -e ~/.profile ]] &amp;&amp; source ~/.profile    # load generic profile settings
[[ -e ~/.bashrc  ]] &amp;&amp; source ~/.bashrc     # load aliases etc.
</code>, <code>.bash_profile</code>, <code>.profile</code>, <code>.bashrc</code>, <code>.bash_profile</code>, <code>.profile</code>, <code>.bash_profile</code>, <code>.profile</code>, <code>.tcshrc</code>, <code>.cshrc</code>, <code>.bash_profile</code>, <code>.bash_profile</code>]"
277,https://unix.stackexchange.com/questions/13802/,Execute a specific command in a given directory without cd'ing to it?,"[""I don't know if this counts, but you can make a subshell:"", 'The directory is only changed for that subshell, so you avoid the work of needing to cd - afterwards.']","[<code>$ (cd /var/log &amp;&amp; cp -- *.log ~/Desktop)
</code>, <code>cd -</code>]"
278,https://unix.stackexchange.com/questions/239772/,"bash iterate file list, except when empty","['In bash, you can set the nullglob option so that a pattern that matches nothing ""disappears"", rather than treated as a literal string:', 'In POSIX shell script, you just verify that fname exists (and at the same time with [ -f ], check it is a regular file (or symlink to regular file) and not other types like directory/fifo/device...):', 'Replace [ -f ""$fname"" ] with [ -e ""$fname"" ] || [ -L ""$fname ] if you want to loop over all the (non-hidden) files whose name ends in .zip regardless of their type.', 'Replace *.zip with .*.zip .zip *.zip if you also want to consider hidden files whose name ends in .zip.']","[<code>bash</code>, <code>nullglob</code>, <code>shopt -s nullglob
for fname in *.zip ; do
   echo ""current file is ${fname}""
done
</code>, <code>fname</code>, <code>[ -f ]</code>, <code>for fname in *.zip; do
    [ -f ""$fname"" ] || continue
    printf '%s\n' ""current file is $fname""
done
</code>, <code>[ -f ""$fname"" ]</code>, <code>[ -e ""$fname"" ] || [ -L ""$fname ]</code>, <code>.zip</code>, <code>*.zip</code>, <code>.*.zip .zip *.zip</code>, <code>.zip</code>]"
279,https://unix.stackexchange.com/questions/122605/,How do I copy multiple files by wildcard?,"['How about something like this in bash:', 'you can test it by putting echo in front of the cp command:']","[<code>for file in ABC.*; do cp ""$file"" ""${file/ABC/DEF}"";done
</code>, <code>for file in ABC.*; do echo cp ""$file"" ""${file/ABC/DEF}"";done
</code>]"
280,https://unix.stackexchange.com/questions/94299/,dircolors: modify color settings globaly,"[""ls takes it color settings from the environment variable LS_COLORS. dircolors is merely a convenient way to generate this environment variable. To have this environment variable take effect system-wide, put it in your shell's startup file."", ""For bash, you'd put this in /etc/profile:"", ""For zsh, you'd either put it in /etc/zshrc or arrange for zsh to read /etc/profile on startup. Your distribution might have zsh do that already. I just bring this up to point out that setting dircolors for truly everybody depends on the shell they use."", ""As for where dircolors gets its settings from, when you don't specify a file it just uses some builtin defaults."", ""You can use xterm's 256 color escape codes in your dircolors file, but be aware that they'll only work for xterm compatible terminals. They won't work on the Linux text console, for example."", 'The format for 256 color escape codes is 38;5;colorN for foreground colors and 48;5;colorN for background colors. So for example:']","[<code>ls</code>, <code>LS_COLORS</code>, <code>dircolors</code>, <code>bash</code>, <code>/etc/profile</code>, <code># `dircolors` prints out `LS_COLORS='...'; export LS_COLORS`, so eval'ing
# $(dircolors) effectively sets the LS_COLORS environment variable.

eval ""$(dircolors /etc/DIR_COLORS)""
</code>, <code>zsh</code>, <code>/etc/zshrc</code>, <code>zsh</code>, <code>/etc/profile</code>, <code>zsh</code>, <code>dircolors</code>, <code>dircolors</code>, <code>xterm</code>, <code>xterm</code>, <code>38;5;colorN</code>, <code>48;5;colorN</code>, <code>.mp3  38;5;160                   # Set fg color to color 160      
.flac 48;5;240                   # Set bg color to color 240
.ogg  38;5;160;48;5;240          # Set fg color 160 *and* bg color 240.
.wav  01;04;05;38;5;160;48;5;240 # Pure madness: make bold (01), underlined (04), blink (05), fg color 160, and bg color 240!
</code>]"
281,https://unix.stackexchange.com/questions/454694/,How can I harden bash scripts against causing harm when changed in the future?,"['or', 'This would make the current shell treat expansions of unset variables as an error:', 'set -u and set -o nounset are POSIX shell options.', 'An empty value would not trigger an error though.', 'For that, use', ""The expansion of ${variable:?word} would expand to the value of variable unless it's empty or unset.  If it's empty or unset, the word would be displayed on standard error and the shell would treat the expansion as an error (the command would not be executed, and if running in a non-interactive shell, this would terminate).  Leaving the : out would trigger the error only for an unset value, just like under set -u."", '${variable:?word} is a POSIX parameter expansion.', 'Neither of these would cause an interactive shell to terminate unless set -e (or set -o errexit) was also in effect. ${variable:?word} causes scripts to exit if the variable is empty or unset. set -u would cause a script to exit if used together with set -e.', 'As for your second question. There is no way to limit rm to not work outside of the current directory.', ""The GNU implementation of rm has a --one-file-system option that stops it from recursively delete mounted filesystems, but that's as close as I believe we can get without wrapping the rm call in a function that actually checks the arguments."", 'As a side note:  ${build} is exactly equivalent to $build unless the expansion occurs as part of a string where the immediately following character is a valid character in a variable name, such as in ""${build}x"".']","[<code>set -u
</code>, <code>set -o nounset
</code>, <code>$ unset build
$ set -u
$ rm -rf ""$build""/*
bash: build: unbound variable
</code>, <code>set -u</code>, <code>set -o nounset</code>, <code>$ rm -rf ""${build:?Error, variable is empty or unset}""/*
bash: build: Error, variable is empty or unset
</code>, <code>${variable:?word}</code>, <code>variable</code>, <code>word</code>, <code>:</code>, <code>set -u</code>, <code>${variable:?word}</code>, <code>set -e</code>, <code>set -o errexit</code>, <code>${variable:?word}</code>, <code>set -u</code>, <code>set -e</code>, <code>rm</code>, <code>rm</code>, <code>--one-file-system</code>, <code>rm</code>, <code>${build}</code>, <code>$build</code>, <code>""${build}x""</code>]"
282,https://unix.stackexchange.com/questions/247576/,"How to get HOME, given USER?","[""There is a utility which will lookup user information regardless of whether that information is stored in local files such as /etc/passwd or in LDAP or some other method. It's called getent."", ""In order to get user information out of it, you run getent passwd $USER. You'll get a line back that looks like:"", 'Now you can simply cut out the home dir from it, e.g. by using cut, like so:']","[<code>/etc/passwd</code>, <code>getent</code>, <code>getent passwd $USER</code>, <code>[jenny@sameen ~]$ getent passwd jenny
jenny:*:1001:1001:Jenny Dybedahl:/home/jenny:/usr/local/bin/bash
</code>, <code>[jenny@sameen ~]$ getent passwd jenny | cut -d: -f6
/home/jenny
</code>]"
283,https://unix.stackexchange.com/questions/92187/,Setting IFS for a single statement,"['In some shells (including bash):', ""(with bash, you can omit the command if not in sh/POSIX emulation). But beware that when using unquoted variables, you also generally need to set -f, and there's no local scope for that in most shells."", 'With zsh, you can do:', ""$=PATH is to force word splitting which is not done by default in zsh (globbing upon variable expansion is not done either so you don't need set -f unless in sh emulation)."", '(){...} (or function {...}) are called anonymous functions and are typically used to set a local scope. with other shells that support local scope in functions, you could do something similar with:', 'To implement a local scope for variables and options in POSIX shells, you can also use the functions provided at https://github.com/stephane-chazelas/misc-scripts/blob/master/locvar.sh. Then you can use it as:', ""(by the way, it's invalid to split $PATH that way above except in zsh as in other shells, IFS is field delimiter, not field separator)."", 'Is just two assignments, one after the other just like a=1 b=2.', 'A note of explanation on var=value cmd:', 'In:', ""The shell executes /path/to/cmd in a new process and passes cmd and arg in argv[] and var=value in envp[]. That's not really a variable assignment, but more passing environment variables to the executed command. In the Bourne or Korn shell, with set -k, you can even write it cmd var=value arg."", ""Now, that doesn't apply to builtins or functions which are not executed. In the Bourne shell, in var=value some-builtin, var ends up being set afterwards, just like with var=value alone. That means for instance that the behaviour of var=value echo foo (which is not useful) varies depending on whether echo is builtin or not."", 'POSIX and/or ksh changed that in that that Bourne behaviour only happens for a category of builtins called special builtins. eval is a special builtin, read is not. For non special builtin, var=value builtin sets var only for the execution of the builtin which makes it behave similarly to when an external command is being run.', ""The command command can be used to remove the special attribute of those special builtins. What POSIX overlooked though is that for the eval and . builtins, that would mean that shells would have to implement a variable stack (even though it doesn't specify the local or typeset scope limiting commands), because you could do:"", 'Or even:', 'with myfunction being a function using or setting $a and potentially calling command eval.', ""That was really an overlook because ksh (which the spec is mostly based on) didn't implement it (and AT&T ksh and zsh still don't), but nowadays, except those two, most shells implement it. Behaviour varies among shells though in things like:"", 'though. Using local on shells that support it is a more reliable way to implement local scope.']","[<code>bash</code>, <code>IFS=: command eval 'p=($PATH)'
</code>, <code>bash</code>, <code>command</code>, <code>set -f</code>, <code>(){ local IFS=:; p=($=PATH); }
</code>, <code>$=PATH</code>, <code>zsh</code>, <code>set -f</code>, <code>(){...}</code>, <code>function {...}</code>, <code>e() { eval ""$@""; }
e 'local IFS=:; p=($PATH)'
</code>, <code>. /path/to/locvar.sh
var=3,2,2
call eval 'locvar IFS; locopt -f; IFS=,; set -- $var; a=$1 b=$2 c=$3'
</code>, <code>$PATH</code>, <code>zsh</code>, <code>IFS=$'\n' a=($str)
</code>, <code>a=1 b=2</code>, <code>var=value cmd</code>, <code>var=value cmd arg
</code>, <code>/path/to/cmd</code>, <code>cmd</code>, <code>arg</code>, <code>argv[]</code>, <code>var=value</code>, <code>envp[]</code>, <code>set -k</code>, <code>cmd var=value arg</code>, <code>var=value some-builtin</code>, <code>var</code>, <code>var=value</code>, <code>var=value echo foo</code>, <code>echo</code>, <code>ksh</code>, <code>eval</code>, <code>read</code>, <code>var=value builtin</code>, <code>var</code>, <code>command</code>, <code>eval</code>, <code>.</code>, <code>local</code>, <code>typeset</code>, <code>a=0; a=1 command eval 'a=2 command eval echo \$a; echo $a'; echo $a
</code>, <code>a=1 command eval myfunction
</code>, <code>myfunction</code>, <code>$a</code>, <code>command eval</code>, <code>ksh</code>, <code>ksh</code>, <code>zsh</code>, <code>a=0; a=1 command eval a=2; echo ""$a""
</code>, <code>local</code>]"
284,https://unix.stackexchange.com/questions/2244/,How do I count the number of occurrences of a word in a text file with the command line?,"['Where tr replaces spaces with newlines, grep filters all resulting lines matching WORD and wc counts the remaining ones.', 'One can even save the wc part using the -c option of grep:', 'The -c option is defined by POSIX.', 'If it is not guaranteed that there are spaces between the words, you have to use some other character (as delimiter) to replace. For example alternative tr parts are', 'or', 'if you want to replace double or single quotes. Of course, you can also use tr to replace multiple characters at once (think different kinds of whitespace and punctuation).', 'In case you need to count WORD but not prefixWORD, WORDsuffix or  prefixWORDsuffix, you can enclose the WORD pattern in begin/end-of-line markers:', 'Which is equivalent to word-begin/end markers, in our context:']","[<code>$ tr ' ' '\n' &lt; FILE | grep WORD | wc -l
</code>, <code>tr</code>, <code>grep</code>, <code>wc</code>, <code>wc</code>, <code>-c</code>, <code>$ tr ' ' '\n' &lt; FILE | grep -c WORD
</code>, <code>-c</code>, <code>tr</code>, <code>tr '""' '\n'
</code>, <code>tr ""'"" '\n'
</code>, <code>tr</code>, <code>grep -c '^WORD$'
</code>, <code>grep -c '\&lt;WORD\&gt;'
</code>]"
285,https://unix.stackexchange.com/questions/120206/,Why does rm *(1)* remove all files in a directory?,"['From man bash:', 'You have a glob expression which matches files beginning with zero or more 1s - which is all files.', 'One simple way to disable this globbing behaviour is to \\ escape the parentheses:', 'Otherwise you can use shopt -u extglob to disable the behaviour and shopt -s extglob to re-enable it:', 'Note that as Stephane says, extglob is enabled by bash-completion so disabling it may cause completion functions not to work properly.']","[<code>man bash</code>, <code>*(pattern-list)
                 Matches zero or more occurrences of the given patterns
</code>, <code>1</code>, <code>\</code>, <code>rm *\(1\)*
</code>, <code>shopt -u extglob</code>, <code>shopt -s extglob</code>, <code>shopt -u extglob
rm *(1)*
shopt -s extglob
</code>, <code>extglob</code>, <code>bash-completion</code>]"
286,https://unix.stackexchange.com/questions/286351/,What is a fast command line way to switch between multiple directories for system administration?,"['Use pushd and then the special names for the directories in your directory stack: ~1, ~2, etc.', 'Example:', 'The most effective way to use pushd in this way is to load up your directory list, then add one more directory to be your current directory, and then you can jump between the static numbers without affecting the position of the directories in your stack.', ""It's also worth noting that cd - will take you to the last directory you were in.  So will cd ~-."", 'The advantage of ~- over just - is that - is specific to cd, whereas ~- is expanded by your shell the same way that ~1, ~2, etc. are.  This comes in handy when copying a file between very long directory paths; e.g.:', 'The above is equivalent to:']","[<code>pushd</code>, <code>~1</code>, <code>~2</code>, <code>tmp $ dirs -v
 0  /tmp
 1  /tmp/scripts
 2  /tmp/photos
 3  /tmp/music
 4  /tmp/pictures
tmp $ cd ~3
music $ dirs -v
 0  /tmp/music
 1  /tmp/scripts
 2  /tmp/photos
 3  /tmp/music
 4  /tmp/pictures
music $ cd ~2
photos $ cd ~4
pictures $ cd ~3
music $ cd ~1
scripts $ 
</code>, <code>pushd</code>, <code>cd -</code>, <code>cd ~-</code>, <code>~-</code>, <code>-</code>, <code>-</code>, <code>cd</code>, <code>~-</code>, <code>~1</code>, <code>~2</code>, <code>cd /very/long/path/to/some/directory/
cd /another/long/path/to/where/the/source/file/is/
cp myfile ~-
</code>, <code>cp /another/long/path/to/where/the/source/file/is/myfile /very/long/path/to/some/directory/
</code>]"
287,https://unix.stackexchange.com/questions/211834/,Slash and backslash in sed,"['Use single quotes for the expression you used:', 'In double quotes, \\ has a special meaning, so you have to backslash it:', ""But it's cleaner to change the delimiter:""]","[<code>sed 's/\//\\\//g'
</code>, <code>\</code>, <code>sed ""s/\//\\\\\//g""
</code>, <code>sed 's=/=\\/=g'
sed ""s=/=\\\/=g""
</code>]"
288,https://unix.stackexchange.com/questions/83926/,"how to download a file using just bash and nothing else (no curl, wget, perl, etc.)","['If you have bash 2.04 or above with the /dev/tcp pseudo-device enabled, you can download a file from bash itself.', ""Paste the following code directly into a bash shell (you don't need to save the code into a file for executing):"", 'Then you can execute it as from the shell as follows:', ""Source: Moreaki's answer upgrading and installing packages through the cygwin command line?"", 'Update:\nas mentioned in the comment, the approach outlined above is simplistic:']","[<code>/dev/tcp</code>, <code>function __wget() {
    : ${DEBUG:=0}
    local URL=$1
    local tag=""Connection: close""
    local mark=0

    if [ -z ""${URL}"" ]; then
        printf ""Usage: %s \""URL\"" [e.g.: %s http://www.google.com/]"" \
               ""${FUNCNAME[0]}"" ""${FUNCNAME[0]}""
        return 1;
    fi
    read proto server path &lt;&lt;&lt;$(echo ${URL//// })
    DOC=/${path// //}
    HOST=${server//:*}
    PORT=${server//*:}
    [[ x""${HOST}"" == x""${PORT}"" ]] &amp;&amp; PORT=80
    [[ $DEBUG -eq 1 ]] &amp;&amp; echo ""HOST=$HOST""
    [[ $DEBUG -eq 1 ]] &amp;&amp; echo ""PORT=$PORT""
    [[ $DEBUG -eq 1 ]] &amp;&amp; echo ""DOC =$DOC""

    exec 3&lt;&gt;/dev/tcp/${HOST}/$PORT
    echo -en ""GET ${DOC} HTTP/1.1\r\nHost: ${HOST}\r\n${tag}\r\n\r\n"" &gt;&amp;3
    while read line; do
        [[ $mark -eq 1 ]] &amp;&amp; echo $line
        if [[ ""${line}"" =~ ""${tag}"" ]]; then
            mark=1
        fi
    done &lt;&amp;3
    exec 3&gt;&amp;-
}
</code>, <code>__wget http://example.iana.org/
</code>, <code>read</code>, <code>$line</code>]"
289,https://unix.stackexchange.com/questions/68484/,"What does ${1+""$@""} mean in a shell script, and how does it differ from ""$@""?","[""That's for compatibility with the Bourne shell. The Bourne shell was an old shell that was first released with Unix version  7 in 1979 and was still common until the mid 90s as /bin/sh on most commercial Unices."", 'It is the ancestor of most Bourne-like shells like ksh, bash or zsh.', 'It had a few awkward features many of which have been fixed in ksh and the other shells and the new standard specification of sh, one of which is this:', 'With the Bourne shell (at least those variants where it has not been fixed): ""$@"" expands to one empty argument if the list of positional parameters is empty ($# == 0) instead of no argument at all.', '${var+something} expands to ""something"" unless $var is unset. It is clearly documented in all shells but hard to find in the bash documentation as you need to pay attention to this sentence:', 'When not performing substring expansion, using the forms documented below, bash tests for a parameter that is unset or null.  Omitting the colon results  in  a  test  only  for  a parameter that is unset.', 'So ${1+""$@""} expands to ""$@"" only if $1 is set ($# > 0) which works around that limitation of the Bourne shell.', ""Note that the Bourne shell is the only shell with that problem. Modern shs (that is sh conforming to the POSIX specification of sh (which the Bourne shell is not)) don't have that issue. So you only need that if you need your code to work on very old systems where /bin/sh might be a Bourne shell instead of a standard shell (note that POSIX doesn't specify the location of the standard sh, so for instance on Solaris before Solaris 11, /bin/sh was still a Bourne shell (though did not have that particular issue) while the normal/standard sh was in another location (/usr/xpg4/bin/sh))."", 'There is a problem in that perlrun perldoc page in that $0 is not quoted though.', 'See http://www.in-ulm.de/~mascheck/various/bourne_args/ for more information.']","[<code>/bin/sh</code>, <code>ksh</code>, <code>bash</code>, <code>zsh</code>, <code>ksh</code>, <code>sh</code>, <code>""$@""</code>, <code>$# == 0</code>, <code>${var+something}</code>, <code>$var</code>, <code>bash</code>, <code>${1+""$@""}</code>, <code>""$@""</code>, <code>$1</code>, <code>$# &gt; 0</code>, <code>sh</code>, <code>sh</code>, <code>sh</code>, <code>/bin/sh</code>, <code>sh</code>, <code>/bin/sh</code>, <code>sh</code>, <code>/usr/xpg4/bin/sh</code>, <code>perlrun</code>, <code>$0</code>]"
290,https://unix.stackexchange.com/questions/144476/,Run a diff between local and remote files,['Source'],"[<code>ssh user@remote_host ""cat remote_file.txt"" | diff - local_file.txt
</code>]"
291,https://unix.stackexchange.com/questions/15998/,What does the -e do in a bash shebang?,"['Your post actually contains 2 questions.', 'The -e flag instructs the script to exit on error. More flags', 'If there is an error it will exit right away.', 'The $? is the exit status of the last command. In Linux an exit status of 0 means that the command was successful. Any other status would mean an error occurred.', 'To apply these answers to your script:', 'would look for the username in the /etc/passwd file.', 'If it finds it then the exit status $? will be equal to 0.', 'If it doesn\'t find it the exit status will be something else (not 0). Here, you will want to execute the echo ""doesn\'t exist"" part of the code.', 'Unfortunately there is an error in your script, and you would execute that code if the user exists - change the line to', 'to get the logic right.', ""However if the user doesn't exist, egrep will return an error code, and due to the -e option the shell will immediately exit after that line, so you would never reach that part of the code.""]","[<code>-e</code>, <code>$?</code>, <code>0</code>, <code>egrep ""^username"" /etc/passwd &gt;/dev/null
</code>, <code>username</code>, <code>/etc/passwd</code>, <code>$?</code>, <code>0</code>, <code>0</code>, <code>echo ""doesn't exist""</code>, <code>if [ $? -ne 0 ]
</code>, <code>egrep</code>, <code>-e</code>]"
292,https://unix.stackexchange.com/questions/37660/,Order of redirections,"['I find it easier to think of using assignments.', 'You start out with', 'then your first example, 1> file.txt 2>&1, does', 'leaving you with', 'If you did it the other way, again you start with', 'then 2>&1 > file.txt does', 'so the end result is', ""and you've only redirected stdout, not stderr.""]","[<code>&gt;</code>, <code>=</code>, <code>&amp;</code>, <code>$</code>, <code>1 = /dev/tty
2 = /dev/tty
</code>, <code>1&gt; file.txt 2&gt;&amp;1</code>, <code>1 = file.txt
2 = $1           # and currently $1 = file.txt
</code>, <code>1 = file.txt
2 = file.txt
</code>, <code>1 = /dev/tty
2 = /dev/tty
</code>, <code>2&gt;&amp;1 &gt; file.txt</code>, <code>2 = $1           # and currently $1 = /dev/tty
1 = file.txt
</code>, <code>1 = file.txt
2 = /dev/tty
</code>, <code>stdout</code>, <code>stderr</code>]"
293,https://unix.stackexchange.com/questions/19058/,How to replace one char with another in all filenames of the current directories?,"['If you need to rename files in subdirectories as well, and your find supports the -execdir predicate, then you can do', 'Thank to @glenn jackman for suggesting -depth option for find and to make me think.', ""Note that on some systems (including GNU/Linux ones), find may fail to find files whose name contains spaces and also sequences of bytes that don't form valid characters (typical with media files with names with non-ASCII characters encoded in a charset different from the locale's). Setting the locale to C (as in LC_ALL=C find...) would address the problem.""]","[<code>find</code>, <code>-execdir</code>, <code>find /search/path -depth -name '* *' \
    -execdir bash -c 'mv -- ""$1"" ""${1// /_}""' bash {} \;
</code>, <code>-depth</code>, <code>find</code>, <code>find</code>, <code>C</code>, <code>LC_ALL=C find...</code>]"
294,https://unix.stackexchange.com/questions/151654/,Checking if an input number is an integer,['Remove quotes'],"[<code>if ! [[ ""$scale"" =~ ^[0-9]+$ ]]
    then
        echo ""Sorry integers only""
fi
</code>]"
295,https://unix.stackexchange.com/questions/6501/,Why would anyone not set 'histappend' in bash?,"['Well, when histappend is not set, this does not mean that the history is wiped on each shell exit. Without histappend bash reads the histfile on startup into memory - during operation new entries are added - and on shell exit the last HISTSIZE lines are written to the history file without appending, i.e. replacing the previous content.', 'For example, if the histfile contains 400 entries, during bash runtime 10 new entries are added - histsize is set to 500, then the new histfile contains 410 entries.', 'This behavior is only problematic if you use more bash instances in parallel. In that case, the history file only contains the contents of the last exiting shell.', 'Independent of this: There are some people who want to wipe their history on shell exit because of privacy reasons.']","[<code>histappend</code>, <code>histappend</code>]"
296,https://unix.stackexchange.com/questions/41287/,How to Extract Album Cover Image from MP3 file?,"['You can use eyed3 which is a great utility for handling id3 tags. To extract all images from an mp3 file you can use:', 'This will write all embedded images from the mp3 file to the specified directory.']","[<code>eyeD3 --write-images=DIR mp3_file
</code>]"
297,https://unix.stackexchange.com/questions/108873/,Removing a directory from PATH,"['There are no standard tools to ""edit"" the value of $PATH (i.e. ""add folder only when it doesn\'t already exists"" or ""remove this folder"").\nYou just execute:', ""that would be for the current session, if you want to change permanently add it to any .bashrc, bash.bashrc, /etc/profile - whatever fits your system and user needs.\nHowever if you're using BASH, you can also do the following if, let's say, you want to remove the directory /home/wrong/dir/ from your PATH variable, assuming it's at the end:"", 'So  in your case you may use']","[<code>export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games
</code>, <code>/home/wrong/dir/</code>, <code>PATH=$(echo ""$PATH"" | sed -e 's/:\/home\/wrong\/dir$//')
</code>, <code>PATH=$(echo ""$PATH"" | sed -e 's/:\/d\/Programme\/cygwin\/bin$//')
</code>]"
298,https://unix.stackexchange.com/questions/79658/,"""not a valid identifier"" when I do ""export $PATH""","[""Running export $PATH will try to export a variable with a name equal to the value of $PATH (after word splitting). That is, it's equivalent to writing something like export /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin. And since /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin is not a valid variable name, it fails. What you want to do is export PATH."", 'export (equivalent to declare -x) in Bash simply makes the variable available to subshells.', 'To print the value of a variable safely and readably, use printf %q ""$PATH"".']","[<code>export $PATH</code>, <code>$PATH</code>, <code>export /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</code>, <code>/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</code>, <code>export PATH</code>, <code>export</code>, <code>declare -x</code>, <code>printf %q ""$PATH""</code>]"
299,https://unix.stackexchange.com/questions/164391/,How does `cat <> file` work?,"['Bash uses <> to create a read-write file descriptor:', 'The redirection operator', 'causes the file whose name is the expansion of word to be opened for both reading and writing on file descriptor n, or on file descriptor 0 if n is not specified. If the file does not exist, it is created.', ""cat <> file opens file read-write and binds it to descriptor 0 (standard input). It's essentially equivalent to < file for any sensibly-written program, since nobody's likely to try writing to standard input ordinarily, but if one did it'd be able to."", 'You can write a simple C program to test that out directly - write(0, ""hello"", 6) will write hello into file via standard input.', '<> should also work in any other POSIX-compliant shell with the same effect.']","[<code>&lt;&gt;</code>, <code>[n]&lt;&gt;word
</code>, <code>cat &lt;&gt; file</code>, <code>file</code>, <code>&lt; file</code>, <code>write(0, ""hello"", 6)</code>, <code>hello</code>, <code>file</code>, <code>&lt;&gt;</code>]"
300,https://unix.stackexchange.com/questions/253892/,"`Syntax error: ""("" unexpected` when creating an array","['When you use ./scriptname.sh it executes with /bin/bash as in the first line with #!. But when you use sh scriptname.sh it executes sh, not bash.', 'The sh shell has no syntax to create arrays, but Bash has the syntax you used.']","[<code>./scriptname.sh</code>, <code>/bin/bash</code>, <code>#!</code>, <code>sh scriptname.sh</code>, <code>sh</code>, <code>bash</code>, <code>sh</code>]"
301,https://unix.stackexchange.com/questions/424492/,How to define a shell script to be sourced not run,"['Assuming that you are running bash, put the following code near the start of the script that you want to be sourced but not executed:', 'Under bash, ${BASH_SOURCE[0]} will contain the name of the current file that the shell is reading regardless of whether it is being sourced or executed.', 'By contrast, $0 is the name of the current file being executed.', '-ef tests if these two files are the same file.  If they are, we alert the user and exit.', 'Neither -ef nor BASH_SOURCE are POSIX. While -ef is supported by ksh, yash, zsh and Dash, BASH_SOURCE requires bash.  In zsh, however, ${BASH_SOURCE[0]} could be replaced by ${(%):-%N}.']","[<code>if [ ""${BASH_SOURCE[0]}"" -ef ""$0"" ]
then
    echo ""Hey, you should source this script, not execute it!""
    exit 1
fi
</code>, <code>${BASH_SOURCE[0]}</code>, <code>$0</code>, <code>-ef</code>, <code>-ef</code>, <code>BASH_SOURCE</code>, <code>-ef</code>, <code>BASH_SOURCE</code>, <code>zsh</code>, <code>${BASH_SOURCE[0]}</code>, <code>${(%):-%N}</code>]"
302,https://unix.stackexchange.com/questions/96305/,Which shell am I running on?,"['$SHELL is not necessarily your current shell, it is the default login shell. To check the shell you are using, try ', 'This should work on most recent Unix/Linux with a ps that supports the BSD syntax. Otherwise, this is the portable (POSIX) way', 'That should return something like this if you are running tcsh:', 'If you want to have tcsh be your default shell, use chsh to set it.']","[<code>$SHELL</code>, <code>ps $$
</code>, <code>ps</code>, <code>ps -p $$
</code>, <code>tcsh</code>, <code>8773 pts/10   00:00:00 tcsh
</code>, <code>tcsh</code>, <code>chsh</code>]"
303,https://unix.stackexchange.com/questions/120153/,Resolving MAC Address from IP Address in Linux,"[""If you just want to find out the MAC address of a given IP address you can use the command arp to look it up, once you've pinged the system 1 time."", 'Now look up in the ARP table:', ""If you want to sweep the entire LAN for MAC addresses you can use the command line tool fing to do so. It's typically not installed so you'll have to go download it and install it manually."", '\xa0\xa0\xa0 ', ""If you find you don't have the arp or fing commands available, you could use iproute2's command ip neigh to see your system's ARP table instead:""]","[<code>arp</code>, <code>$ ping skinner -c 1
PING skinner.bubba.net (192.168.1.3) 56(84) bytes of data.
64 bytes from skinner.bubba.net (192.168.1.3): icmp_seq=1 ttl=64 time=3.09 ms

--- skinner.bubba.net ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 3.097/3.097/3.097/0.000 ms
</code>, <code>$ arp -a
skinner.bubba.net (192.168.1.3) at 00:19:d1:e8:4c:95 [ether] on wlp3s0
</code>, <code>fing</code>, <code>$ sudo fing 10.9.8.0/24
</code>, <code>arp</code>, <code>fing</code>, <code>ip neigh</code>, <code>$ ip neigh
192.168.1.61 dev eth0 lladdr b8:27:eb:87:74:11 REACHABLE
192.168.1.70 dev eth0 lladdr 30:b5:c2:3d:6c:37 STALE
192.168.1.95 dev eth0 lladdr f0:18:98:1d:26:e2 REACHABLE
192.168.1.2 dev eth0 lladdr 14:cc:20:d4:56:2a STALE
192.168.1.10 dev eth0 lladdr 00:22:15:91:c1:2d REACHABLE
</code>]"
304,https://unix.stackexchange.com/questions/24419/,Terminal autocomplete: cycle through suggestions,"['This is actually a readline feature called menu-complete . You can bind it to tab (replacing the default complete) by running:', 'You probably want to add that to your ~/.bashrc. Alternatively, you could configure it for all readline completions (not just bash) in ~/.inputrc.', 'You may also find bind -p (show current bindings, note that shows tab as ""\\C-i"") and bind -l (list all functions that can be bound) useful, as well as the bash manual\'s line editing section and readline\'s documentation.']","[<code>menu-complete</code>, <code>complete</code>, <code>bind TAB:menu-complete
</code>, <code>~/.bashrc</code>, <code>~/.inputrc</code>, <code>bind -p</code>, <code>""\C-i""</code>, <code>bind -l</code>]"
305,https://unix.stackexchange.com/questions/119269/,How to get IP Address using shell script?,"['To list all IP addresses, regardless of name, try this:', 'or:', 'Specify the interface name (e.g. eth0) right after ifconfig if you only want the IP of a specific interface:', 'or:']","[<code>ifconfig | perl -nle 's/dr:(\S+)/print $1/e'
</code>, <code>ifconfig | awk '/inet addr/{print substr($2,6)}'
</code>, <code>ifconfig</code>, <code>ifconfig eth0 | perl -nle 's/dr:(\S+)/print $1/e'
</code>, <code>ifconfig eth0 | awk '/inet addr/{print substr($2,6)}'
</code>]"
306,https://unix.stackexchange.com/questions/4495/,Object-oriented shell for *nix,"['I can think of three desirable features in a shell:', 'Unix shells tend to concentrate on the interactive aspect and subcontract most of the system access and some of the programming to external tools, such as:', 'Many, many things can be done by invoking a command with the right arguments or piped input. This is a very powerful approach — better have one tool per task that does it well, than a single program that does everything but badly — but it does have its limitations.', ""A major limitation of unix shells, and I suspect this is what you're after with your “object-oriented scripting” requirement, is that they are not good at retaining information from one command to the next, or combining commands in ways fancier than a pipeline. In particular, inter-program communication is text-based, so applications can only be combined if they serialize their data in a compatible way. This is both a blessing and a curse: the everything-is-text approach makes it easy to accomplish simple tasks quickly, but raises the barrier for more complex tasks."", ""Interactive usability also runs rather against program maintainability. Interactive programs should be short, require little quoting, not bother you with variable declarations or typing, etc. Maintainable programs should be readable (so not have many abbreviations), should be readable (so you don't have to wonder whether a bare word is a string, a function name, a variable name, etc.), should have consistency checks such as variable declarations and typing, etc."", 'In summary, a shell is a difficult compromise to reach. Ok, this ends the rant section, on to the examples.', ""The Perl Shell (psh) “combines the interactive nature of a Unix shell with the power of Perl”. Simple commands (even pipelines) can be entered in shell syntax; everything else is Perl. The project hasn't been in development for a long time. It's usable, but hasn't reached the point where I'd consider using it over pure Perl (for scripting) or pure shell (interactively or for scripting)."", 'IPython is an improved interactive Python console, particularly targetted at numerical and parallel computing. This is a relatively young project.', 'irb (interactive ruby) is the Ruby equivalent of the Python console.', ""scsh is a scheme implementation (i.e. a decent programming language) with the kind of system bindings traditionally found in unix shells (strings, processes, files). It doesn't aim to be usable as an interactive shell however."", ""zsh is an improved interactive shell. Its strong point is interactivity (command line edition, completion, common tasks accomplished with terse but cryptic syntax). Its programming features aren't that great (on par with ksh), but it comes with a number of libraries for terminal control, regexps, networking, etc."", ""fish is a clean start at a unix-style shell. It doesn't have better programming or system access features. Because it breaks compatibility with sh, it has more room to evolve better features, but that hasn't happened."", 'Addendum: another part of the unix toolbox is treating many things as files:', ""Maybe the future of unix shells is not better system access through commands (and better control structures to combine commands) but better system access through filesystems (which combine somewhat differently — I don't think we've worked out what the key idioms (like the shell pipe) are yet).""]","[<code>ftp</code>, <code>mail</code>, <code>Mail</code>, <code>mailx</code>, <code>cron</code>, <code>dbus-*</code>, <code>/sys</code>, <code>/proc</code>]"
307,https://unix.stackexchange.com/questions/31248/,removing or clearing stack of popd/pushd paths,['dirs -c is what you are looking for.'],[<code>dirs -c</code>]
308,https://unix.stackexchange.com/questions/91282/,What exactly is an environment variable?,"['An environment is not as magical as it might seem. The shell stores it in memory and passes to the execve() system call. The child process inherits it as an array pointer called environ. From the execve manpage:', 'SYNOPSIS', 'argv is  an  array  of argument strings passed to the new program.\n  By convention, the first of these strings should contain the filename \n  associated with the file being executed. envp is an array of strings,\n  conventionally of the form key=value, which are passed as environment\n  to  the new program.', 'The environ(7) manpage also offers some insight:', 'SYNOPSIS', 'DESCRIPTION', 'The  variable  environ points  to  an array of pointers to strings\n  called the ""environment"".  The last pointer in this array has the\n  value NULL.  (This variable must be declared in the user program, \n  but is declared in the header file <unistd.h> in case the\n  header files came from libc4 or libc5, and in case they came from \n  glibc and _GNU_SOURCE was defined.)  This array of strings is made\n  available to the process by the exec(3) call that started the process.', 'Both of these GNU manpages match the POSIX specification']","[<code>execve()</code>, <code>environ</code>, <code>execve</code>, <code>   #include &lt;unistd.h&gt;

   int execve(const char *filename, char *const argv[],
              char *const envp[]);
</code>, <code>argv</code>, <code>envp</code>, <code>environ(7)</code>, <code>   extern char **environ;
</code>, <code>environ</code>, <code>NULL</code>, <code>&lt;unistd.h&gt;</code>]"
309,https://unix.stackexchange.com/questions/42020/,How can I delete all files with a particular extension in a particular folder?,"['Yes, rm *.xvg will only delete the files with the specified extension in your current directory.', 'A good way to make sure you are indeed in the directory you want delete your files is to use the pwd command which will display your current directory and then do an ls to verify you find the files you are expecting.', 'If you are bit apprehensive about issuing the rm command, there are 2 things you can do:', 'type ls *.xvg to see a list of what files would be affected by this command.', ""Unless you have a lot of files, you could always also use the -i command line switch for rm (also exists for cp and mv). Using rm -i *.xvg would prompt you for each individual file if it was ok to delete it, so you could be sure nothing you didn't expect was getting deleted. (This will be tedious if you have a lot of files though :)""]","[<code>rm *.xvg</code>, <code>pwd</code>, <code>ls</code>, <code>rm</code>, <code>ls *.xvg</code>, <code>-i</code>, <code>rm</code>, <code>cp</code>, <code>mv</code>, <code>rm -i *.xvg</code>]"
310,https://unix.stackexchange.com/questions/86941/,How to SSH into a specific directory?,"['Just put as the last line of your ~bob/.bash_profile file on foo:', 'Now each time you log in (whether by SSH or otherwise), the cd command will run. No mucking around with ssh is necessary.', 'I know you wrote that you\'d ""like to avoid changing anything on \'foo\' if possible,"" but if the bob@foo account is yours, changing your own .bash_profile should be acceptable, no?']","[<code>cd /home/guest &gt;&amp; /dev/null
</code>]"
311,https://unix.stackexchange.com/questions/21363/,Execute bash scripts on entering a directory,"['You can make cd a function (and pop and pushd), and make it detect if you enter that particular directory.', ""Do not do this in directories that you haven't whitelisted, because it would make it very easy for someone to trick you into running arbitrary code — send you an archive, so you unzip it, change into the directory it created, and you've now run the attacker's code."", ""I don't recommend this approach, because it means the script will be executed even if you enter that directory for some reason that's unrelated to working on the project. I suggest having a specific function that changes to the project directory and sources the settings script.""]","[<code>cd</code>, <code>pop</code>, <code>pushd</code>, <code>cd () { builtin cd ""$@"" &amp;&amp; chpwd; }
pushd () { builtin pushd ""$@"" &amp;&amp; chpwd; }
popd () { builtin popd ""$@"" &amp;&amp; chpwd; }
unset_all_project_settings () {
  # do whatever it takes to undo the effect of projectSettings.bash,
  # e.g. unset variables, remove PATH elements, etc.
}
chpwd () {
  case $PWD in
    /some/directory|/some/other/directory) . ./projectSettings.bash;;
    *) unset_all_project_settings;;
  esac
}
</code>, <code>myproj () {
  cd /some/directory &amp;&amp; . ./projectSettings.bash
}
</code>]"
312,https://unix.stackexchange.com/questions/151118/,Understand `compgen` builtin command,"['Options for compgen command are the same as complete, except -p and -r. From compgen man page:', 'For options [abcdefgjksuv]:', 'You can see complete man page here.']","[<code>compgen</code>, <code>complete</code>, <code>-p</code>, <code>-r</code>, <code>compgen</code>, <code>compgen
 compgen [option] [word]
 Generate possible completion matches for word according to the options, which 
 may be any option accepted by the complete builtin with the exception of -p 
 and -r, and write the matches to the standard output
</code>, <code>[abcdefgjksuv]</code>, <code>-a</code>, <code>-b</code>, <code>-c</code>, <code>-d</code>, <code>-e</code>, <code>-f</code>, <code>-g</code>, <code>-j</code>, <code>-k</code>, <code>-s</code>, <code>-u</code>, <code>-v</code>]"
313,https://unix.stackexchange.com/questions/154427/,"unexpected EOF while looking for matching `""' - bash script","['You can see your problem if you just look at your question. Note how the syntax highlighting is screwed up after line 95:', 'As the error message tells you, you have an unmatched "". Just remove the extra "" from the line above and you should be fine:']","[<code>echo -e ""Sorry, an error occurred. You have to run this on OS X""""
</code>, <code>""</code>, <code>""</code>, <code>echo -e ""Sorry, an error occurred. You have to run this on OS X""
</code>]"
314,https://unix.stackexchange.com/questions/84852/,delete files matching pattern,"[""A string contains “a number followed by an x followed by a number” if and only if it contains a digit followed by an x followed by a digit, i.e. if it contains a substring matching the pattern [0-9]x[0-9]. So you're looking to remove the files whose name matches the pattern *[0-9]x[0-9]*[0-9]x[0-9]*.jpg."", ""If your find doesn't have -delete, call rm to delete the files.""]","[<code>x</code>, <code>x</code>, <code>[0-9]x[0-9]</code>, <code>*[0-9]x[0-9]*[0-9]x[0-9]*.jpg</code>, <code>find /path/to/directory -type f -name '*[0-9]x[0-9]*[0-9]x[0-9]*.jpg' -delete
</code>, <code>find</code>, <code>-delete</code>, <code>rm</code>, <code>find /path/to/directory -type f -name '*[0-9]x[0-9]*[0-9]x[0-9]*.jpg' -exec rm {} +
</code>]"
315,https://unix.stackexchange.com/questions/158289/,Finding largest file recursively,"['use find (here assuming GNU find) to output file names with the file size. sort. print out the largest one.', ""That assumes file paths don't contain newline characters."", 'Using a loop in bash with the GNU implementation of stat:', ""This will be significantly slower than the find solution. That also assumes that file names don't end in newline characters and will skip hidden files and not descend into hidden directories."", ""If there's a file called - in the current directory, the size of the file open on stdin will be considered."", 'Beware that versions of bash prior to 4.3 followed symbolic links when descending the directory tree.']","[<code>find</code>, <code>find</code>, <code>find . -type f -printf ""%s\t%p\n"" | sort -n | tail -1
</code>, <code>bash</code>, <code>stat</code>, <code>shopt -s globstar
max_s=0
for f in **; do
  if [[ -f ""$f"" &amp;&amp; ! -L ""$f"" ]]; then
    size=$( stat -c %s -- ""$f"" )
    if (( size &gt; max_s )); then
      max_s=$size
      max_f=$f
    fi
  fi
done
echo ""$max_s $max_f""
</code>, <code>-</code>, <code>bash</code>]"
316,https://unix.stackexchange.com/questions/114244/,Replace all newlines to space except the last,"[""You can use paste -s -d ' ' file.txt:""]","[<code>paste -s -d ' ' file.txt</code>, <code>$ cat file.txt
one line
another line
third line
fourth line

$ paste -s -d ' ' file.txt 
one line another line third line fourth line
</code>]"
317,https://unix.stackexchange.com/questions/22387/,How do ${0##*/} and ${0%/*} work?,"[""Those are not regular expressions, they are examples of Bash's parameter expansion: the substitution of a variable or a special parameter by its value. The Wooledge Wiki has a good explanation."", 'Basically, in the example you have, ${0##*/} translates as:', 'So, where $0 is the name of a file, eg., $HOME/documents/doc.txt, then the parameter would be expanded as: doc.txt', 'Similarly, for ${0%/*}, the pattern / is matched against the end of parameter (the %), with the shortest or non-greedy match deleted – which in the example above would give you $HOME/documents.', ""See also the article on the Bash Hacker's Wiki.""]","[<code>${0##*/}</code>, <code>$0</code>, <code>$HOME/documents/doc.txt</code>, <code>doc.txt</code>, <code>${0%/*}</code>, <code>/</code>, <code>%</code>, <code>$HOME/documents</code>]"
318,https://unix.stackexchange.com/questions/175851/,How to permanently enable scl CentOS 6.4?,"['In your ~/.bashrc or ~/.bash_profile Simply source the ""enable"" script provided with the devtoolset. For example, with the Devtoolset 2, the command is:', 'or', 'Lot more efficient: no forkbomb, no tricky shell']","[<code>~/.bashrc</code>, <code>~/.bash_profile</code>, <code>source /opt/rh/devtoolset-2/enable
</code>, <code>source scl_source enable devtoolset-2
</code>]"
319,https://unix.stackexchange.com/questions/322459/,Is it possible to check where an alias was defined?,"['Manual definition will be hard to spot (the history logs, maybe) though asking the shell to show what it is doing and then grep should help find those set in a rc file:', ""If the shell isn't precisely capturing the necessary options with one of the above invocations (that interactively run the null command), then script:"", 'Another option would be to use something like strace or sysdig to find all the files the shell touches, then go grep those manually (handy if the shell or program does not have an -x flag); the standard RC files are not sufficient for a manual filename check if something like oh-my-zsh or site-specific configurations are pulling in code from who knows where (or also there may be environment variables, as sorontar points out in their answer).']","[<code>grep</code>, <code>bash -ixlc : 2&gt;&amp;1 | grep ...
zsh -ixc : 2&gt;&amp;1 | grep ...
</code>, <code>script</code>, <code>script somethingtogrep thatstrangeshell -x
...
grep ... somethingtogrep
</code>, <code>strace</code>, <code>sysdig</code>, <code>grep</code>, <code>-x</code>]"
320,https://unix.stackexchange.com/questions/402750/,Modify global variable in while loop,"[""In your example the while-loop is executed in a subshell, so changes to the variable inside the while-loop won't affect the external variable. This is because you're using the loop with a pipe, which automatically causes it to run in a subshell."", 'Here is an alternative solution using a while loop:', 'And here is the same approach using a for-loop:', 'For more information see the following posts:', 'A variable modified inside a while loop is not remembered', 'Bash Script: While-Loop Subshell Dilemma', 'Also look at the following chapter from the Advanced Bash Scripting Guide:']","[<code>i=1
while read x; do
   i=$(($i + 1))
   echo $i
done &lt;&lt;&lt;$(find tmp -type f)
echo $i
</code>, <code>i=1
for x in $(find tmp -type f);
do 
   i=$(($i + 1))
   echo $i
done
echo $i
</code>]"
321,https://unix.stackexchange.com/questions/252349/,"What is the difference between kill , pkill and killall?","['The kill command is a very simple wrapper to the kill system call, which knows only about process IDs (PIDs). pkill and killall are also wrappers to the kill system call, (actually, to the libc library which directly invokes the system call), but can determine the PIDs for you, based on things like, process name, owner of the process, session id, etc. ', ""How pkill and killall work can be seen using ltrace or strace on them. On Linux, they both read through the /proc filesystem, and for each pid (directory) found, traverses the path in a way to identify a process by its name or other attributes. How this is done is technically speaking, kernel and system specific. In general, they read from /proc/<PID>/stat which contains the command name as the 2nd field. For pkill -f and pgrep examine the /cmdline entry for each PID's proc entry."", ""pkill and pgrep use the readproc system call, whereas killall does not. I couldn't say if there's a performance difference: you'll have to benchmark that on your own.""]","[<code>kill</code>, <code>kill</code>, <code>pkill</code>, <code>killall</code>, <code>kill</code>, <code>pkill</code>, <code>killall</code>, <code>ltrace</code>, <code>strace</code>, <code>/proc</code>, <code>/proc/&lt;PID&gt;/stat</code>, <code>pkill -f</code>, <code>pgrep</code>, <code>/cmdline</code>, <code>pkill</code>, <code>pgrep</code>, <code>readproc</code>, <code>killall</code>]"
322,https://unix.stackexchange.com/questions/70/,What Unix commands can be used as a semaphore/lock?,"[""If lockfile is not installed on your system, then mkdir will do\nthe work: it's an atomic operation, and it fails if the directory \nalready exists (as long as you don't add the -p command-line\nswitch).""]","[<code>lockfile</code>, <code>mkdir</code>, <code>-p</code>, <code>create_lock_or_wait () {
  path=""$1""
  wait_time=""${2:-10}""
  while true; do
        if mkdir ""${path}.lock.d""; then
           break;
        fi
        sleep $wait_time
  done
}

remove_lock () {
  path=""$1""
  rmdir ""${path}.lock.d""
}
</code>]"
323,https://unix.stackexchange.com/questions/1571/,Grabbing the extension in a file name,"[""If the file name is file-1.0.tar.bz2, the extension is bz2. The method you're using to extract the extension (fileext=${filename##*.}) is perfectly valid¹."", 'How do you decide that you want the extension to be tar.bz2 and not bz2 or 0.tar.bz2? You need to answer this question first. Then you can figure out what shell command matches your specification.', ""One possible specification is that extensions must begin with a letter. This heuristic fails for a few common extensions like 7z, which might be best treated as a special case. Here's a bash/ksh/zsh implementation:"", 'For POSIX portability, you need to use a case statement for pattern matching.', ""Another possible specification is that some extensions denote encodings and indicate that further stripping is needed. Here's a bash/ksh/zsh implementation (requiring shopt -s extglob under bash and setopt ksh_glob under zsh):"", 'Note that this considers 0 to be an extension in file-1.0.gz.', '¹ \n${VARIABLE##SUFFIX} and related constructs are in POSIX, so they work in any non-antique Bourne-style shell such as ash, bash, ksh or zsh.\n']","[<code>file-1.0.tar.bz2</code>, <code>bz2</code>, <code>fileext=${filename##*.}</code>, <code>tar.bz2</code>, <code>bz2</code>, <code>0.tar.bz2</code>, <code>7z</code>, <code>basename=$filename; fileext=
while [[ $basename = ?*.* &amp;&amp;
         ( ${basename##*.} = [A-Za-z]* || ${basename##*.} = 7z ) ]]
do
  fileext=${basename##*.}.$fileext
  basename=${basename%.*}
done
fileext=${fileext%.}
</code>, <code>case</code>, <code>while case $basename in
        ?*.*) case ${basename##*.} in [A-Za-z]*|7z) true;; *) false;; esac;;
        *) false;;
      esac
do …
</code>, <code>shopt -s extglob</code>, <code>setopt ksh_glob</code>, <code>basename=$filename
fileext=
while [[ $basename = ?*.@(bz2|gz|lzma) ]]; do
  fileext=${basename##*.}.$fileext
  basename=${basename%.*}
done
if [[ $basename = ?*.* ]]; then
  fileext=${basename##*.}.$fileext
  basename=${basename%.*}
fi
fileext=${fileext%.}
</code>, <code>0</code>, <code>file-1.0.gz</code>, <code>${VARIABLE##SUFFIX}</code>]"
324,https://unix.stackexchange.com/questions/2432/,"How to remove ""You have mail"" welcome message","['It sounds like something has sent mail on (and to) the machine using the local mail exchanger. Most likely the email is an automated message from some installed package. Once you log in, type mail on the terminal to read and (presumably) delete the relevant mail. (Inside mail, use ? to find out what the commands are.) Once you\'ve read or deleted any unread mail, you won\'t see the ""You have mail"" message again until/unless something else sends mail in the same way. Odds are once you know what\'s sending you the mail, you can find a configuration option to change where it sends it to.']","[<code>mail</code>, <code>mail</code>, <code>?</code>]"
325,https://unix.stackexchange.com/questions/32460/,Excluding some of the commands from being getting stored in bash history,"['You might want $HISTIGNORE: ""A colon-separated list of patterns used to decide which command lines should be saved on the history list."" This line in your ~/.bashrc should do the job:', ""Also, you can add a space at the beginning of a command to exclude it from history. This works as long as $HISTCONTROL contains ignorespace or ignoreboth, which is default on any distro I've used.""]","[<code>$HISTIGNORE</code>, <code>HISTIGNORE='rm *:svn revert*'
</code>, <code>$HISTCONTROL</code>, <code>ignorespace</code>, <code>ignoreboth</code>]"
326,https://unix.stackexchange.com/questions/100704/,Difference between executing multiple commands with && and ;,"['In the shell, && and ; are similar in that they both can be used to terminate commands. The difference is && is also a conditional operator. With ; the following command is always executed, but with && the later command is only executed if the first succeeds.', 'Newlines are interchangeable with ; when terminating commands.']","[<code>&amp;&amp;</code>, <code>;</code>, <code>&amp;&amp;</code>, <code>;</code>, <code>&amp;&amp;</code>, <code>false; echo ""yes""   # prints ""yes""
true; echo ""yes""    # prints ""yes""
false &amp;&amp; echo ""yes"" # does not echo
true &amp;&amp; echo ""yes""  # prints ""yes""
</code>, <code>;</code>]"
327,https://unix.stackexchange.com/questions/5863/,Open a file given by the result of a command in vim,"['You can use command substitution:', 'or ']","[<code>vim $(find -name somefile.txt)
</code>, <code>find -name somefile.txt -exec vim {} \;
</code>]"
328,https://unix.stackexchange.com/questions/7738/,How can I use $variable in a shell brace expansion of a sequence?,"['You may want to try :', 'Not sure whether this is the best answer, but it certainly is one.']","[<code>eval rm foo.{$ext0..$extN}
</code>]"
329,https://unix.stackexchange.com/questions/72039/,What's the difference between single and double equal signs (=) in shell comparisons?,"['[[ $a == $b ]] is not comparison, it\'s pattern matching. You need [[ $a == ""$b"" ]] for byte-to-byte equality comparison. = is the same as == in any shell that supports [[...]] (introduced by ksh).', '[[...]] is not standard sh syntax. The [ command is standard, and the standard comparison operator there is = (though some [ implementations also recognise ==).', 'Just like in any argument to any command, variable expansions must be quoted to prevent split+glob and empty removal (only the latter being performed in zsh), so:', 'In standard sh, pattern matching is done with case:', 'For completeness, other equality-like operators you may come across in shell scripts:', '[ ""$a"" -eq ""$b"" ]: standard [ operator to compare decimal integer numbers. Some [ implementations allow blanks around the numbers, some allow arbitrary arithmetic expressions, but that\'s not portable. Portably, one can use [ ""$(($a))"" -eq ""$(($b))"" ] for that. See also [ ""$((a == b))"" -ne 0 ] which would be the standard equivalent (except that POSIXly, the behaviour is only specified if $a and $b contain integer constants) of:', ""((a == b)), from ksh and also found in zsh and bash, returns true if the evaluation of the arithmetic expression stored in $a yields the same number as that of $b. Typically, that's used for comparing numbers. Note that  there are variations between shells as to how arithmetic expressions are evaluated and what numbers are supported (for instance bash and some implementation/versions of ksh don't support floating point or treat numbers with leading zeros as octal)."", 'expr ""$a"" = ""$b"" does a number comparison if both operands are recognised as decimal integer numbers (some allowing blanks around the number), and otherwise checks if the two string operators have the same sorting order. It would also fail for values of $a or $b that are expr operators like (, substr...', 'awk \'BEGIN{exit !(ARGV[1] == ARGV[2])}\' ""$a"" ""$b"": if $a and $b are recognised as numbers (at least decimal integer and floating point numbers like 1.2, -1.5e-4, leading trailing blanks ignored, some also recognising hexadecimal, octal or anything recognised by strtod()), then a numeric comparison is performed. Otherwise, depending on the implementation, it\'s either a byte-to-byte string comparison, or like for expr a strcoll() comparison, that is whether $a and $b sort  the same.', 'See also:']","[<code>[[ $a == $b ]]</code>, <code>[[ $a == ""$b"" ]]</code>, <code>=</code>, <code>==</code>, <code>[[...]]</code>, <code>ksh</code>, <code>[[...]]</code>, <code>sh</code>, <code>[</code>, <code>=</code>, <code>[</code>, <code>==</code>, <code>zsh</code>, <code>[ ""$a"" = ""$b"" ]
</code>, <code>sh</code>, <code>case</code>, <code>case $a in
  ($b) ...
esac
</code>, <code>[ ""$a"" -eq ""$b"" ]</code>, <code>[</code>, <code>[</code>, <code>[ ""$(($a))"" -eq ""$(($b))"" ]</code>, <code>[ ""$((a == b))"" -ne 0 ]</code>, <code>$a</code>, <code>$b</code>, <code>((a == b))</code>, <code>zsh</code>, <code>bash</code>, <code>$a</code>, <code>$b</code>, <code>expr ""$a"" = ""$b""</code>, <code>$a</code>, <code>$b</code>, <code>expr</code>, <code>(</code>, <code>substr</code>, <code>awk 'BEGIN{exit !(ARGV[1] == ARGV[2])}' ""$a"" ""$b""</code>, <code>$a</code>, <code>$b</code>, <code>strtod()</code>, <code>expr</code>, <code>strcoll()</code>, <code>$a</code>, <code>$b</code>]"
330,https://unix.stackexchange.com/questions/146671/,Does ~ always equal $HOME,"[""What's important to understand is that ~ expansion is a feature of the shell (of some shells), it's not a magic character than means your home directory wherever it's used."", 'It is expanded (by the shell, which is an application used to interpret command lines), like $var is expanded to its value under some conditions when used in a shell command line before the command is executed.', ""That feature first appeared in the C-shell in the late 1970s (the Bourne shell didn't have it, nor did its predecessor the Thompson shell), was later added to the Korn shell (a newer shell built upon the Bourne shell in the 80s). It was eventually standardized by POSIX and is now available in most shells including non-POSIX ones like fish."", ""Because it's in such widespread use in shells, some non-shell applications also recognise it as meaning the home directory. That's the case of many applications in their configuration files or their own command line (mutt, slrn, vim...)."", 'bash specifically (which is the shell of the GNU project and widely used in many Linux-based operating systems), when invoked as sh, mostly follows the POSIX rules about ~ expansion, and in areas not specified by POSIX, behaves mostly like the Korn shell (of which it is a part clone).', 'While $var is expanded in most places (except inside single quotes), ~ expansion, being an afterthought is only expanded in a few specific conditions.', 'It is expanded when on its own argument in list contexts, in contexts where a string is expected.', ""Here are a few examples of where it's expanded in bash:"", ""Here are a few examples where it's not expanded:"", 'As to what it expands to: ~ alone expands to the content of the HOME variable, or when it is not set, to the home directory of the current user in the account database (as an extension since POSIX leaves that behaviour undefined).', 'It should be noted that in ksh88 and bash versions prior to 4.0, tilde expansion underwent globbing (filename generation) in list contexts:', 'That should not be a problem in usual cases.', ""Note that because it's expanded, the same warning applies as other forms of expansions."", ""Doesn't work if $HOME starts with - or contains .. components. So, even though it's very unlikely to ever make any difference, strictly speaking, one should write:"", 'Or even:', '(to cover for values of $HOME like -, +2...) or simply:', '(as cd takes you to your home directory without any argument)', 'Other shells have more advanced ~ expansions. For instance, in zsh, we have:']","[<code>~</code>, <code>$var</code>, <code>fish</code>, <code>mutt</code>, <code>slrn</code>, <code>vim</code>, <code>bash</code>, <code>sh</code>, <code>~</code>, <code>$var</code>, <code>~</code>, <code>bash</code>, <code>cmd arg ~ other arg</code>, <code>var=~</code>, <code>var=x:~:x</code>, <code>PATH</code>, <code>MANPATH</code>, <code>for i in ~</code>, <code>[[ ~ = text ]]</code>, <code>[[ text = ~ ]]</code>, <code>~</code>, <code>ksh</code>, <code>bash</code>, <code>case ~ in ~) ...</code>, <code>${var#~}</code>, <code>cmd foo=~</code>, <code>sh</code>, <code>=</code>, <code>bash</code>, <code>cmd ~/x</code>, <code>cmd ~:x</code>, <code>x:~:x</code>, <code>x-~-x</code>, <code>a[~]=foo; echo ""${a[~]} $((a[~]))""</code>, <code>echo ""~"" '~'</code>, <code>echo ~@ ~~</code>, <code>~u</code>, <code>u</code>, <code>echo @~</code>, <code>(( HOME == ~ ))</code>, <code>$(( var + ~ ))</code>, <code>extglob</code>, <code>case $var in @(~|other))...</code>, <code>case $var in ~|other)</code>, <code>./configure --prefix=~</code>, <code>--prefix</code>, <code>cmd ""foo""=~</code>, <code>bash</code>, <code>sh</code>, <code>export ""foo""=~</code>, <code>env JAVA_HOME=~ cmd</code>, <code>~</code>, <code>HOME</code>, <code>bash</code>, <code>$ bash -c 'echo ""$HOME""'
/home/***stephane***
$ bash -c 'echo ~'
/home/***stephane*** /home/stephane
$ bash -c 'echo ""~""'
~
</code>, <code>cd ~
</code>, <code>$HOME</code>, <code>-</code>, <code>..</code>, <code>cd -P -- ~
</code>, <code>case ~ in
  (/*) cd -P ~;;
  (*) d=~; cd -P ""./$d"";;
esac
</code>, <code>$HOME</code>, <code>-</code>, <code>+2</code>, <code>cd
</code>, <code>cd</code>, <code>~</code>, <code>zsh</code>, <code>~4</code>, <code>~-</code>, <code>~-2</code>, <code>cd</code>, <code>~something</code>]"
331,https://unix.stackexchange.com/questions/48392/,Understanding backtick (`),"['Text between backticks is executed and replaced by the output of the command (minus the trailing newline characters, and beware that shell behaviors vary when there are NUL characters in the output). That is called command substitution because it is substituted with the output of the command. So if you want to print 5, you can\'t use backticks, you can use quotation marks, like echo ""$b"" or just drop any quotation and use echo $b. ', 'As you can see, since $b contains 5, when using backticks bash is trying to run command 5 and since there is no such command, it fails with error message.', 'To understand how backticks works, try running this:', ""cat /etc/passwd |head -n1 should print first line of /etc/passwd file. But since we use backticks, it doesn't print this on console. Instead it is stored in A variable. You can echo $A to this. Note that more efficient way of printing first line is using command head -n1 /etc/passwd but I wanted to point out that expression inside of backticks does not have to be simple."", 'So if first line of /etc/passwd is root:x:0:0:root:/root:/bin/bash, first command will be dynamically substituted by bash to A=""root:x:0:0:root:/root:/bin/bash"".', 'Note that this syntax is of the Bourne shell. Quoting and escaping becomes quickly a nightmare with it especially when you start nesting them. Ksh introduced the $(...) alternative which is now standardized (POSIX) and supported by all shells (even the Bourne shell from Unix v9). So you should use $(...) instead nowadays unless you need to be portable to very old Bourne shells.', 'Also note that the output of `...` and $(...) are subject to word splitting and filename generation just like variable expansion (in zsh, word splitting only), so would generally need to be quoted in list contexts.']","[<code>echo ""$b""</code>, <code>echo $b</code>, <code>$b</code>, <code>bash</code>, <code>5</code>, <code>$ A=`cat /etc/passwd | head -n1`
$ echo ""$A""
</code>, <code>cat /etc/passwd |head -n1</code>, <code>/etc/passwd</code>, <code>A</code>, <code>$A</code>, <code>head -n1 /etc/passwd</code>, <code>root:x:0:0:root:/root:/bin/bash</code>, <code>A=""root:x:0:0:root:/root:/bin/bash""</code>, <code>$(...)</code>, <code>$(...)</code>, <code>`...`</code>, <code>$(...)</code>]"
332,https://unix.stackexchange.com/questions/104755/,How can I create a local function in my bashrc?,"['Use unset as last line in your .bashrc:', 'will delete/unset the function do_stuff.', 'To delete/unset the variables invoke it as follows:']","[<code>unset</code>, <code>.bashrc</code>, <code>unset -f do_stuff
</code>, <code>do_stuff</code>, <code>unset variablename
</code>]"
333,https://unix.stackexchange.com/questions/20157/,Why does a bash here-string add a trailing newline char?,"[""The easy answer is because ksh is written that way (and bash is compatible). But there's a reason for that design choice."", 'Most commands expect text input. In the unix world, a text file consists of a sequence of lines, each ending in a newline. So in most cases a final newline is required. An especially common case is to grab the output of a command with a command susbtitution, process it in some way, then pass it to another command. The command substitution strips final newlines; <<< puts one back.', ""Bash and ksh can't manipulate binary data anyway (it can't cope with null characters), so it's not surprising that their facilities are geared towards text data."", 'The <<< here-string syntax is mostly only for convenience anyway, like << here-documents. If you need to not add a final newline, use echo -n (in bash) or printf and a pipeline.']","[<code>&lt;&lt;&lt;</code>, <code>tmp=$(foo)
tmp=${tmp//hello/world}
tmp=${tmp#prefix}
bar &lt;&lt;&lt;$tmp
</code>, <code>&lt;&lt;&lt;</code>, <code>&lt;&lt;</code>, <code>echo -n</code>, <code>printf</code>]"
334,https://unix.stackexchange.com/questions/88106/,Why doesn't my ~/.bash_profile work?,"[""The file ~/.bash_profile is read by bash when it is a login shell. That's what you get when you log in in text mode."", ""When you log in under X, the startup scripts are executed by /bin/sh. On Ubuntu and Mint, /bin/sh is dash, not bash. Dash and bash both have the same core features, but dash sticks to these core features in order to be fast and small whereas bash adds a lot of features at the cost of requiring more resources. It is common to use dash for scripts that don't need the extra features and bash for interactive use (though zsh has a lot of nicer features)."", 'Most combinations of display manager (the program where you type your user name and password) and desktop environment read ~/.profile from the login scripts in /etc/X11/Xsession, /usr/bin/lightdm-session, /etc/gdm/Xsession or whichever is applicable. So put your environment variable definitions in ~/.profile. Make sure to use only syntax that dash supports.', 'So what should you put where?', 'A good .bash_profile loads .profile, and loads .bashrc if the shell is interactive.', 'In .profile, put environment variable definitions, and other session settings such as ulimit.', 'See also Difference between Login Shell and Non-Login Shell? and Alternative to .bashrc.']","[<code>~/.bash_profile</code>, <code>/bin/sh</code>, <code>/bin/sh</code>, <code>~/.profile</code>, <code>/etc/X11/Xsession</code>, <code>/usr/bin/lightdm-session</code>, <code>/etc/gdm/Xsession</code>, <code>~/.profile</code>, <code>.bash_profile</code>, <code>.profile</code>, <code>.bashrc</code>, <code>. ~/.profile
if [[ $- == *i* ]]; then . ~/.bashrc; fi
</code>, <code>.profile</code>, <code>ulimit</code>, <code>.bashrc</code>, <code>.inputrc</code>]"
335,https://unix.stackexchange.com/questions/86632/,How do you time how long a command took to run?,"['use time:', 'time will execute the rest of the command line as a command  (in this example longrunningcommand --takeyourtime) and when the command is done it will print the elapsed time.', 'another example: time foo --bar will execute foo --bar and wait for it to finish and then print the elapsed time.', 'time is a builtin command in most shells. the difference of the shell builtin and the system command is mostly the format of the output. see below for more elaboration on the differences.', 'if you want to use the system time do it like this:', 'or like this:', 'the backslash works in bash and maybe some other shells. command works in most shells.', 'more elaborate examples', 'example longrunningcommand:', 'example invocation:', '(with delay between each line of output)', 'example invocation using bash builtin time:', 'the interesting information is real    0m5,020s. for more information about the other numbers see here: https://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1', 'example invocation using system time:', 'the interesting information is 0:06.02elapsed. for the meaning of the other numbers read the man page of time: http://man7.org/linux/man-pages/man1/time.1.html', 'you can change the output of the system time. observe:', 'how to redirect or capture the output', 'for demonstration observe command hellostdoutstderr:', 'example invocations:', 'the bash builtin time prints the terminal even if stdout and stderr is redirected because it is a builtin and can do whatever it likes (in the shell)', 'to still redirect this output read here: https://stackoverflow.com/questions/18348593/how-can-i-output-from-usr-bin-time-to-a-file-at-the-right-location-within-execu', 'or here: https://www.cyberciti.biz/faq/unix-linux-time-command-examples-usage-syntax/', 'the system time prints to stderr like it should', 'you can tell time to print to a separate file']","[<code>time</code>, <code>$ time longrunningcommand --takeyourtime
</code>, <code>time</code>, <code>longrunningcommand --takeyourtime</code>, <code>time foo --bar</code>, <code>foo --bar</code>, <code>time</code>, <code>time</code>, <code>$ /usr/bin/time longrunningcommand --getsomecoffee
</code>, <code>$ \time longrunningcommand --callmom
$ command time longrunningcommand --callmom
</code>, <code>command</code>, <code>longrunningcommand</code>, <code>#!/bin/sh

echosleep() {
  seq $1 | while read tick; do
    echo $tick
    sleep 1
  done
  echo done
}

case $1 in
  --takeyourtime) echosleep 4 ;;
  --getsomecoffee) echosleep 5 ;;
  --callmom) echosleep 6 ;;
  *) echo wat ;;
esac
</code>, <code>$ ./longrunningcommand --takeyourtime
1
2
3
4
done
</code>, <code>time</code>, <code>$ time ./longrunningcommand --getsomecoffee
1
2
3
4
5
done

real    0m5,020s
user    0m0,010s
sys 0m0,010s
</code>, <code>real    0m5,020s</code>, <code>time</code>, <code>$ \time ./longrunningcommand --callmom
1
2
3
4
5
6
done
0.00user 0.01system 0:06.02elapsed 0%CPU (0avgtext+0avgdata 3656maxresident)k
0inputs+0outputs (0major+1089minor)pagefaults 0swaps
</code>, <code>0:06.02elapsed</code>, <code>time</code>, <code>time</code>, <code>$ \time sleep 0.5
0.00user 0.00system 0:00.50elapsed 0%CPU (0avgtext+0avgdata 2376maxresident)k
0inputs+0outputs (0major+81minor)pagefaults 0swaps
$ \time -p sleep 0.5
real 0.50
user 0.00
sys 0.00
$ \time -f %E sleep 0.5
0:00.50
</code>, <code>hellostdoutstderr</code>, <code>#!/bin/sh
sleep 0.5
echo stdout
echo stderr &gt;&amp;2
</code>, <code> $ ./hellostdoutstderr 
stdout
stderr
$ ./hellostdoutstderr &gt;stdout 2&gt;stderr
$ cat stdout
stdout
$ cat stderr
stderr
</code>, <code>time</code>, <code>$ time ./hellostdoutstderr &gt;stdout 2&gt;stderr

real    0m0,511s
user    0m0,005s
sys 0m0,006s
</code>, <code>time</code>, <code>$ \time ./hellostdoutstderr &gt;stdout 2&gt;stderr
$ cat stdout
stdout
$ cat stderr
stderr
0.00user 0.00system 0:00.50elapsed 1%CPU (0avgtext+0avgdata 3672maxresident)k
0inputs+16outputs (0major+311minor)pagefaults 0swaps
</code>, <code>time</code>, <code>$ \time -o timeout ./hellostdoutstderr &gt;stdout 2&gt;stderr
$ cat stderr
stderr
$ cat timeout 
0.00user 0.00system 0:00.50elapsed 1%CPU (0avgtext+0avgdata 3676maxresident)k
0inputs+16outputs (0major+309minor)pagefaults 0swaps
</code>]"
336,https://unix.stackexchange.com/questions/39273/,How to Navigate within bash's Reverse Search?,"[""You can access this via the forward-search-history function which is bind per default to ctrl+s. Unfortunately ctrl+s is used to signal xoff per default which means you can't use it to change the direction of the search. There are two solutions for solving the problem, one disabling sending the xoff/xon signaling and the other change the keybinding for forward-search-history "", 'Run stty -ixon in your terminal or add it to your ~/.bashrc. This allows you to use ctrl+s to use the forward-search-history history function.', 'For more information about control flow have a look at How to unfreeze after accidentally pressing Ctrl-S in a terminal? and some of the answers', ""If you don't want to change the default behavior of ctrl+s you can change the keybinding for forward-search-history with bind. As most keys are already defined in bash you may have to get creative:"", 'This will bind ctrl+t to forward-search-history, but please be aware that per default ctrl+t runs transpose-chars']","[<code>forward-search-history</code>, <code>xoff</code>, <code>xoff/xon</code>, <code>forward-search-history</code>, <code>stty -ixon</code>, <code>~/.bashrc</code>, <code>forward-search-history</code>, <code>forward-search-history</code>, <code>bind</code>, <code>bind ""\C-t"":forward-search-history
</code>, <code>transpose-chars</code>]"
337,https://unix.stackexchange.com/questions/191205/,BASH base conversion from decimal to hex,"['With bash (or any shell, provided the printf command is available (a standard POSIX command often built in the shells)):', '\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\nWith zsh, you can also do:', 'That works for bases from 2 to 36 (with 0-9a-z case insensitive as the digits).', 'With ksh93, you can use:', 'Which works for bases from 2 to 64 (with 0-9a-zA-Z@_ as the digits).', ""With ksh and zsh, there's also:"", ""Though that's limited to bases up to 36 in ksh88, zsh and pdksh and 64 in ksh93."", ""Note that all those are limited to the size of the long integers on your system (int's with some shells). For anything bigger, you can use bc or dc."", 'With supported bases ranging from 2 to some number required by POSIX to be at least as high as 99. For bases greater than 16, digits greater than 9 are represented as space-separated 0-padded decimal numbers.', 'Or same with dc (bc used to be (and still is on some systems) a wrapper around dc):']","[<code>bash</code>, <code>printf</code>, <code>printf '%x\n' 85
</code>, <code>zsh</code>, <code>dec=85
hex=$(([##16]dec))
</code>, <code>0-9a-z</code>, <code>ksh93</code>, <code>dec=85
base54=${ printf %..54 ""$dec""; }
</code>, <code>0-9a-zA-Z@_</code>, <code>ksh</code>, <code>zsh</code>, <code>$ typeset -i34 x=123; echo ""$x""
34#3l
</code>, <code>long</code>, <code>int</code>, <code>bc</code>, <code>dc</code>, <code>$ echo 'obase=16; 9999999999999999999999' | bc
21E19E0C9BAB23FFFFF
$ echo '16o 9999999999999999999999 p' | dc
21E19E0C9BAB23FFFFF
</code>, <code>$ echo 'obase=30; 123456' | bc
 04 17 05 06
</code>, <code>dc</code>, <code>bc</code>, <code>dc</code>, <code>$ echo 30o123456p | dc
 04 17 05 06
</code>]"
338,https://unix.stackexchange.com/questions/6699/,How do I suppress dd output?,"['From the dd(1) man page:', 'thus:', 'This still outputs the ', 'garbage when dd exits, so redirecting to a data sink really is your only option.']","[<code>dd(1)</code>, <code>   status=noxfer
          suppress transfer statistics
</code>, <code>dd if=boot1h of=""/dev/r$temp1"" status=noxfer
</code>, <code>0+1 records in
0+1 records out
</code>, <code>dd</code>]"
339,https://unix.stackexchange.com/questions/333186/,How to list the open file descriptors (and the files they refer to) in my current bash session,"['Yes, this will list all open file descriptors:', 'Of course, as usual: 0 is stdin, 1 is stdout and 2 is stderr.\nThe 4th is an open file (to write) in this case.']","[<code>$ ls -la /proc/$$/fd
total 0
dr-x------ 2 isaac isaac  0 Dec 28 00:56 .
dr-xr-xr-x 9 isaac isaac  0 Dec 28 00:56 ..
lrwx------ 1 isaac isaac 64 Dec 28 00:56 0 -&gt; /dev/pts/6
lrwx------ 1 isaac isaac 64 Dec 28 00:56 1 -&gt; /dev/pts/6
lrwx------ 1 isaac isaac 64 Dec 28 00:56 2 -&gt; /dev/pts/6
lrwx------ 1 isaac isaac 64 Dec 28 00:56 255 -&gt; /dev/pts/6
l-wx------ 1 isaac isaac 64 Dec 28 00:56 4 -&gt; /home/isaac/testfile.txt
</code>]"
340,https://unix.stackexchange.com/questions/70966/,How do I remove leading zeroes from output of 'date' or avoid octal interpretation of such decimal numbers?,"['In your case, you can simply disable zero padding by append - after % in the format string of date: %-H', ""By default, date pads numeric fields with zeroes. The following optional flags may follow '%':"", 'See date manual', 'If you want to interpret number in different base, in bash', 'So, to interpret a number as decimal, use 10#n form, eg. 10#09', 'See Arithmetic Evaluation section of bash manual.']","[<code>-</code>, <code>%</code>, <code>%-H</code>, <code>-</code>, <code>_</code>, <code>0</code>, <code>^</code>, <code>#</code>, <code>10#n</code>, <code>10#09</code>, <code>echo $((10#09*2))
18
</code>]"
341,https://unix.stackexchange.com/questions/209833/,What does a dollar sign followed by a square bracket $[...] mean in bash?,"['You can find old bash source here.  In particular I downloaded bash-1.14.7.tar.gz.  In the documentation/bash.txt you will find:', 'Arithmetic Expansion', 'Arithmetic expansion allows the evaluation of an arithmetic expression and  the substitution of the result.  There are two formats for arithmetic expansion:', 'The references to $[ are gone in doc/bash.html from the bash-doc-2.0.tar.gz download and the NEWS file mentions that:', 'The $[...] arithmetic expansion syntax is no longer supported, in favor of $((...)).', '$((...)) is also the standard syntax for an arithmetic expansion, but may have been added to the standard later than the original Bash implementation.', ""However, $[...] does still seem to work in Bash 5.0, so it's not completely removed.""]","[<code>documentation/bash.txt</code>, <code>     $[expression]

     $((expression))
</code>, <code>$[</code>, <code>doc/bash.html</code>, <code>NEWS</code>, <code>$[...]</code>, <code>$((...))</code>, <code>$((...))</code>, <code>$[...]</code>]"
342,https://unix.stackexchange.com/questions/214141/,Explain the shell command: shift $(($optind - 1)),"['shift $((OPTIND-1)) (note OPTIND is upper case) is normally found immediately after a getopts while loop. $OPTIND is the number of options found by getopts. ', 'As pauljohn32 mentions in the comments, strictly speaking, OPTIND gives the position of the next command line argument.', 'From the GNU Bash Reference Manual:', 'getopts optstring name [args]', 'getopts is used by shell scripts to parse positional parameters.\n  optstring contains the option characters to be recognized; if a\n  character is followed by a colon, the option is expected to have an\n  argument, which should be separated from it by whitespace. The colon\n  (‘:’) and question mark (‘?’) may not be used as option characters.\n  Each time it is invoked, getopts places the next option in the shell\n  variable name, initializing name if it does not exist, and the index\n  of the next argument to be processed into the variable OPTIND.\n  OPTIND is initialized to 1 each time the shell or a shell script is\n  invoked. When an option requires an argument, getopts places that\n  argument into the variable OPTARG. The shell does not reset OPTIND\n  automatically; it must be manually reset between multiple calls to\n  getopts within the same shell invocation if a new set of parameters\n  is to be used.', 'When the end of options is encountered, getopts exits with a return\n  value greater than zero. OPTIND is set to the index of the first\n  non-option argument, and name is set to ‘?’.', 'getopts normally parses the positional parameters, but if more\n  arguments are given in args, getopts parses those instead.', 'shift n\nremoves n strings from the positional parameters list. Thus shift $((OPTIND-1)) removes all the options that have been parsed by getopts from the parameters list, and so after that point, $1 will refer to the first non-option argument passed to the script.', 'Update', 'As mikeserv mentions in the comment, shift $((OPTIND-1)) can be unsafe. To prevent unwanted word-splitting etc, all parameter expansions should be double-quoted. So the safe form for the command is', 'shift ""$((OPTIND-1))""']","[<code>shift $((OPTIND-1))</code>, <code>OPTIND</code>, <code>getopts</code>, <code>while</code>, <code>$OPTIND</code>, <code>getopts</code>, <code>OPTIND</code>, <code>getopts</code>, <code>optstring</code>, <code>getopts</code>, <code>name</code>, <code>OPTIND</code>, <code>OPTIND</code>, <code>OPTARG</code>, <code>OPTIND</code>, <code>getopts</code>, <code>getopts</code>, <code>OPTIND</code>, <code>getopts</code>, <code>args</code>, <code>getopts</code>, <code>shift</code>, <code>shift $((OPTIND-1))</code>, <code>getopts</code>, <code>$1</code>, <code>shift $((OPTIND-1))</code>, <code>shift ""$((OPTIND-1))""</code>]"
343,https://unix.stackexchange.com/questions/33336/,How to enable autocompletion for remote paths when using scp?,"[""Make sure that you've turned on the fancy autocompletion. On many distributions, this means your ~/.bashrc needs to contain . /etc/bash_completion."", ""You'll need to have passwordless authentication set up, i.e. with a key that's already loaded in ssh-agent."", 'Establishing an SSH connection is slow, so you can considerably speed up completions by establishing a connection once and for all and using that connection thereafter. The relatively complicated way to do that is to open a master SSH connection with ssh -N -M target-host after setting up master-slave connections in ~/.ssh/config; see Multiple ssh sessions in single command for instructions (you need the ControlMaster and ControlPath options).', 'The simple method is to mount the remote filesystem over SSHFS and use cp with normal shell completion.']","[<code>~/.bashrc</code>, <code>. /etc/bash_completion</code>, <code>ssh-agent</code>, <code>ssh -N -M target-host</code>, <code>~/.ssh/config</code>, <code>ControlMaster</code>, <code>ControlPath</code>, <code>cp</code>, <code>mkdir ~/remote
sshfs USER@192.168.178.32:/home/USER ~/remote
cp -p someFile ~/remote/put/it/some/where/oh/damn/you/here
</code>]"
344,https://unix.stackexchange.com/questions/98948/,ASCII to Binary and Binary to ASCII conversion tools?,"['With spaces:', '(it assumes the input is in blocks of 8 bits (0-padded)).', 'With unpack ""(B8)*"", we extract 8 bits at a time, and we join the resulting strings with spaces with join "" "".']","[<code>$ echo AB | perl -lpe '$_=unpack""B*""'
0100000101000010
$ echo 0100000101000010 | perl -lpe '$_=pack""B*"",$_'
AB
</code>, <code>-e <i>expression</i></code>, <code>perl</code>, <code>-p</code>, <code>sed</code>, <code>$_</code>, <code>-l</code>, <code>sed</code>, <code>$_</code>, <code>perl -lpe code</code>, <code>sed code</code>, <code>perl</code>, <code>sed</code>, <code>unpack ""B*""</code>, <code>$_</code>, <code>pack</code>, <code>unpack</code>, <code>perldoc -f pack</code>, <code>$ echo AB | perl -lpe '$_=join "" "", unpack""(B8)*""'
01000001 01000010
$ echo 01000001 01000010 | perl -lape '$_=pack""(B8)*"",@F'
AB
</code>, <code>unpack ""(B8)*""</code>, <code>join "" ""</code>]"
345,https://unix.stackexchange.com/questions/19124/,bash multi line command with comments after the continuation character,"['Comments end at the first newline (see shell token recognition rule 10), without allowing continuation lines, so this code has foo in a separate command line:', ""As for your first proposal, the backslash isn't followed by a newline, you're just quoting the space: it's equivalent to"", '$(: this is a comment) substitutes the output of the command : this is a comment. If the output of that command is empty, this is effectively a highly confusing way to insert a comment in the middle of a line.', ""There's no magic going on: : is an ordinary command, the colon utility, which does nothing. The colon utility is mostly useful when the shell syntax requires a command but you happen to have nothing to do."", ""Another use case is an idiom for setting a variable if it's not already set."", ""The remark about goto is a historical one. The colon utility dates back from even before the Bourne shell, all the way to the Thompson shell, which had a goto instruction. The colon then meant a label; a colon is a fairly common syntax for goto labels (it's still present in sed).""]","[<code>foo</code>, <code>echo # this is a comment \
foo
</code>, <code>echo ' # this is a comment'
foo
</code>, <code>$(: this is a comment)</code>, <code>: this is a comment</code>, <code>:</code>, <code># Sample code to compress files that don't look compressed
case ""$1"" in
  *.gz|*.tgz|*.bz2|*.zip|*.jar|*.od?) :;; # the file is already compressed
  *) bzip2 -9 ""$1"";;
esac
</code>, <code>: ""${foo:=default value}""
</code>]"
346,https://unix.stackexchange.com/questions/49936/,/dev/tcp listen instead of nc listen,"['If Perl is installed (as it will be on a RHEL machine):', ""would work, unless a local firewall doesn't allow incoming connections to 1234."", 'If socat is installed:', 'If zsh is installed:']","[<code>perl -MIO::Socket::INET -ne 'BEGIN{$l=IO::Socket::INET-&gt;new(
  LocalPort=&gt;1234,Proto=&gt;""tcp"",Listen=&gt;5,ReuseAddr=&gt;1);
  $l=$l-&gt;accept}print $l $_' &lt; ~/.bashrc
</code>, <code>socat -u - tcp-listen:1234,reuseaddr &lt; ~/.bashrc
</code>, <code>zmodload zsh/net/tcp
ztcp -ld3 1234 &amp;&amp; # start listening socket on fd 3
  ztcp -ad4 3 &amp;&amp; # accept connection on fd 4
  ztcp -c 3 &amp;&amp; # close the listening socket that is no longer needed
  cat &lt; ~/.bashrc &gt;&amp;4 &amp;&amp; # send the data
  ztcp -c 4 # close the communication socket to tell the other end we're finished
</code>]"
347,https://unix.stackexchange.com/questions/120786/,List all binaries from $PATH,"[""This is not an answer, but it's showing binary, a command which you could run"", '(assuming bash)', 'Other useful commands ']","[<code>compgen -c
</code>, <code>bash</code>, <code>compgen -a # will list all the aliases you could run.
compgen -b # will list all the built-ins you could run.
compgen -k # will list all the keywords you could run.
compgen -A function # will list all the functions you could run.
compgen -A function -abck # will list all the above in one go.
</code>]"
348,https://unix.stackexchange.com/questions/46715/,Piping from grep to awk not working,"[""It's probably output buffering from grep.  you can disable that with grep --line-buffered."", ""But you don't need to pipe output from grep into awk.  awk can do regexp pattern matching all by itself."", ""tail -f test.txt | awk '/Beam/ {print $3}'""]","[<code>grep --line-buffered</code>, <code>tail -f test.txt | awk '/Beam/ {print $3}'</code>]"
349,https://unix.stackexchange.com/questions/4023/,Aliases vs functions vs scripts,"[""The main difference between aliases and functions is that aliases don't take arguments¹, but functions do. When you write something like alias l='ls --color', l foo is expanded to ls --color foo; you can't grab foo into the alias expansion and do something different with it the way you can do with a function. See also How to pass parameter to alias?."", ""Aliases are looked up before functions: if you have both a function and an alias called foo, foo invokes the alias. (If the alias foo is being expanded, it's temporarily blocked, which makes things like alias ls='ls --color' work. Also, you can bypass an alias at any time by running \\foo.) I wouldn't expect to see a measurable performance difference though."", 'Functions and standalone scripts have mostly similar capabilities; here are a few differences I can think of:', ""Something that's intermediate between a function and a standalone script is a script snippet that you read with the source or . builtin. Like a function, it can modify the shell's environment, and must be written in the shell's language. Like a script, it is loaded each time it's invoked and no sooner."", ""¹ \nYeah, I know, this doesn't apply to tcsh.\n""]","[<code>alias l='ls --color'</code>, <code>l foo</code>, <code>ls --color foo</code>, <code>foo</code>, <code>foo</code>, <code>foo</code>, <code>foo</code>, <code>alias ls='ls --color'</code>, <code>\foo</code>, <code>source</code>, <code>.</code>]"
350,https://unix.stackexchange.com/questions/62950/,"getopt, getopts or manual parsing - what to use when I want to support both short and long options?","[""If it has to be portable to a range of Unices, you'd have to stick to POSIX sh. And AFAIU there you just have no choice but rolling argument handling by hand.""]",[]
351,https://unix.stackexchange.com/questions/97882/,"Why do we need the ""at"" command in Linux?","['Bernhard\'s reply is correct: in multi-user systems, the ability to execute heavy programs at some ungodly hours of the night is especially convenient, for both the person submitting the job, and his coworkers. It is part of ""playing nice"". ', 'I did most of my Ph.D. computations this way, combining the script with the nice command which demoted the priority of my work whenever other people were keeping the machine busy, while leaving intact its ability to hog all the system resources at night. ', 'I used the very same command to check whether my program was running, and to restart it if necessary. ', 'Also, you should keep in mind that at was written way before screen, tmux, and so on, so that it was a simple way to have a detached shell, i.e., one that would not die once you logged off the system. ', 'Lastly, you should also notice that it is different from cron, which also has been around for a long time. The difference lies in the fact that at is occasional, while cron, being so repetitive, is more suited for system jobs which really need to be executed forever at fixed intervals: in fact, at gives you  your own environment, with your own settings (and choices) of environment variable, while cron uses a minimal set of environment variables (just check the difference in PATH, as an example). ']",[]
352,https://unix.stackexchange.com/questions/291285/,View a range of bash history,"['Instead of history, you can use fc, which allow you select range:']","[<code>history</code>, <code>fc</code>, <code>fc -l 4 7
</code>]"
353,https://unix.stackexchange.com/questions/182882/,Use .sh or .bash extension for bash scripts?,"['does using the .bash extension actually invoke bash or does it depend\n  on system config / 1st shebang line.', ""If you do not use an interpreter explicitly, then the interpreter being invoked is determined by the shebang used in the script. If you use an interpreter specifically then the interpreter doesn't care what extension you give for your script. However, the extension exists to make it very obvious for others what kind of script it is. "", 'See, .py extension to the bash script does not make it a python script.', 'Its always a bash script.']","[<code>shebang</code>, <code>[sreeraj@server ~]$ cat ./ext.py
#!/bin/bash
echo ""Hi. I am a bash script""
</code>, <code>.py</code>, <code>[sreeraj@server ~]$ python ./ext.py
  File ""./ext.py"", line 2
    echo ""Hi. I am a bash script""
                                ^
SyntaxError: invalid syntax
</code>, <code>bash</code>, <code>[sreeraj@server ~]$ ./ext.py
Hi. I am a bash script
</code>]"
354,https://unix.stackexchange.com/questions/4290/,aliasing cd to pushd - is it a good idea?,"['Personally, I have these in my bashrc and use them all the time:', 'You can then navigate around on the command-line a bit like a browser. cd changes the directory. back goes to the previous directory that you cded from. And flip will move between the current and previous directories without popping them from the directory stack. Overall, it works great.', ""The only real problem that I'm aware of is the fact that it's then a set of commands that I'm completely used to but don't exist on anyone else's machine. So, if I have to use someone else's machine, it can be a bit frustrating. If you're used to just using pushd and popd directly, you don't have that problem. And while if you just alias cd put not popd, you won't have the issue of back not existing, you'll still have the problem that cd doesn't do quite what you expect on other machines."", ""I would note, however, that your particular implementation of cd doesn't quite work like cd in that the normal cd by itself will go to your home directory, but yours doesn't. The version that I have here doesn't have that problem. Mine also appends DIRSTACK onto the front of the dirs print out, but that's more a matter of personal taste more than anything."", ""So, as I said, I use these aliases all the time and have no problem with them. It's just that it can be a bit frustrating to have to use another machine and then find them not there (which shouldn't be surprising, but they're one of those things that you use so often that you don't think about them, so having them not work like you're used to can still be surprising).""]","[<code>pushd()
{
  if [ $# -eq 0 ]; then
    DIR=""${HOME}""
  else
    DIR=""$1""
  fi

  builtin pushd ""${DIR}"" &gt; /dev/null
  echo -n ""DIRSTACK: ""
  dirs
}

pushd_builtin()
{
  builtin pushd &gt; /dev/null
  echo -n ""DIRSTACK: ""
  dirs
}

popd()
{
  builtin popd &gt; /dev/null
  echo -n ""DIRSTACK: ""
  dirs
}

alias cd='pushd'
alias back='popd'
alias flip='pushd_builtin'
</code>, <code>cd</code>, <code>back</code>, <code>cd</code>, <code>flip</code>, <code>pushd</code>, <code>popd</code>, <code>cd</code>, <code>popd</code>, <code>back</code>, <code>cd</code>, <code>cd</code>, <code>cd</code>, <code>cd</code>, <code>DIRSTACK</code>, <code>dirs</code>]"
355,https://unix.stackexchange.com/questions/438564/,How do Ubuntu and Debian manage $HOME for users with sudo privileges?,"['Both Debian and Ubuntu ship an /etc/sudoers file that contains Defaults env_reset, which resets environment variables.', 'However, the behavior of env_reset was changed from not touching $HOME to resetting it to the home of the target user.', 'Ubuntu decided to patch their version of sudo to keep the previous behavior:\nhttps://bugs.launchpad.net/ubuntu/+source/sudo/+bug/760140', 'In Ubuntu, in order to reset the $HOME environment variable to the target user, one has to set either Defaults always_set_home or Defaults set_home (in which case only sudo -s will get HOME updated) in their /etc/sudoers.', 'This bug at Ubuntu tracker has some more rationale on not setting $HOME in sudo:\nhttps://bugs.launchpad.net/ubuntu/+source/sudo/+bug/1373495', 'See comment #4:', ""If HOME is removed, then e.g. vim, bash, etc., will use /root/.vimrc,\n  /root/.bashrc, etc rather than the user's ~/.vimrc, ~/.bashrc, etc.\n  While it's a bad idea to run X clients via sudo, they too would likely\n  look in the wrong locations for configuration files, and there's a\n  chance that X11 clients may not even be able to connect to the X11\n  server if they are aimed at the wrong .Xauthority file."", ""It's a conscious decision by Ubuntu developers."", 'This answer has more details on the sudoers options such as always_set_home:\nhttps://unix.stackexchange.com/a/91572/281844', ""There's a second issue in your question, which is the sudo echo $HOME which still displays the user's home even in Debian."", 'That happens because the shell is expanding $HOME before running the sudo command.', 'So this:', 'Is first expanded by the shell into:', 'And then sudo executes echo /home/user as root...', 'This should demonstrate the difference too:', 'Or get a full root shell and see the environment variable there:']","[<code>/etc/sudoers</code>, <code>Defaults env_reset</code>, <code>env_reset</code>, <code>sudo</code>, <code>Defaults always_set_home</code>, <code>Defaults set_home</code>, <code>sudo -s</code>, <code>/etc/sudoers</code>, <code>always_set_home</code>, <code>sudo echo $HOME</code>, <code>$HOME</code>, <code>sudo</code>, <code>$ sudo echo $HOME
</code>, <code>$ sudo echo /home/user
</code>, <code>echo /home/user</code>, <code>$ sudo bash -c 'echo $HOME'
/root
</code>, <code>$ sudo -s
# echo $HOME
/root
</code>]"
356,https://unix.stackexchange.com/questions/48805/,Semicolon in conditional structures,"['The semicolon is needed only when the end of line is missing:', 'Without semicolons, you get Syntax error.', 'I do not understand your question about quotes. Can you be more specific?', '(And by the way, using = instead of == is more portable and POSIX compliant).']","[<code>if [ ""a"" == ""a"" ] ; then echo ""true"" ; fi
</code>, <code>=</code>, <code>==</code>]"
357,https://unix.stackexchange.com/questions/56655/,What is the difference between [[ $a == z* ]] and [ $a == z* ]?,"['The difference between [[ … ]] and [ … ] is mostly covered in Why does parameter expansion with spaces without quotes work inside double brackets ""[["" but not inside single brackets ""[""?.\nCrucially, [[ … ]] is special syntax, whereas [ is a funny-looking name for a command. [[ … ]] has special syntax rules for what\'s inside, [ … ] doesn\'t.', ""With the added wrinkle of a wildcard, here's how [[ $a == z* ]] is evaluated:"", ""Here's how [ $a == z* ] is evaluated:"", 'Note: In [[ $a == z* ]], at step 3, the value of a does not undergo word splitting and filename generation, because it\'s in a context where a single word is expected (the left-hand argument of the conditional operator ==). In most cases, if a single word makes sense at that position then variable expansion behaves like it does in double quotes. However, there\'s an exception to that rule: in [[ abc == $a ]], if the value of a contains wildcards, then abc is matched against the wildcard pattern. For example, if the value of a is a* then [[ abc == $a ]] is true (because the wildcard * coming from the unquoted expansion of $a matches bc) whereas [[ abc == ""$a"" ]] is false (because the ordinary character * coming from the quoted expansion of $a does not match bc). Inside [[ … ]], double quotes do not make a difference, except on the right-hand side of the string matching operators (=, ==, != and =~).']","[<code>[[ … ]]</code>, <code>[ … ]</code>, <code>[[ … ]]</code>, <code>[</code>, <code>[[ … ]]</code>, <code>[ … ]</code>, <code>[[ $a == z* ]]</code>, <code>[[ … ]]</code>, <code>$a == z*</code>, <code>==</code>, <code>$a</code>, <code>z*</code>, <code>a</code>, <code>==</code>, <code>a</code>, <code>z*</code>, <code>[ $a == z* ]</code>, <code>[</code>, <code>$a</code>, <code>==</code>, <code>z*</code>, <code>]</code>, <code>$a</code>, <code>a</code>, <code>a</code>, <code>foo b*</code>, <code>a='foo b*'</code>, <code>bar</code>, <code>baz</code>, <code>qux</code>, <code>zim</code>, <code>zum</code>, <code>[</code>, <code>foo</code>, <code>bar</code>, <code>baz</code>, <code>==</code>, <code>zim</code>, <code>zum</code>, <code>]</code>, <code>[</code>, <code>[</code>, <code>[[ $a == z* ]]</code>, <code>a</code>, <code>==</code>, <code>[[ abc == $a ]]</code>, <code>a</code>, <code>abc</code>, <code>a</code>, <code>a*</code>, <code>[[ abc == $a ]]</code>, <code>*</code>, <code>$a</code>, <code>bc</code>, <code>[[ abc == ""$a"" ]]</code>, <code>*</code>, <code>$a</code>, <code>bc</code>, <code>[[ … ]]</code>, <code>=</code>, <code>==</code>, <code>!=</code>, <code>=~</code>]"
358,https://unix.stackexchange.com/questions/38330/,How can I find a rogue alias declaration?,"['I would look in /etc/profile.d/ for the offending alias.', 'You could also do the following to find it:', 'This will recursively grep through files looking for a line beginning with alias COMMAND.', 'If all else fails, put this at the end of your ~/.bashrc']","[<code>/etc/profile.d/</code>, <code>alias</code>, <code>grep -r '^alias COMMAND' /etc
</code>, <code>grep</code>, <code>alias COMMAND</code>, <code>~/.bashrc</code>, <code>unalias COMMAND
</code>]"
359,https://unix.stackexchange.com/questions/25425/,What does : ${param:=value} mean?,"[""Let's break this down into pieces."", 'This code runs the command : with some arguments. The command : does nothing and ignores its arguments. Therefore the whole command line does nothing, except whatever side effects happen in the arguments.', 'The syntax ${parameter_name:=value} exists in all non-antique Bourne-style shells, including ash, bash, ksh and zsh. It sets the parameter to a default if necessary. It is equivalent to', 'In other words, if parameter_name is not set or is set to an empty value, then set it to the indicated value; and then run the command, using the new parameter value. There is a variant, ${parameter_name=value}, which leaves the parameter empty if it was empty, only using the indicated value if the parameter was unset.', ""You'll find this syntax documented under “parameter expansion” in the POSIX spec, and the dash, bash, ksh and zsh manuals."", 'There are variations on this syntax, in particular ${parameter_name:-value} which let you use a default value for this expansion only, without assigning to the parameter.', 'In summary, : ${parameter_name:=value} is a concise way of writing']","[<code>:</code>, <code>:</code>, <code>${parameter_name:=value}</code>, <code>if [ -z ""$parameter_name"" ]; then parameter_name=value; fi
… ${parameter_name}
</code>, <code>parameter_name</code>, <code>${parameter_name=value}</code>, <code>${parameter_name:-value}</code>, <code>: ${parameter_name:=value}</code>, <code>if [ -z ""$parameter_name"" ]; then parameter_name=value; fi
</code>]"
360,https://unix.stackexchange.com/questions/23572/,Bash Sudo Command Not Found,"[""It looks from http://www.turnkeylinux.org/redmine like Redmine, unlike Ubuntu, does not use sudo by default. What username are you using to SSH in? If it's root, then you don't need to use sudo, as everything you do when SSHed in to the Redmine system is done as root. If it's something else, like admin, then you could try using the su command to get a root shell in which to run commands as root.""]","[<code>root</code>, <code>sudo</code>, <code>root</code>, <code>admin</code>, <code>su</code>, <code>root</code>, <code>root</code>]"
361,https://unix.stackexchange.com/questions/123103/,How to keep Bash running after command execution?,"[""This is better done from a script though with exec $0. Or if one of those file descriptors directs to a terminal device that is not currently being used it will help - you've gotta remember, other processes wanna check that terminal, too. "", ""And by the way, if your goal is, as I assume it is, to preserve the script's environment after executing it, you'd probably be a lot better served with : "", ""The shell's .dot and bash's source are not one and the same - the shell's .dot is POSIX specified as a special shell builtin and is therefore as close to being guaranteed as you can get, though this is by no means a guarantee it will be there...  "", 'Though the above should do as you expect with little issue. For instance, you can :', ""The shell will run your script and return you to the interactive prompt - so long as you avoid exiting the shell from your script, that is, or backgrounding your process - that'll link your i/o to /dev/null."", ""It's my opinion that you should get a little more familiar with the shell's built-in task management options. @Kiwy and @jillagre have both already touched on this in their answers, but it might warrant further detail. And I've already mentioned one POSIX-specified special shell built-in, but set, jobs, fg, and bg are a few more, and, as another answer demonstrates trap and kill are two more still. "", ""If you're not already receiving instant notifications on the status of concurrently running backgrounded  processes, it's because your current shell options are set to the POSIX-specified default of -m, but you can get these asynchronously with set -b instead:"", ""A very fundamental feature of Unix-based systems is their method of handling process signals. I once read an enlightening article on the subject that likens this process to Douglas Adams' description of the planet NowWhat: "", '""In The Hitchhiker\'s Guide to the Galaxy, Douglas Adams mentions an \n  extremely dull planet, inhabited by a bunch of depressed humans and a \n  certain breed of animals with sharp teeth which communicate with the \n  humans by biting them very hard in the thighs. This is strikingly \n  similar to UNIX, in which the kernel communicates with processes by \n  sending paralyzing or deadly signals to them. Processes may intercept \n  some of the signals, and try to adapt to the situation, but most of them \n  don\'t."" ', 'This is referring to kill signals.', ""At least for me, the above quote answered a lot of questions. For instance, I'd always considered it very strange and not at all intuitive that if I wanted to monitor a dd process I had to kill it. After reading that it made sense."", ""I would say most of them don't try to adapt for good reason - it can be a far greater annoyance than it would be a boon to have a bunch of processes spamming your terminal with whatever information their developers thought might have been important to you."", ""Depending on your terminal configuration (which you can check with stty -a), CTRL+Z is likely set to forward a SIGTSTP to the current foreground process group leader, which is likely your shell, and which should also be configured by default to trap that signal and suspend your last command. Again, as the answers of @jillagre and @Kiwy together show, there's no stopping you from tailoring this functionality to your purpose as you prefer."", ""So to take advantage of these features it's expected that you first understand them and customize their handling to your own needs. For example, I've just found this screenrc on Github that includes screen key-bindings for SIGTSTP:"", 'That would make it a simple matter to suspend a process running as a child screen process or the screen child process itself as you wished. ', 'And immediately afterward:', 'OR:', 'Would foreground or background the process as you preferred. The jobs built-in can provide you a list of these at any time. Adding the -l operand will include pid details.']","[<code>( exec sh -i 3&lt;&lt;SCRIPT 4&lt;&amp;0 &lt;&amp;3                                        ⏎
    echo ""do this thing""
    echo ""do that thing""
  exec  3&gt;&amp;- &lt;&amp;4
  SCRIPT
)
</code>, <code>exec $0.</code>, <code>. ./script
</code>, <code>.dot</code>, <code>bash's source</code>, <code>.dot</code>, <code> ( exec sh -i 3&lt;&lt;SCRIPT 4&lt;&amp;0 &lt;&amp;3                                        ⏎
    echo ""do this thing""
    echo ""do that thing""
    $(cat /path/to/script)
    exec  3&gt;&amp;- &lt;&amp;4
    SCRIPT
 )
</code>, <code>exit</code>, <code>/dev/null.</code>, <code>% printf 'echo ""%s""\n' ""These lines will print out as echo"" \
    ""statements run from my interactive shell."" \
    ""This will occur before I'm given the prompt."" &gt;|/tmp/script
% ( exec sh -i 3&lt;&lt;SCRIPT 4&lt;&amp;0 &lt;&amp;3
    echo ""do this thing""
    echo ""do that thing""
    $(cat /tmp/script)
    exec  3&gt;&amp;- &lt;&amp;4
SCRIPT
)
sh-4.3$ echo ""do this thing""
    do this thing
sh-4.3$ echo ""do that thing""
    do that thing
sh-4.3$ echo ""These lines will print out as echo""
    These lines will print out as echo
sh-4.3$ echo ""statements run from my interactive shell.""
    statements run from my interactive shell.
sh-4.3$ echo ""This will occur before I'm given the prompt.""
    This will occur before I'm given the prompt.
sh-4.3$ exec  3&gt;&amp;- &lt;&amp;4
sh-4.3$
</code>, <code>JOBS</code>, <code>set, jobs, fg,</code>, <code>bg</code>, <code>trap</code>, <code>kill</code>, <code>-m</code>, <code>set -b</code>, <code>% man set
</code>, <code>    −b This option shall be supported if the implementation supports the
         User  Portability  Utilities  option. It shall cause the shell to
         notify the user asynchronously of background job completions. The
         following message is written to standard error:
</code>, <code>             ""[%d]%c %s%s\n"", &lt;job-number&gt;, &lt;current&gt;, &lt;status&gt;, &lt;job-name&gt;

         where the fields shall be as follows:

         &lt;current&gt; The  character  '+' identifies the job that would be
                     used as a default for the fg or  bg  utilities;  this
                     job  can  also  be specified using the job_id ""%+"" or
                     ""%%"".  The character  '−'  identifies  the  job  that
                     would  become  the default if the current default job
                     were to exit; this job can also  be  specified  using
                     the  job_id  ""%−"".   For  other jobs, this field is a
                     &lt;space&gt;.  At most one job can be identified with  '+'
                     and  at  most one job can be identified with '−'.  If
                     there is any suspended  job,  then  the  current  job
                     shall  be  a suspended job. If there are at least two
                     suspended jobs, then the previous job also shall be a
</code>, <code>   −m  This option shall be supported if the implementation supports the
         User Portability Utilities option. All jobs shall be run in their
         own  process groups. Immediately before the shell issues a prompt
         after completion of the background job, a message  reporting  the
         exit  status  of  the background job shall be written to standard
         error. If a foreground job stops, the shell shall write a message
         to  standard  error to that effect, formatted as described by the
         jobs utility. In addition, if a job  changes  status  other  than
         exiting  (for  example,  if  it  stops  for input or output or is
         stopped by a SIGSTOP signal), the shell  shall  write  a  similar
         message immediately prior to writing the next prompt. This option
         is enabled by default for interactive shells.
</code>, <code>signals</code>, <code>kill signals</code>, <code>% kill -l 
&gt; HUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM STKFLT CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL PWR SYS
</code>, <code>dd</code>, <code>kill</code>, <code>stty -a</code>, <code>CTRL+Z</code>, <code>SIGTSTP</code>, <code>trap</code>, <code>SCREEN JOBS</code>, <code>screen</code>, <code>SIGTSTP</code>, <code># hitting 'C-z C-z' will run Ctrl+Z (SIGTSTP, suspend as usual)
bind ^Z stuff ^Z

# hitting 'C-z z' will suspend the screen client
bind z suspend
</code>, <code>screen</code>, <code>screen</code>, <code>% fg  
</code>, <code>% bg
</code>, <code>jobs</code>, <code>-l</code>]"
362,https://unix.stackexchange.com/questions/17717/,Refer to a file under the same directory of a script found in $PATH,"['These should work the same, as long as there are no symlinks (in the path  expansion or the script itself):', 'MYDIR=""$(dirname ""$(realpath ""$0"")"")""', 'MYDIR=""$(dirname ""$(which ""$0"")"")""', 'A two step version of any of the above:', 'MYSELF=""$(realpath ""$0"")""', 'MYDIR=""${MYSELF%/*}""', 'If there is a symlink on the way to your script, then which will provide an answer not including resolution of that link. If realpath is not installed by default on your system, you can find it here.', '[EDIT]: As it seems that realpath has no advantage over readlink -f suggested by Caleb, it is probably better to use the latter. My timing tests indicate it is actually faster.']","[<code>MYDIR=""$(dirname ""$(realpath ""$0"")"")""</code>, <code>MYDIR=""$(dirname ""$(which ""$0"")"")""</code>, <code>MYSELF=""$(realpath ""$0"")""</code>, <code>MYDIR=""${MYSELF%/*}""</code>, <code>which</code>, <code>realpath</code>, <code>realpath</code>, <code>readlink -f</code>]"
363,https://unix.stackexchange.com/questions/193659/,"In which situations are PS2, PS3, PS4 used as the prompt?","['Here is what the bash documentation says:', 'So, PS1 is your normal ""waiting for a command"" prompt, PS2 is the\ncontinuation prompt that you saw after typing an incomplete command,\nPS3 is shown when the select command is waiting for input, and\nPS4 is the debugging trace line prefix.', ""The documentation I quoted doesn't say so, but the default for\nPS3 in bash is #?:""]","[<code>PS1    The  value  of  this parameter is expanded (see PROMPTING below)
       and used as the primary prompt string.   The  default  value  is
       ``\s-\v\$ ''.
PS2    The  value of this parameter is expanded as with PS1 and used as
       the secondary prompt string.  The default is ``&gt; ''.
PS3    The value of this parameter is used as the prompt for the select
       command (see SHELL GRAMMAR above).
PS4    The  value  of  this  parameter  is expanded as with PS1 and the
       value is printed before each command  bash  displays  during  an
       execution  trace.  The first character of PS4 is replicated mul‐
       tiple times, as necessary, to indicate multiple levels of  indi‐
       rection.  The default is ``+ ''.
</code>, <code>PS1</code>, <code>PS2</code>, <code>PS3</code>, <code>select</code>, <code>PS4</code>, <code>PS3</code>, <code>#?</code>, <code>$ select x in foo bar baz; do echo $x; done
1) foo
2) bar
3) baz
#? 3
baz
#? 2
bar
#? ^C
</code>]"
364,https://unix.stackexchange.com/questions/72819/,Count number of lines of output from previous program,"['You can use tee to split the output stream sending one copy to wc and the other copy to STDOUT like normal.', ""The >(cmd) is bash syntax which means run cmd and replace the >(cmd) bit with the path to (a named pipe connected to) that program's STDIN.""]","[<code>tee</code>, <code>wc</code>, <code>program | tee &gt;(wc -l)
</code>, <code>&gt;(cmd)</code>, <code>cmd</code>, <code>&gt;(cmd)</code>]"
365,https://unix.stackexchange.com/questions/53841/,How to use a timer in bash?,"['If you want the duration in seconds, at the top use', 'and at the end']","[<code>start=$SECONDS
</code>, <code>duration=$(( SECONDS - start ))
</code>]"
366,https://unix.stackexchange.com/questions/174016/,How do I use null bytes in Bash?,"['Bash uses C-style strings internally, which are terminated by null bytes. This means that a Bash string (such as the value of a variable, or an argument to a command) can never actually contain a null byte. For example, this mini-script:', ""actually prints 3, because $foobar is actually just 'foo': the bar comes after the end of the string."", ""Similarly, echo $'foo\\0bar' just prints foo, because echo doesn't know about the \\0bar part."", 'As you can see, the \\0 sequence is actually very misleading in a $\'...\'-style string; it looks like a null byte inside the string, but it doesn\'t end up working that way. In your first example, your read command has -d $\'\\0\'. This works, but only because -d \'\' also works! (That\'s not an explicitly documented feature of read, but I suppose it works for the same reason: \'\' is the empty string, so its terminating null byte comes immediately. -d delim is documented as using ""The first character of delim"", and I guess that even works if the ""first character"" is past the end of the string!)', 'But as you know from your find example, it is possible for a command to print out a null byte, and for that byte to be piped to another command that reads it as input. No part of that relies on storing a null byte in a string inside Bash. The only problem with your second example is that we can\'t use $\'\\0\' in an argument to a command; echo ""$file""$\'\\0\' could happily print the null byte at the end, if only it knew that you wanted it to.', ""So instead of using echo, you can use printf, which supports the same sorts of escape sequences as $'...'-style strings. That way, you can print a null byte without having to have a null byte inside a string. That would look like this:"", 'or simply this:', '(Note: echo actually also has an -e flag that would let it process \\0 and print a null byte; but then it would also try to process any special sequences in your filename. So the printf approach is more robust.)', ""Incidentally, there are some shells that do allow null bytes inside strings. Your example works fine in Zsh, for example (assuming default settings). However, regardless of your shell, Unix-like operating systems don't provide a way to include null bytes inside arguments to programs (since program arguments are passed as C-style strings), so there will always be some limitations. (Your example can work in Zsh only because echo is a shell builtin, so Zsh can invoke it without relying on the OS support for invoking other programs. If you used command echo instead of echo, so that it bypassed the builtin and used the standalone echo program on the $PATH, you'd see the same behavior in Zsh as in Bash.)""]","[<code>foobar=$'foo\0bar'    # foobar='foo' + null byte + 'bar'
echo ""${#foobar}""     # print length of $foobar
</code>, <code>3</code>, <code>$foobar</code>, <code>'foo'</code>, <code>bar</code>, <code>echo $'foo\0bar'</code>, <code>foo</code>, <code>echo</code>, <code>\0bar</code>, <code>\0</code>, <code>$'...'</code>, <code>read</code>, <code>-d $'\0'</code>, <code>-d ''</code>, <code>read</code>, <code>''</code>, <code>-d <i>delim</i></code>, <code>find</code>, <code>$'\0'</code>, <code>echo ""$file""$'\0'</code>, <code>echo</code>, <code>printf</code>, <code>$'...'</code>, <code>for file in * ; do printf '%s\0' ""$file"" ; done \
  | while IFS= read -r -d '' ; do echo ""$REPLY"" ; done
</code>, <code>printf '%s\0' * \
  | while IFS= read -r -d '' ; do echo ""$REPLY"" ; done
</code>, <code>echo</code>, <code>-e</code>, <code>\0</code>, <code>printf</code>, <code>echo</code>, <code>command echo</code>, <code>echo</code>, <code>echo</code>, <code>$PATH</code>]"
367,https://unix.stackexchange.com/questions/88642/,What does !$ mean?,"[""Basically, it's the last argument to the previous command."", '!$ is the ""end"" of the previous command. Consider the following\n  example: We start by looking for a word in a file:', 'if joe is in that userlist, we want to remove him from it. We can either fire up vi with that long directory tree as the argument, or as simply as vi !$ Which\n  bash expands to:', '(source; handy guide, by the way)', ""It's worth nothing the distinction between this !$ token and the special shell variable $_.\nIndeed, both expand to the last argument of the previous command. However, !$ is expanded during history expansion, while $_ is expanded during parameter expansion.\nOne important consequence of this is that, when you use !$, the expanded command is saved in your history."", 'For example, consider the keystrokes', 'echo Foo Enter echo !$ Jar Enter Up Enter; and', 'echo Foo Enter echo $_ Jar Enter Up Enter.', '(The only characters changed are the $! and $_ in the middle.)', 'In the former, when you press Up, the command line reads echo Foo Jar, so the last line written to stdout is Foo Jar.', 'In the latter, when you press Up, the command line reads echo $_ bar, but now $_ has a different value than it did previously—indeed, $_ is now Jar, so the last line written to stdout is Jar Jar.', 'Another consequence is that _ can be used in other parameter expansions, for example, the sequence of commands', 'prints isomorphism isosceles.\nBut there\'s no analogous ""${!$%morphism}"" expansion.', 'For more information about the phases of expansion in Bash, see the EXPANSION section of man 1 bash (this is called Shell Expansions in the online edition). The HISTORY EXPANSION section is separate.']","[<code>!$</code>, <code>grep -i joe /some/long/directory/structure/user-lists/list-15
</code>, <code>vi !$</code>, <code>vi /some/long/directory/structure/user-lists/list-15
</code>, <code>!$</code>, <code>$_</code>, <code>!$</code>, <code>$_</code>, <code>!$</code>, <code>echo Foo</code>, <code>echo !$ Jar</code>, <code>echo Foo</code>, <code>echo $_ Jar</code>, <code>$!</code>, <code>$_</code>, <code>echo Foo Jar</code>, <code>Foo Jar</code>, <code>echo $_ bar</code>, <code>$_</code>, <code>$_</code>, <code>Jar</code>, <code>Jar Jar</code>, <code>_</code>, <code>printf '%s '    isomorphism
printf '%s\n'   ${_%morphism}sceles
</code>, <code>isomorphism isosceles</code>, <code>${!$%morphism}</code>, <code>EXPANSION</code>, <code>man 1 bash</code>, <code>HISTORY EXPANSION</code>]"
368,https://unix.stackexchange.com/questions/93783/,search text on the terminal output,"['Ctrl+a (default screen command prefix), [ (enter copy mode) followed by ?SEARCH_TEXT seems to work. Press n to go to the next occurrence. From there, you can copy words, lines, regions, etc to dump into files or paste later on (with Ctrl+a, ]).', '']","[<code>screen</code>, <code>copy</code>, <code>?SEARCH_TEXT</code>]"
369,https://unix.stackexchange.com/questions/107939/,How to restart the Python script automatically if it is killed or dies,"['On Ubuntu (until 14.04, 16.04 and later use systemd) can use upstart to do so, better than a cron job. You put a config setup in /etc/init and make sure you specify respawn', 'It could be a minimal file /etc/init/testing.conf (edit as root):', 'And you can test with /your/base/directory/testing.py:', 'and start with:', 'and follow what happens (in another window) with:', 'and stop with:', 'You can also add [start on][2] to have the command start on boot of the system.']","[<code>/etc/init</code>, <code>/etc/init/testing.conf</code>, <code>root</code>, <code>chdir /your/base/directory
exec python testing.py
respawn
</code>, <code>/your/base/directory/testing.py</code>, <code>from __future__ import print_function

import time

with open('/var/tmp/testing.log', 'a') as fp:
    print(time.time(), 'done', file=fp)
    time.sleep(3)
</code>, <code>sudo start testing
</code>, <code>tail -f /var/tmp/testing.log
</code>, <code>sudo stop testing
</code>, <code>[start on][2]</code>]"
370,https://unix.stackexchange.com/questions/24260/,Reading lines from a file with bash: for vs. while,"['The for loop is fine here. But note that this is because the file contains machine names, which do not contain any whitespace characters or globbing characters. for x in $(cat file); do … does not work to iterate over the lines of file in general, because the shell first splits the output from the command cat file anywhere there is whitespace, and then treats each word as a glob pattern so \\[?* are further expanded. You can make for x in $(cat file) safe if you work on it:', 'Related reading: Looping through files with spaces in the names?; How can I read line by line from a variable in bash?; Why is while IFS= read used so often, instead of IFS=; while read..? Note that when using while read, the safe syntax to read lines is while IFS= read -r line; do ….', ""Now let's turn to what goes wrong with your while read attempt. The redirection from the server list file applies to the whole loop. So when ssh runs, its standard input comes from that file. The ssh client can't know when the remote application might want to read from its standard input. So as soon as the ssh client notices some input, it sends that input to the remote side. The ssh server there is then ready to feed that input to the remote command, should it want it. In your case, the remote command never reads any input, so the data ends up discarded, but the client side doesn't know anything about that. Your attempt with echo worked because echo never reads any input, it leaves its standard input alone."", 'There are a few ways you can avoid this. You can tell ssh not to read from standard input, with the -n option.', ""The -n option in fact tells ssh to redirect its input from /dev/null. You can do that at the shell level, and it'll work for any command."", ""A tempting method to avoid ssh's input coming from the file is to put the redirection on the read command: while read server </home/kenny/list_of_servers.txt; do …. This will not work, because it causes the file to be opened again each time the read command is executed (so it would read the first line of the file over and over). The redirection needs to be on the whole while loop so that the file is opened once for the duration of the loop."", ""The general solution is to provide the input to the loop on a file descriptor other than standard input. The shell has constructs to ferry input and output from one descriptor number to another. Here, we open the file on file descriptor 3, and redirect the read command's standard input from file descriptor 3. The ssh client ignores open non-standard descriptors, so all is well."", 'In bash, the read command has a specific option to read from a different file descriptor, so you can write read -u3 server.', 'Related reading: File descriptors & shell scripting; When would you use an additional file descriptor?']","[<code>for</code>, <code>for x in $(cat file); do …</code>, <code>file</code>, <code>cat file</code>, <code>\[?*</code>, <code>for x in $(cat file)</code>, <code>set -f
IFS='
'
for x in $(cat file); do …
</code>, <code>while IFS= read</code>, <code>IFS=; while read..</code>, <code>while read</code>, <code>while IFS= read -r line; do …</code>, <code>while read</code>, <code>ssh</code>, <code>echo</code>, <code>echo</code>, <code>-n</code>, <code>while read server; do
  ssh -n $server ""uname -a""
done &lt; /home/kenny/list_of_servers.txt
</code>, <code>-n</code>, <code>ssh</code>, <code>/dev/null</code>, <code>while read server; do
  ssh $server ""uname -a"" &lt;/dev/null
done &lt; /home/kenny/list_of_servers.txt
</code>, <code>read</code>, <code>while read server &lt;/home/kenny/list_of_servers.txt; do …</code>, <code>read</code>, <code>read</code>, <code>while read server &lt;&amp;3; do
  ssh $server ""uname -a""
done 3&lt;/home/kenny/list_of_servers.txt
</code>, <code>read</code>, <code>read -u3 server</code>]"
371,https://unix.stackexchange.com/questions/127334/,Bash subshell creation with curly braces,"['In a pipeline, all commands run concurrently (with their stdout/stdin connected by pipes) so in different processes.', 'In', 'All three commands run in different processes, so at least two of them have to run in a child process. Some shells run one of them in the current shell process (if builtin like read or if the pipeline is the last command of the script), but bash runs them all in their own separate process (except with the lastpipe option in recent bash versions and under some specific conditions).', '{...} groups commands. If that group is part of a pipeline, it has to run in a separate process just like a simple command.', 'In:', 'We need a shell to evaluate that a; b ""$?"" is a separate process, so we need a subshell. The shell could optimise by not forking for b since it\'s the last command to be run in that group. Some shells do it, but apparently not bash.']","[<code>cmd1 | cmd2 | cmd3
</code>, <code>read</code>, <code>bash</code>, <code>lastpipe</code>, <code>bash</code>, <code>{...}</code>, <code>{ a; b ""$?""; } | c
</code>, <code>a; b ""$?""</code>, <code>b</code>, <code>bash</code>]"
372,https://unix.stackexchange.com/questions/116955/,where is `cd` located?,"[""If you're in Bash cd is a builtin. The type command even bears this out:"", 'The system will use the first thing in this list, so the builtin will be the preferred option, and the only one that works (see the section below on What is /bin/cd). ', 'I like to think of builtins as functions that Bash knows how to do itself. Basically anything that you use a lot has been moved into the Bash ""kernel"" so that it doesn\'t have to go executing a process for each time. ', 'You can always explicitly tell Bash that you want a builtin by using the builtin command like so:', 'See the help about builtin:', 'The hash is meant only to ""hash"" (aka. ""save"" in a key/value pair) the locations of files, not for builtins or keywords. The primary task for hash is in saving on having to go through the $PATH each time looking for frequently used executables.', ""These are typically the commands that are part of Bash's programming language features."", 'Some things are implemented in multiple ways, such as [:', ""...and cd as you've discovered."", 'On my Fedora 19 system /bin/cd is actually a shell script:', ""But it doesn't do what you think. See these other U&L Q&A's for more details:"", 'Bottom line:', ""POSIX's requires that it's there and in this implementation, it acts as a test, confirming that you're able to change directories to X, but then returning a return code confirming or denying that this is possible.""]","[<code>cd</code>, <code>$ type -a cd
cd is a shell builtin
cd is /usr/bin/cd
cd is /bin/cd
</code>, <code>builtin</code>, <code>$ builtin cd
</code>, <code>builtin</code>, <code>$ help builtin
</code>, <code>hash</code>, <code>$PATH</code>, <code>$ type while
while is a shell keyword
$ type for
for is a shell keyword
$ type !
! is a shell keyword
</code>, <code>[</code>, <code>$ type -a [
[ is a shell builtin
[ is /usr/bin/[
[ is /bin/[    
</code>, <code>cd</code>, <code>/bin/cd</code>, <code>$ more /bin/cd
#!/bin/sh
builtin cd ""$@""
</code>]"
373,https://unix.stackexchange.com/questions/65891/,How to execute a shellscript when I plug-in a USB-device,"['If you want to run the script on a specific device, you can use the vendor and product ids ', 'In  /etc/udev/rules.d/test.rules:', 'in test.sh:', 'With env, you can see what environment is set from udev and with file, you will discover the file type.', 'The concrete attributes for your device can be discovered with lsusb ', 'gives ', '...\n  Bus 001 Device 016: ID 152d:2329 JMicron Technology Corp. / JMicron USA Technology Corp. JM20329 SATA Bridge\n  ...']","[<code>/etc/udev/rules.d/test.rules</code>, <code>ATTRS{idVendor}==""152d"", ATTRS{idProduct}==""2329"", RUN+=""/tmp/test.sh""
</code>, <code>test.sh</code>, <code>#! /bin/sh

env &gt;&gt;/tmp/test.log
file ""/sys${DEVPATH}"" &gt;&gt;/tmp/test.log

if [ ""${ACTION}"" = add -a -d ""/sys${DEVPATH}"" ]; then
echo ""add ${DEVPATH}"" &gt;&gt;/tmp/test.log
fi
</code>, <code>env</code>, <code>file</code>, <code>lsusb</code>, <code>lsusb
</code>]"
374,https://unix.stackexchange.com/questions/184519/,"How to ""grep"" for line length in a given range?",['where'],"[<code>grep -x '.\{3,10\}'
</code>, <code>-x</code>, <code>.</code>, <code>{3,10}</code>]"
375,https://unix.stackexchange.com/questions/33389/,Bash: repeat last N commands,"['fc -N -1', 'Where the -N is the last N commands you want to repeat.', 'This will open an editor with the last N commands in it. You can edit the commands as desired and when you close the editor, they will all be run in sequence.']","[<code>fc -N -1</code>, <code>-N</code>]"
376,https://unix.stackexchange.com/questions/6430/,How to redirect stderr and stdout to different files and also display in terminal?,"['Use the tee command as follows:', '3>&1 1>&2 2>&3 is how you swap stderr and stdout, because tee can only accept stdout.', 'Take a look at Unix tee command for more advanced redirections using tee.']","[<code>tee</code>, <code>(cmd | tee stdout.log) 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3 | tee stderr.log
</code>, <code>3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3</code>, <code>tee</code>]"
377,https://unix.stackexchange.com/questions/8469/,How can I close a terminal without killing its children (without running `screen` first)?,"['If some-boring-process is running in your current bash session:', ""That doesn't do anything to redirect the output -- you have to think of that when you launch your boring process. [Edit] There seems to be a way to redirect it https://gist.github.com/782263"", 'But seriously, look into screen. I have shells on a remote server that have been running for months.', 'Looks like this:']","[<code>some-boring-process</code>, <code>ctrl-z</code>, <code>bg</code>, <code>jobs</code>, <code>disown -h %1</code>, <code>$ sleep 999999
^Z
[1]+  Stopped                 sleep 999999
$ bg
[1]+ sleep 999999 &amp;
$ disown -h %1
</code>]"
378,https://unix.stackexchange.com/questions/24146/,"Avoiding ""BASH-isms"" in shell scripts","[""There's checkbashisms. On Debian, it's shipped as part of the package maintainer tools."", ""Test your scripts under dash and posh. Both have a few non-POSIX constructs, but if your script works in both, it's likely to work in most places. (With the caveat that it's difficult to test typical shell scripts as they tend to have a lot of corner cases.)"", ""If you intend for your scripts to be portable to embedded Linux platforms, test them with BusyBox. Note that BusyBox can be more or less restricted, depending on how small an embedded system you want; it's quite normal to have scripts that rely on a feature that some BusyBox installations don't have."", ""Note that non-portability doesn't come from the shell alone, it also comes from external utilities. OpenBSD and Solaris tend to have utilities with POSIX features and not much more, so they're good for testing for portability."", ""You'll want to refer to the POSIX specification, and other resources mentioned in this thread (especially the autoconf manual); but that's documentation, it doesn't help if you use a feature accidentally.""]",[]
379,https://unix.stackexchange.com/questions/484423/,Should we use UTF-8 characters like ⏰ in bash/shell script?,"['A useful guideline for this is the ""Portable Operating System Interface"" (POSIX), a family of standards that is implemented by most Unix-like systems. It is usually a good idea to limit shell scripts to features mandated by POSIX to make sure they will be usable across different shells and platforms.', 'According to the POSIX specification of function definitions in the ""Shell Command Language"":', 'The function is named fname; the application shall ensure that it is a name (see the Base Definitions volume of IEEE Std 1003.1-2001, Section 3.230, Name). An implementation may allow other characters in a function name as an extension.', 'Following the link to the definition of a ""name"":', 'In the shell command language, a word consisting solely of underscores, digits, and alphabetics from the portable character set.', 'That character set contains only characters between U0000 and U007E.\nTherefore characters like ""⏰"" (U23F0) are not valid in a POSIX-compliant identifier.', ""Your shell might accept them, but that doesn't guarantee that others will as well.\nTo be able to use your script across different platforms and software versions, you should avoid using non-compliant identifiers like this.""]",[]
380,https://unix.stackexchange.com/questions/39623/,"Trap, ERR, and echoing the error line","['As pointed out in comments, your quoting is wrong. You need single quotes to prevent $LINENO from being expanded when the trap line is first parsed.', 'This works:', 'Running it:']","[<code>$LINENO</code>, <code>#! /bin/bash

err_report() {
    echo ""Error on line $1""
}

trap 'err_report $LINENO' ERR

echo hello | grep foo  # This is line number 9
</code>, <code> $ ./test.sh
 Error on line 9
</code>]"
381,https://unix.stackexchange.com/questions/501828/,Why is opening a file faster than reading variable content?,"[""Here, it's not about opening a file versus reading a variable's content but more about forking an extra process or not."", ""grep -oP '^MemFree: *\\K[0-9]+' /proc/meminfo forks a process that executes grep that opens /proc/meminfo (a virtual file, in memory, no disk I/O involved) reads it and matches the regexp."", 'The most expensive part in that is forking the process and loading the grep utility and its library dependencies, doing the dynamic linking, open the locale database, dozens of files that are on disk (but likely cached in memory).', 'The part about reading /proc/meminfo is insignificant in comparison, the kernel needs little time to generate the information in there and grep needs little time to read it.', ""If you run strace -c on that, you'll see the one open() and one read() systems calls used to read /proc/meminfo is peanuts compared to everything else grep does to start (strace -c doesn't count the forking)."", 'In:', ""In most shells that support that $(<...) ksh operator, the shell just opens the file and read its content (and strips the trailing newline characters). bash is different and much less efficient in that it forks a process to do that reading and passes the data to the parent via a pipe. But here, it's done once so it doesn't matter."", 'In:', 'The shell needs to spawn two processes, which are running concurrently but interact between each other via a pipe. That pipe creation, tearing down, and writing and reading from it has some little cost. The much greater cost is the spawning of an extra process. The scheduling of the processes has some impact as well.', 'You may find that using the zsh <<< operator makes it slightly quicker:', ""In zsh and bash, that's done by writing the  content of $a in a temporary file, that is less expensive than spawning an extra process, but will probably not give you any gain compared to getting the data straight off /proc/meminfo. That's still less efficient than your approach that copies /proc/meminfo on disk, as the writing of the temp file is done at each iteration."", ""dash doesn't support here-strings, but its heredocs are implemented with a pipe that doesn't involve spawning an extra process. In:"", 'The shell creates a pipe, forks a process. The child executes grep with its stdin as the reading end of the pipe, and the parent writes the content at the other end of the pipe.', 'But that pipe handling and process synchronisation is still likely to be more expensive than just getting the data straight off /proc/meminfo.', 'The content of /proc/meminfo is short and takes not much time to produce. If you want to save some CPU cycles, you want to remove the expensive parts: forking processes and running external commands.', 'Like:', 'Avoid bash though whose pattern matching is very ineficient. With zsh -o extendedglob, you can shorten it to:', ""Note that ^ is special in many shells (Bourne, fish, rc, es and zsh with the extendedglob option at least), I'd recommend quoting it. Also note that echo can't be used to output arbitrary data (hence my use of printf above).""]","[<code>grep -oP '^MemFree: *\K[0-9]+' /proc/meminfo</code>, <code>grep</code>, <code>/proc/meminfo</code>, <code>/proc/meminfo</code>, <code>grep</code>, <code>strace -c</code>, <code>open()</code>, <code>read()</code>, <code>/proc/meminfo</code>, <code>grep</code>, <code>strace -c</code>, <code>a=$(&lt;/proc/meminfo)
</code>, <code>$(&lt;...)</code>, <code>bash</code>, <code>printf '%s\n' ""$a"" | grep '^MemFree'
</code>, <code>&lt;&lt;&lt;</code>, <code>grep '^MemFree' &lt;&lt;&lt; ""$a""
</code>, <code>$a</code>, <code>/proc/meminfo</code>, <code>/proc/meminfo</code>, <code>dash</code>, <code> grep '^MemFree' &lt;&lt; EOF
 $a
 EOF
</code>, <code>grep</code>, <code>/proc/meminfo</code>, <code>/proc/meminfo</code>, <code>IFS= read -rd '' meminfo &lt; /proc/meminfo
memfree=${meminfo#*MemFree:}
memfree=${memfree%%$'\n'*}
memfree=${memfree#""${memfree%%[! ]*}""}
</code>, <code>bash</code>, <code>zsh -o extendedglob</code>, <code>memfree=${${""$(&lt;/proc/meminfo)""##*MemFree: #}%%$'\n'*}
</code>, <code>^</code>, <code>echo</code>, <code>printf</code>]"
382,https://unix.stackexchange.com/questions/223503/,How to use grep when file does not contain the string,"['grep will return success if it finds at least one instance of the pattern and failure if it does not.  So you could either add an else clause if you want both ""does"" and ""does not"" prints, or you could just negate the if condition to only get failures.  An example of each:']","[<code>grep</code>, <code>else</code>, <code>if</code>, <code>if grep -q ""$user2"" /etc/passwd; then
    echo ""User does exist!!""
else
    echo ""User does not exist!!""
fi

if ! grep -q ""$user2"" /etc/passwd; then
    echo ""User does not exist!!""
fi
</code>]"
383,https://unix.stackexchange.com/questions/415990/,How can I expand a quoted variable to nothing if it's empty?,"['Posix compliant shells and Bash have ${parameter:+word}:', 'If parameter is unset or null, null shall be substituted; otherwise, the expansion of word (or an empty string if word is omitted) shall be substituted.', 'So you can just do:', 'and have var1 be checked, and ""$var1"" be used if it\'s set and non-empty (with the ordinary double-quoting rules). Otherwise it expands to nothing. Note that only the inner part is quoted here, not the whole thing.', ""The same also works in zsh. You have to repeat the variable, so it's not ideal, but it works out exactly as you wanted."", 'If you want a set-but-empty variable to expand to an empty argument, use ${var1+""$var1""} instead.']","[<code>${parameter:+word}</code>, <code>${var1:+""$var1""}
</code>, <code>var1</code>, <code>""$var1""</code>, <code>${var1+""$var1""}</code>]"
384,https://unix.stackexchange.com/questions/27013/,Displaying seconds as days/hours/mins/seconds?,"['You can use something like this:', 'Examples:']","[<code>function displaytime {
  local T=$1
  local D=$((T/60/60/24))
  local H=$((T/60/60%24))
  local M=$((T/60%60))
  local S=$((T%60))
  (( $D &gt; 0 )) &amp;&amp; printf '%d days ' $D
  (( $H &gt; 0 )) &amp;&amp; printf '%d hours ' $H
  (( $M &gt; 0 )) &amp;&amp; printf '%d minutes ' $M
  (( $D &gt; 0 || $H &gt; 0 || $M &gt; 0 )) &amp;&amp; printf 'and '
  printf '%d seconds\n' $S
}
</code>, <code>$ displaytime 11617
3 hours 13 minutes and 37 seconds
$ displaytime 42
42 seconds
$ displaytime 666
11 minutes and 6 seconds
</code>]"
385,https://unix.stackexchange.com/questions/170063/,Start a process on a different tty,"['As long as nothing else is using the other TTY (/dev/tty2 in this example), this should work. This includes a getty process that may be waiting for someone to login; having more than one process reading its input from a TTY will lead to unexpected results.', 'setsid takes care of starting the command in a new session.', 'Note that command will have to take care of setting the stty settings correctly, e.g. turn on ""cooked mode"" and onlcr so that outputting a newline will add a carriage return, etc.']","[<code>setsid sh -c 'exec command &lt;&gt; /dev/tty2 &gt;&amp;0 2&gt;&amp;1'
</code>, <code>/dev/tty2</code>, <code>getty</code>, <code>setsid</code>, <code>command</code>, <code>stty</code>, <code>onlcr</code>]"
386,https://unix.stackexchange.com/questions/61907/,How do I create a directory in all subdirectories?,"['With globs :', 'If you want to create multiple subdirs at once :    ', 'for dir in */; do mkdir -- ""$dir""/{tmp1,foo,bar,qux}; done']","[<code>for dir in */; do mkdir -- ""$dir/tmp1""; done
</code>, <code>*/</code>, <code>for dir in */; do mkdir -- ""$dir""/{tmp1,foo,bar,qux}; done</code>]"
387,https://unix.stackexchange.com/questions/34011/,The best way to expand glob pattern?,"[""Just let it expand inside an array declaration's right side:"", '\nNote that the shell option nullglob needs to be set.\nIt is not set by default.\nIt prevents an error in case the glob (or one of multiple globs) does not match any name.  ', 'Set it in bash with ', 'or in zsh with ']","[<code>list=(../smth*/)          # grab the list
echo ""${#list[@]}""        # print array length
echo ""${list[@]}""         # print array elements
for file in ""${list[@]}""; do echo ""$file""; done  # loop over the array
</code>, <code>nullglob</code>, <code>bash</code>, <code>shopt -s nullglob
</code>, <code>zsh</code>, <code>setopt nullglob
</code>]"
388,https://unix.stackexchange.com/questions/48505/,How to make sure only one instance of a bash script runs?,"[""Almost like nsg's answer: use a lock directory. Directory creation is atomic under linux and unix and *BSD and a lot of other OSes."", ""You can put the PID of the locking sh into a file in the lock directory for debugging purposes, but don't fall into the trap of thinking you can check that PID to see if the locking process still executes. Lots of race conditions lie down that path.""]","[<code>if mkdir $LOCKDIR
then
    # Do important, exclusive stuff
    if rmdir $LOCKDIR
    then
        echo ""Victory is mine""
    else
        echo ""Could not remove lock dir"" &gt;&amp;2
    fi
else
    # Handle error condition
    ...
fi
</code>]"
389,https://unix.stackexchange.com/questions/67006/,How can one run multiple programs in the background with single command?,"[""From a shell syntax point of view, & separates commands like ;/|/&&... (though of course with different semantic). So it's just:""]","[<code>&amp;</code>, <code>;</code>, <code>|</code>, <code>&amp;&amp;</code>, <code>cmd1 &amp; cmd2 &amp; cmd3 &amp;
</code>]"
390,https://unix.stackexchange.com/questions/275329/,Using grep in conditional statement in bash,"[""You're almost there. Just omit the exclamation mark:"", 'Result:', 'The if condition is fulfilled if grep returns with exit code 0 (which means a match). The ! exclamation mark will negate this.']","[<code>OUTPUT='blah blah (Status: 200)'
if echo ""$OUTPUT"" | grep -q ""(Status:\s200)""; then
    echo ""MATCH""
fi
</code>, <code>MATCH
</code>, <code>if</code>, <code>!</code>]"
391,https://unix.stackexchange.com/questions/69322/,How to get milliseconds since Unix epoch?,"['date +%s.%N will give you, eg., 1364391019.877418748.  The %N is the\nnumber of nanoseconds elapsed in the current second. Notice it is 9 digits,\nand by default date will pad this with zeros if it is less than 100000000.  This is actually a problem if we want to do math with the number, because bash treats numbers with a leading zero as octal.  This padding can be disabled by using a hyphen in the field spec, so:', 'would naively give you milliseconds since the epoch.', ""However, as Stephane Chazelas points out in comment below, that's two different date calls which will yield two slightly different times.  If\nthe second has rolled over in between them, the calculation will be an\nentire second off.  So:"", 'Or optimized (thanks to comments below, though this should have been obvious):']","[<code>date +%s.%N</code>, <code>1364391019.877418748</code>, <code>echo $((`date +%s`*1000+`date +%-N`/1000000))
</code>, <code>date</code>, <code>echo $(($(date +'%s * 1000 + %-N / 1000000')))
</code>, <code>echo $(( $(date '+%s%N') / 1000000));
</code>]"
392,https://unix.stackexchange.com/questions/25049/,How do I close a terminal without saving the history?,"[""Your shell's history is saved in the file indicated by the HISTFILE variable. So:"", ""This also applies to zsh, but not to ksh which keeps saving to the file indicated by $HISTFILE when the shell starts (and conversely, you decide to save your history in ksh once you've started the shell).""]","[<code>HISTFILE</code>, <code>unset HISTFILE
</code>, <code>$HISTFILE</code>]"
393,https://unix.stackexchange.com/questions/12601/,How to get the output inside `screen` out to a script?,"['You could start screen with the -L option.  This will cause screen to create a file screenlog.n (the n part is numerical, starting with a zero) in the current working directory.', 'In your case this would look something like: screen -S session_name -L -X eval \'stuff ""$cmd""\\015\'', 'As long as you remember to clean up afterwards, this should match what you are after.', 'For last line of the log, it can easily be obtained with tail -1 screenlog.0, or the entire log can be parsed however you wish.']","[<code>screen</code>, <code>-L</code>, <code>screenlog.n</code>, <code>screen -S session_name -L -X eval 'stuff ""$cmd""\015'</code>, <code>tail -1 screenlog.0</code>]"
394,https://unix.stackexchange.com/questions/41740/,find -exec + vs find | xargs: which one to choose?,"[""You might want to chain calls to find (once, when you learned, that it is possible, which might be today). This is, of course, only possible as long as you stay in find. Once you pipe to xargs it's out of scope. "", 'Small example, two files a.lst and b.lst: ', 'No trick here - simply the fact that both contain ""fuddel"" but only one contains ""fiddel"".', ""Assume we didn't know that. We search a file which matches 2 conditions: "", ""Well, maybe you know the syntax for grep or another program to pass both strings as condition, but that's not the point. Every program which can return true or false, given a file as argument, can be used here - grep was just a popular example. "", 'And note, you may follow find -exec with other find commands, like -ls or -delete or something similar. Note, that delete not only does rm (removes files), but rmdir (removes directories) too. ', 'Such a chain is read as an AND combination of commands, as long as not otherwise specified (namely with an -or switch (and parens (which need masking))). ', ""So you aren't leaving the find chain, which is a handy thing. I don't see any advantage in using -xargs, since you have to be careful in passing the files, which is something find doesn't need to do - it automatically handles passing each file as a single argument for you. "", ""If you believe you need some masking for finds {} braces, feel free to visit my question which asks for evidence. My assertion is: You don't. ""]","[<code>cat a.lst
fuddel.sh
fiddel.sh

cat b.lst
fuddel.sh
</code>, <code>find -exec grep -q fuddel {} "";"" -exec grep -q fiddel {} "";"" -ls
192097    4 -rw-r--r--   1 stefan   stefan         20 Jun 27 17:05 ./a.lst
</code>, <code>-or</code>]"
395,https://unix.stackexchange.com/questions/305744/,How does !! work in bash?,"['!! is listed in the bash manual under the heading ""Event Designators"":', 'So !! will be replaced with the previous command.', 'Note that the shell history will not contain the literal !! but instead the actual command that was executed:']","[<code>!!</code>, <code>bash</code>, <code>   An event designator is a reference to a command line  entry  in  the
   history list.  Unless the reference is absolute, events are relative
   to the current position in the history list.

   !      Start a history  substitution,  except  when  followed  by  a
          blank,  newline,  carriage  return,  = or ( (when the extglob
          shell option is enabled using the shopt builtin).
   !n     Refer to command line n.
   !-n    Refer to the current command minus n.
   !!     Refer to the previous command.  This is a synonym for  `!-1'.
   !string
          Refer  to the most recent command preceding the current posi-
          tion in the history list starting with string.
   !?string[?]
          Refer to the most recent command preceding the current  posi-
          tion  in  the history list containing string.  The trailing ?
          may be omitted if string is followed immediately  by  a  new-
          line.
   ^string1^string2^
          Quick  substitution.   Repeat the previous command, replacing
          string1       with       string2.        Equivalent        to
          ``!!:s/string1/string2/'' (see Modifiers below).
   !#     The entire command line typed so far.
</code>, <code>!!</code>, <code>!!</code>, <code>$ ls
[some output]

$ !! .
[same output]

$ history 3
  645  2016-08-25 17:40:55 ls
  646  2016-08-25 17:40:57 ls .
  647  2016-08-25 17:41:00 history 3
</code>]"
396,https://unix.stackexchange.com/questions/217622/,Add path to $PATH if not already in $PATH,"['First check if the path to add is already part of the variable:', 'If /path/to/add is already in the $PATH, then nothing happens, else it is added at the beginning.', 'If you need it at the end use PATH=${PATH}:/path/to/add instead.', 'Edit: In you case it would look like this:']","[<code>[[ "":$PATH:"" != *"":/path/to/add:""* ]] &amp;&amp; PATH=""/path/to/add:${PATH}""
</code>, <code>/path/to/add</code>, <code>$PATH</code>, <code>PATH=${PATH}:/path/to/add</code>, <code>[[ "":$PATH:"" != *"":${OPENSHIFT_HOMEDIR}/app-root/runtime/bin:""* ]] &amp;&amp; PATH=""${OPENSHIFT_HOMEDIR}/app-root/runtime/bin:${PATH}""
</code>]"
397,https://unix.stackexchange.com/questions/311758/,Remove specific word in variable,"['Try:', 'This also work in ksh93, mksh, zsh.', 'POSIXLY:', 'It assumes your words are space delimited and has side effect that remove spaces before and after ""$WORDTOREMOVE"".']","[<code>$ printf '%s\n' ""${FOO//$WORDTOREMOVE/}""
CATS DOGS FISH
</code>, <code>ksh93</code>, <code>mksh</code>, <code>zsh</code>, <code>FOO=""CATS DOGS FISH MICE""
WORDTOREMOVE=""MICE""

remove_word() (
  set -f
  IFS=' '

  s=$1
  w=$2

  set -- $1
  for arg do
    shift
    [ ""$arg"" = ""$w"" ] &amp;&amp; continue
    set -- ""$@"" ""$arg""
  done

  printf '%s\n' ""$*""
)

remove_word ""$FOO"" ""$WORDTOREMOVE""
</code>, <code>""$WORDTOREMOVE""</code>]"
398,https://unix.stackexchange.com/questions/35782/,Quick way to include a directory path when calling mv?,"['Use brace expansion:', 'would expand to']","[<code>mv very/long/path/to/filename.{old,new}
</code>, <code>mv very/long/path/to/filename.old very/long/path/to/filename.new
</code>]"
399,https://unix.stackexchange.com/questions/332531/,Why does remote Bash source .bash_profile instead of .bashrc,"['A login shell first reads /etc/profile and then ~/.bash_profile.', 'A non-login shell reads from /etc/bash.bashrc and then ~/.bashrc.', 'Why is that important?', 'Because of this line in man ssh:', 'If command is specified, it is executed on the remote host instead of a login shell.', 'In other words, if the ssh command only has options (not a command), like:', 'It will start a login shell, a login shell reads ~/.bash_profile.', 'An ssh command which does have a command, like:', 'Where the command is : (or do nothing).\nIt will not start a login shell, therefore ~/.bashrc is what will be read.', 'The supplied tty connection for /dev/stdin in the remote computer may be an actual tty or something else.', 'For:', 'Which ends in a TTY (not a network connection) as the started bash sees it.', 'For a ssh connection with a command:', ""The list of TTY's start the same, but note that /etc/profile was not sourced."", 'Which tells the shell that the connection is a pipe (not a network connection).', 'So, in both the test cases, the shell is unable to know that the connection is from a network and therefore does not read ~/.bashrc (if we only talk about the connection to a network). It does read ~/.bashrc, but for a different reason.']","[<code>/etc/profile</code>, <code>~/.bash_profile</code>, <code>/etc/bash.bashrc</code>, <code>~/.bashrc</code>, <code>man ssh</code>, <code>ssh user@host
</code>, <code>~/.bash_profile</code>, <code>ssh user@host :
</code>, <code>:</code>, <code>~/.bashrc</code>, <code>$ ssh isaac@localhost
/etc/profile sourced

$ ls -la /dev/stdin
lrwxrwxrwx 1 root root 15 Dec 24 03:35 /dev/stdin -&gt; /proc/self/fd/0

$ ls -la /proc/self/fd/0
lrwx------ 1 isaac isaac 64 Dec 24 19:34 /proc/self/fd/0 -&gt; /dev/pts/3

$ ls -la /dev/pts/3
crw--w---- 1 isaac tty 136, 3 Dec 24 19:35 /dev/pts/3
</code>, <code>$ ssh isaac@localhost 'ls -la /dev/stdin'
isaac@localhost's password: 
lrwxrwxrwx 1 root root 15 Dec 24 03:35 /dev/stdin -&gt; /proc/self/fd/0
</code>, <code>$ ssh isaac@localhost 'ls -la /proc/self/fd/0'
isaac@localhost's password:
lr-x------ 1 isaac isaac 64 Dec 24 19:39 /proc/self/fd/0 -&gt; pipe:[6579259]
</code>, <code>~/.bashrc</code>]"
400,https://unix.stackexchange.com/questions/289499/,"Difference between ""command not found"" and ""no such file or directory""?","[""That's because bash remembered your command location, store it in a hash table."", ""After you uninstalled node, the hash table isn't cleared, bash still thinks node is at /usr/local/bin/node, skipping the PATH lookup, and calling /usr/local/bin/node directly, using execve(). Since when node isn't there anymore, execve() returns ENOENT error, means no such file or directory, bash reported that error to you."", 'In bash, you can remove an entry from hash table:', 'or remove the entire hash table (works in all POSIX shell):']","[<code>bash</code>, <code>node</code>, <code>bash</code>, <code>node</code>, <code>/usr/local/bin/node</code>, <code>PATH</code>, <code>/usr/local/bin/node</code>, <code>execve()</code>, <code>node</code>, <code>execve()</code>, <code>ENOENT</code>, <code>bash</code>, <code>bash</code>, <code>hash -d node
</code>, <code>hash -r
</code>]"
401,https://unix.stackexchange.com/questions/22645/,"What does a ""< <(...)"" redirection mean?","['No, < < and << are not the same thing.', 'The first is composed of the common < redirection character combined with the first character of the <(command) syntax. This is a ksh construct (also found in bash and zsh) known as process substitution that takes the output of command and provides it in a file whose name refers to the other end of the pipe command is writing to.', 'In other word you can think of < <(command) as < file, where file contains the output of command.']","[<code>&lt; &lt;</code>, <code>&lt;&lt;</code>, <code>&lt;</code>, <code>&lt;(command)</code>, <code>ksh</code>, <code>bash</code>, <code>zsh</code>, <code>command</code>, <code>command</code>, <code>&lt; &lt;(command)</code>, <code>&lt; file</code>, <code>command</code>]"
402,https://unix.stackexchange.com/questions/228331/,Avoid running the script if a variable is not defined,"['The quickest way is probably to add these two lines to the start of the script:', 'The first line sets the nounset option in the shell running the script, which aborts if you try to expand an unset variable; the second expands $BATCHNUM in the context of a no-op, to trigger the abort before doing anything else.', 'If you want a more helpful error message, you could instead write:', 'Or similar.']","[<code>set -u # or set -o nounset
: ""$BATCHNUM""
</code>, <code>nounset</code>, <code>$BATCHNUM</code>, <code>if [[ -z ""$BATCHNUM"" ]]; then
    echo ""Must provide BATCHNUM in environment"" 1&gt;&amp;2
    exit 1
fi
</code>]"
403,https://unix.stackexchange.com/questions/56810/,adding text to filename before extension,['Using standard POSIX parameter expansion:'],"[<code>for f in *.shp; do printf '%s\n' ""${f%.shp}_poly.shp""; done
</code>]"
404,https://unix.stackexchange.com/questions/75354/,Can bash case statements cascade?,"['You need to use ;& instead of ;; to get a fall-through behavior:', 'See the Conditional Constructs section of the bash documentation.', 'The other special marker is ;;&, which:', 'causes the shell to test the patterns in the next clause, if any, and execute any associated command-list on a successful match.', ';; is always final, no further patterns are tested.']","[<code>;&amp;</code>, <code>;;</code>, <code>#! /bin/bash
foo() {
    case ""$1"" in
        3)
            echo ""Level Three""
            ;&amp;
        2)
            echo ""Level Two""
            ;&amp;
        1)
            echo ""Level One""
            ;;
        a)
            echo ""Level a""
            ;&amp;
        b)
            echo ""Level b""
            ;&amp;
        c)
            echo ""Level c""
            ;;
    esac
}
echo 3:
foo 3
echo 2:
foo 2
echo a:
foo a
</code>, <code>3:
Level Three
Level Two
Level one
2:
Level Two
Level one
a:
Level a
Level b
Level c
</code>, <code>;;&amp;</code>, <code>;;</code>, <code>#! /bin/bash

foo() {
    case ""$1"" in
        *3*)
            echo ""Level Three""
            ;;&amp;
        *2*)
            echo ""Level Two""
            ;;&amp;
        *1*)
            echo ""Level One""
            ;;&amp;
    esac
}

echo 12:
foo 12
echo 13:
foo 13
echo 23:
foo 23
</code>, <code>12:
Level Two
Level One
13:
Level Three
Level One
23:
Level Three
Level Two
</code>]"
405,https://unix.stackexchange.com/questions/145651/,Using exec and tee to redirect logs to stdout and a log file in the same time,"['Use process substitution with & redirection and exec:', '$log_file will contain the output of the script and any subprocesses, and the output will also be printed to the screen.', '>(...) starts the process ... and returns a file representing its standard input. ', 'exec &> ... redirects both standard output and standard error into ... for the remainder of the script (use just exec > ... for stdout only). ', 'tee -a appends its standard input to the file, and also prints it to the screen.']","[<code>&amp;</code>, <code>exec</code>, <code>exec &amp;&gt; &gt;(tee -a ""$log_file"")
echo ""This will be logged to the file and to the screen""
</code>, <code>$log_file</code>, <code>&gt;(...)</code>, <code>...</code>, <code>exec &amp;&gt; ...</code>, <code>...</code>, <code>exec &gt; ...</code>, <code>tee -a</code>]"
406,https://unix.stackexchange.com/questions/12356/,How does TAB auto-complete find options to complete?,['Depending on the command:'],"[<code>/etc/bash_completion.d/*</code>, <code>complete</code>, <code>complete -F _find find</code>, <code>_find</code>, <code>find</code>, <code>compgen</code>, <code>--help</code>, <code>complete</code>, <code>complete -F _longopt ls</code>, <code>_longopt</code>, <code>/etc/bash_completion.d/*</code>, <code>complete</code>, <code>-A</code>]"
407,https://unix.stackexchange.com/questions/88487/,What happens if you edit a script during execution?,"['In Unix, most editors work by creating a new temporary file containing the edited contents. When the edited file is saved, the original file is deleted and the temporary file renamed to the original name. (There are, of course, various safeguards to prevent dataloss.) This is, for example, the style used by sed or perl when invoked with the -i (""in-place"") flag, which is not really ""in-place"" at all. It should have been called ""new place with old name"".', 'This works well because unix assures (at least for local filesystems) that an opened file continues to exist until it is closed, even if it is ""deleted"" and a new file with the same name is created. (It\'s not coincidental that the unix system call to ""delete"" a file is actually called ""unlink"".) So, generally speaking, if a shell interpreter has some source file open, and you ""edit"" the file in the manner described above, the shell won\'t even see the changes since it still has the original file open.', '[Note: as with all standards-based comments, the above is subject to multiple interpretations and there are various corner-cases, such as NFS. Pedants are welcome to fill the comments with exceptions.]', ""It is, of course, possible to modify files directly; it's just not very convenient for editing purposes, because while you can overwrite data in a file, you cannot delete or insert without shifting all following data, which would imply quite a lot of rewriting. Furthermore, while you were doing that shifting, the contents of the file would be unpredictable and processes which had the file open would suffer. In order to get away with this (as with database systems, for example), you need a sophisticated set of modification protocols and distributed locks; stuff which is well beyond the scope of a typical file editing utility."", 'So, if you want to edit a file while its being processed by a shell, you have two options:', 'You can append to the file. This should always work.', ""You can overwrite the file with new contents of exactly the same length. This may or may not work, depending on whether the shell has already read that part of the file or not. Since most file I/O involves read buffers, and since all the shells I know read an entire compound command before executing it, it is pretty unlikely that you can get away with this. It certainly wouldn't be reliable."", ""I don't know of any wording in the Posix standard which actually requires the possibility of appending to a script file while the file is being executed, so it might not work with every Posix compliant shell, much less with the current offering of almost- and sometimes-posix-compliant shells. So YMMV. But as far as I know, it does work reliably with bash."", 'As evidence, here\'s a ""loop-free"" implementation of the infamous 99 bottles of beer program in bash, which uses dd to overwrite and append (the overwriting is presumably safe because it substitutes the currently executing line, which is always the last line of the file, with a comment of exactly the same length; I did that so that the end result can be executed without the self-modifying behaviour.) ']","[<code>sed</code>, <code>perl</code>, <code>-i</code>, <code>dd</code>, <code>#!/bin/bash
if [[ $1 == reset ]]; then
  printf ""%s\n%-16s#\n"" '####' 'next ${1:-99}' |
  dd if=/dev/stdin of=$0 seek=$(grep -bom1 ^#### $0 | cut -f1 -d:) bs=1 2&gt;/dev/null
  exit
fi

step() {
  s=s
  one=one
  case $beer in
    2) beer=1; unset s;;
    1) beer=""No more""; one=it;;
    ""No more"") beer=99; return 1;;
    *) ((--beer));;
  esac
}
next() {
  step ${beer:=$(($1+1))}
  refrain |
  dd if=/dev/stdin of=$0 seek=$(grep -bom1 ^next\  $0 | cut -f1 -d:) bs=1 conv=notrunc 2&gt;/dev/null
}
refrain() {
  printf ""%-17s\n"" ""# $beer bottles""
  echo echo ${beer:-No more} bottle$s of beer on the wall, ${beer:-No more} bottle$s of beer.
  if step; then
    echo echo Take $one down, pass it around, $beer bottle$s of beer on the wall.
    echo echo
    echo next abcdefghijkl
  else
    echo echo Go to the store, buy some more, $beer bottle$s of beer on the wall.
  fi
}
####
next ${1:-99}   #
</code>]"
408,https://unix.stackexchange.com/questions/335801/,Bash remembers wrong path to an executable that was moved/deleted,"[""When you run a command in bash it will remember the location of that executable so it doesn't have to search the PATH again each time.  So if you run the executable, then change the location, bash will still try to use the old location.  You should be able to confirm this with hash -t pip3 which will show the old location."", 'If you run hash -d pip3 it will tell bash to forget the old location and should find the new one next time you try.']","[<code>bash</code>, <code>PATH</code>, <code>bash</code>, <code>hash -t pip3</code>, <code>hash -d pip3</code>]"
409,https://unix.stackexchange.com/questions/31695/,How to make the terminal display user@machine in bold letters?,"['You should be able to do this by setting the PS1 prompt variable in your ~/.bashrc file like this:', 'To make it colored (and possibly bold - this depends on whether your terminal emulator has enabled it) you need to add escape color codes:', 'Here, everything not being escaped between the 1;91m and 0m parts will be colored in the 1;91 color (bold red). Put these escape codes around different parts of the prompt to use different colors, but remember to reset the colors with 0m or else you will have colored terminal output as well. Remember to source the file afterwards to update the current shell: source ~/.bashrc']","[<code>PS1</code>, <code>~/.bashrc</code>, <code>PS1='[\u@\h \w]\$ '
</code>, <code>PS1='\[\e[1;91m\][\u@\h \w]\$\[\e[0m\] '
</code>, <code>1;91m</code>, <code>0m</code>, <code>1;91</code>, <code>0m</code>, <code>source ~/.bashrc</code>]"
410,https://unix.stackexchange.com/questions/13724/,File descriptors & shell scripting,"['First, note that the syntax for closing is 5>&- or 6<&-, depending on whether the file descriptor is being read for writing or for reading. There seems to be a typo or formatting glitch in that blog post.', ""Here's the commented script."", ""There's no closing here. Because all the inputs and outputs are going to the same place in this simple example, the use of extra file descriptors is not necessary. You could write"", 'Using explicit file descriptors becomes useful when you want to write to multiple files in turn. For example, consider a script that outputs data to a data output file and logging data to a log file and possibly error messages as well. That means three output channels: one for data, one for logs and one for errors. Since there are only two standard descriptors for output, a third is needed. You can call exec to open the output files:', 'The remark about efficiency comes in when you have a redirection in a loop, like this (assume the file is empty to begin with):', 'At each iteration, the program opens /tmp/bar, seeks to the end of the file, appends some data and closes the file. It is more efficient to open the file once and for all:', 'When there are multiple redirections happening at different times, calling exec to perform redirections rather than wrapping a block in a redirection becomes useful.', ""You'll find several other examples of redirection by browsing the io-redirection tag on this site.""]","[<code>5&gt;&amp;-</code>, <code>6&lt;&amp;-</code>, <code>exec 5&gt;/tmp/foo       # open /tmp/foo for writing, on fd 5
exec 6&lt;/tmp/bar       # open /tmp/bar for reading, on fd 6
cat &lt;&amp;6 |             # call cat, with its standard input connected to
                      # what is currently fd 6, i.e., /tmp/bar
while read a; do      # 
  echo $a &gt;&amp;5         # write to fd 5, i.e., /tmp/foo
done                  # 
</code>, <code>cat &lt;/tmp/bar |
while read a; do
  echo $a
done &gt;/tmp/foo
</code>, <code>exec</code>, <code>exec &gt;data-file
exec 3&gt;log-file
echo ""first line of data""
echo ""this is a log line"" &gt;&amp;3
…
if something_bad_happens; then echo error message &gt;&amp;2; fi
exec &gt;&amp;-  # close the data output file
echo ""output file closed"" &gt;&amp;3
</code>, <code>while …; do echo $a &gt;&gt;/tmp/bar; done
</code>, <code>/tmp/bar</code>, <code>while …; do echo $a; done &gt;/tmp/bar
</code>, <code>exec</code>, <code>exec &gt;/tmp/bar
while …; do echo $a; done
</code>, <code>io-redirection</code>]"
411,https://unix.stackexchange.com/questions/270272/,How to get the tty in which bash is running?,"['Simply by typing tty:', 'Too simple and obvious to be true :)', 'Edit: The first one returns you also the pty of the process running grep as you can notice:', 'therefore you would need to filter out the grep to get only one result, which is getting ugly:', 'or using ', '(a more sane variant)']","[<code>tty</code>, <code>$ tty 
/dev/pts/20
</code>, <code>pty</code>, <code>grep</code>, <code>$ ps ax | grep $$
28295 pts/20   Ss     0:00 /bin/bash
29786 pts/20   S+     0:00 grep --color=auto 28295
</code>, <code>ps ax | grep $$ | grep -v grep | awk '{ print $2 }'
</code>, <code>ps ax | grep ""^$$"" | awk '{ print $2 }'
</code>]"
412,https://unix.stackexchange.com/questions/332691/,"How to insert variables inside a string containing """"?","['You can embed variables only in double-quoted strings.', 'An easy and safe way to make this work is to break out of the single-quoted string like this:', 'Notice that after breaking out of the single-quoted string, I enclosed the variables within double-quotes.\nThis is to make it safe to have special characters inside the variables.', ""Since you asked for another way, here's an inferior alternative using printf:"", 'This is inferior because it uses a sub-shell to achieve the same effect, which is an unnecessary extra process.', 'As @steeldriver wrote in a comment, in modern versions of bash, you can write like this to avoid the sub-shell:', 'Since printf is a shell builtin, this alternative is probably on part with my first suggestion at the top.']","[<code>xml='&lt;?xml version=""1.0"" encoding=""iso-8859-1""?&gt;&lt;tag1&gt;'""$str1""'&lt;/tag1&gt;&lt;tag2&gt;'""$str2""'&lt;/tag2&gt;'
</code>, <code>printf</code>, <code>xml=$(printf '&lt;?xml version=""1.0"" encoding=""iso-8859-1""?&gt;&lt;tag1&gt;%s&lt;/tag1&gt;&lt;tag2&gt;%s&lt;/tag2&gt;' ""$str1"" ""$str2"")
</code>, <code>printf -v xml ' ... ' ""$str1"" ""$str2""
</code>, <code>printf</code>]"
413,https://unix.stackexchange.com/questions/164676/,Why can Shell builtins not be run with capital letters but other commands can?,"['From your other questions I take it you\'re using OS X. The default HFS+ filesystem on OS X is case-insensitive: you can\'t have two files called ""abc"" and ""ABC"" in the same directory, and trying to access either name will get to the same file. The same thing can happen under Cygwin, or with case-insensitive filesystems (like FAT32 or ciopfs) anywhere.', ""Because grep is a real executable, it's looked up on the filesystem (in the directories of PATH). When your shell looks in /usr/bin for either grep or GREP it will find the grep executable."", ""Shell builtins are not looked up on the filesystem: because they're built in, they are accessed through (case-sensitive) string comparisons inside the shell itself."", ""What you're encountering is an interesting case. While cd is a builtin, accessed case-sensitively, CD is found as an executable /usr/bin/cd. The cd executable is pretty useless: because cd affects the current shell execution environment, it is always provided as a shell regular built-in, but there is a cd executable for POSIX's sake anyway, which changes directory for itself and then immediately terminates, leaving the surrounding shell where it started."", 'You can try these out with the type builtin:', ""type tells you what the shell will do when you run that command. When you run cd you access the builtin, but CD finds the executable. For other builtins, the builtin and the executable will be reasonably compatible (try echo), but for cd that isn't possible.""]","[<code>grep</code>, <code>PATH</code>, <code>/usr/bin</code>, <code>grep</code>, <code>GREP</code>, <code>grep</code>, <code>cd</code>, <code>CD</code>, <code>/usr/bin/cd</code>, <code>cd</code>, <code>cd</code>, <code>cd</code>, <code>type</code>, <code>$ type cd
cd is a shell builtin
$ type CD
CD is /usr/bin/CD
</code>, <code>type</code>, <code>cd</code>, <code>CD</code>, <code>echo</code>, <code>cd</code>]"
414,https://unix.stackexchange.com/questions/114908/,Bash script to convert all *flac to *.mp3 with FFmpeg?,['Try this: '],"[<code>for i in *.flac ; do 
    ffmpeg -i ""$i"" -acodec libmp3lame ""$(basename ""${i/.flac}"")"".mp3
    sleep 60
done
</code>]"
415,https://unix.stackexchange.com/questions/299321/,Bash multiplication and addition,"['Using arithmetic expansion:', 'Using the antiquated expr utility:', 'Using bc -l (-l not actually needed in this case as no math functions are used):', 'Using bc -l as a co-process (it acts like a sort of computation service in the background¹):', 'That last one looks (arguably) cleaner in ksh93:', '¹ This solved a an issue for me once where I needed to process a large amount of input in a loop. The processing required some floating point computations, but spawning bc a few times in the loop proved to be exceedingly slow. Yes, I could have solved it in many other ways, but I was bored...']","[<code>for (( k = 0; k &lt; 50; ++k )); do
  a=$(( 2*k + 1 ))
  echo ""$a""
done
</code>, <code>expr</code>, <code>for (( k = 0; k &lt; 50; ++k )); do
  a=$( expr 2 '*' ""$k"" + 1 )
  echo ""$a""
done
</code>, <code>bc -l</code>, <code>-l</code>, <code>for (( k = 0; k &lt; 50; ++k )); do
  a=$( bc -l &lt;&lt;&lt;""2*$k + 1"" )
  echo ""$a""
done
</code>, <code>bc -l</code>, <code>coproc bc -l

for (( k = 0; k &lt; 50; ++k )); do
  printf ""2*%d + 1\n"" ""$k"" &gt;&amp;${COPROC[1]}
  read -u ""${COPROC[0]}"" a
  echo ""$a""
done

kill ""$COPROC_PID""
</code>, <code>ksh93</code>, <code>bc -l |&amp;
bc_pid=""$!""

for (( k = 0; k &lt; 50; ++k )); do
  print -p ""2*$k + 1""
  read -p a
  print ""$a""
done

kill ""$bc_pid""
</code>, <code>bc</code>]"
416,https://unix.stackexchange.com/questions/4770/,"Quoting in ssh $host $FOO and ssh $host ""sudo su user -c $FOO"" type constructs","['Dealing with multiple levels of quoting (really, multiple levels of parsing/interpretation) can get complicated. It helps to keep a few things in mind: ', 'Let us look at your example commands.', 'Your first example command (above) uses four languages: your shell, the regex in pgrep, the regex in grep (which might be different from the regex language in pgrep), and awk. There are two levels of interpretation involved: the shell and one level after the shell for each of the involved commands. There is only one explicit level of quoting (shell quoting into awk).', 'Next you added a level of ssh on top. This is effectively another shell level: ssh does not interpret the command itself, it hands it to a shell on the remote end (via (e.g.) sh -c …) and that shell interprets the string.', 'Then you asked about adding another shell level in the middle by using su (via sudo, which does not interpret its command arguments, so we can ignore it). At this point, you have three levels of nesting going on (awk → shell, shell → shell (ssh), shell → shell (su user -c), so I advise using the “bottom, up” approach. I will assume that your shells are Bourne compatible (e.g. sh, ash, dash, ksh, bash, zsh, etc.). Some other kind of shell (fish, rc, etc.) might require different syntax, but the method still applies.', 'The thing to keep in mind here is that each language (quoting level) may give slightly different semantics (or even drastically different semantics) to the same quoting character.', ""Most languages have a “literal” quoting mechanism, but they vary in exactly how literal they are. The single quote of Bourne-like shells is actually literal (which means you can not use it to quote a single quote character itself). Other languages (Perl, Ruby) are less literal in that they interpret some backslash sequences inside single quoted regions non-literally (specifically, \\\\ and \\' result in \\ and ', but other backslash sequences are actually literal)."", 'You will have to read the documentation for each of your languages to understand its quoting rules and the overall syntax.', 'The innermost level of your example is an awk program.', 'You are going to embed this in a shell command line:', 'We need to protect (at a minimum) the space and the $ in the awk program. The obvious choice is to use single quote in the shell around the whole program.', 'There are other choices though:', 'If the program used a comma between the open and close curly braces we would also need to quote or escape either the comma or the curly braces to avoid “brace expansion” in some shells.', ""We pick '{print $1}' and embed it in the rest of the shell “code”:"", 'Next, you wanted to run this via su and sudo.', 'su user -c … is just like some-shell -c … (except running under some other UID), so su just adds another shell level. sudo does not interpret its arguments, so it does not add any quoting levels.', 'We need another shell level for our command string. We can pick single quoting again, but we have to give special handling to the existing single quotes. The usual way looks like this:', 'There are four strings here that the shell will interpret and concatenate: the first single quoted string (pgrep … awk), an escaped single quote, the single-quoted awk program, another escaped single quote. ', 'There are, of course many alternatives:', 'Using different quoting in the first level allows for other variations at this level:', 'Embedding the first variation in the sudo/*su* command line give this:', 'You could use the same string in any other single shell level contexts (e.g. ssh host …).', 'Next, you added a level of ssh on top. This is effectively another shell level: ssh does not interpret the command itself, but it hands it to a shell on the remote end (via (e.g.) sh -c …) and that shell interprets the string.', 'The process is the same: take the string, pick a quoting method, use it, embed it.', 'Using single quotes again:', ""Now there are eleven strings that are interpreted and concatenated: 'sudo su user -c ', escaped single quote, 'pgrep … awk ', escaped single quote, escaped backslash, two escaped single quotes, the single quoted awk program, an escaped single quote, an escaped backslash, and a final escaped single quote."", 'The final form looks like this:', 'This is a bit unwieldy to type by hand, but the literal nature of the shell’s single quoting makes it easy to automate a slight variation:']","[<code>pgrep -fl java | grep -i datanode | awk '{print $1}'
</code>, <code>ssh host …
</code>, <code>sh -c …</code>, <code>ssh host ""sudo su user -c …""
</code>, <code>\\</code>, <code>\'</code>, <code>\</code>, <code>'</code>, <code>{print $1}
</code>, <code>pgrep -fl java | grep -i datanode | awk …
</code>, <code>$</code>, <code>'{print $1}'</code>, <code>{print\ \$1}</code>, <code>$</code>, <code>{print' $'1}</code>, <code>$</code>, <code>""{print \$1}""</code>, <code>$</code>, <code>{print"" $""1}</code>, <code>$</code>, <code>$</code>, <code>'{print $1}'</code>, <code>pgrep -fl java | grep -i datanode | awk '{print $1}'
</code>, <code>sudo su user -c …
</code>, <code>su user -c …</code>, <code>some-shell -c …</code>, <code>'pgrep -fl java | grep -i datanode | awk '\''{print $1}'\'
</code>, <code>pgrep … awk</code>, <code>pgrep\ -fl\ java\ \|\ grep\ -i\ datanode\ \|\ awk\ \'{print\ \$1}</code>, <code>pgrep\ -fl\ java\|grep\ -i\ datanode\|awk\ \'{print\$1}</code>, <code>""pgrep -fl java | grep -i datanode | awk '{print \$1}'""</code>, <code>$</code>, <code>'pgrep -fl java | grep -i datanode | awk '""'""'{print \$1}'""'""</code>, <code>'pgrep -fl java | grep -i datanode | awk ""{print \$1}""'</code>, <code>'pgrep -fl java | grep -i datanode | awk {print\ \$1}'</code>, <code>sudo su user -c 'pgrep -fl java | grep -i datanode | awk '\''{print $1}'\'
</code>, <code>ssh host …</code>, <code>sh -c …</code>, <code>ssh host …
</code>, <code>'sudo su user -c '\''pgrep -fl java | grep -i datanode | awk '\'\\\'\''{print $1}'\'\\\'
</code>, <code>'sudo su user -c '</code>, <code>'pgrep … awk '</code>, <code>ssh host 'sudo su user -c '\''pgrep -fl java | grep -i datanode | awk '\'\\\'\''{print $1}'\'\\\'
</code>, <code>#!/bin/sh

sq() { # single quote for Bourne shell evaluation
    # Change ' to '\'' and wrap in single quotes.
    # If original starts/ends with a single quote, creates useless
    # (but harmless) '' at beginning/end of result.
    printf '%s\n' ""$*"" | sed -e ""s/'/'\\\\''/g"" -e 1s/^/\'/ -e \$s/\$/\'/
}

# Some shells (ksh, bash, zsh) can do something similar with %q, but
# the result may not be compatible with other shells (ksh uses $'...',
# but dash does not recognize it).
#
# sq() { printf %q ""$*""; }

ap='{print $1}'
s1=""pgrep -fl java | grep -i datanode | awk $(sq ""$ap"")""
s2=""sudo su user -c $(sq ""$s1"")""

ssh host ""$(sq ""$s2"")""
</code>]"
417,https://unix.stackexchange.com/questions/78734/,Why shouldn't someone use passwords in the command line?,"['Command lines are not just available in history. They are also available, for example, in the output of ps -ocmd or through the /proc filesystem. (/proc/<pid>/cmdline) which is where ps reads them.', ""Also, users' home directories are often world- or group- readable; you can make the history file only user-readable, but that might not survive deletion and recreation.""]","[<code>ps -ocmd</code>, <code>/proc</code>, <code>/proc/&lt;pid&gt;/cmdline</code>, <code>ps</code>]"
418,https://unix.stackexchange.com/questions/144514/,Add arguments to 'bash -c',"[""You're interpreting the man page wrong.  Firstly, the part about -- signalling the end of options is irrelevant to what you're trying to do.  The -c overrides the rest of the command line from that point on, so that it's no longer going through bash's option handling at all, meaning that the -- would be passed through to the command, not handled by bash as an end of options marker."", ""The second mistake is that extra arguments are assigned as positional parameters to the shell process that's launched, not passed as arguments to the command.  So, what you're trying to do could be done as one of:"", 'In the first case, passing echo the parameters $0 and $1 explicitly, and in the second case, using ""$@"" to expand as normal as ""all positional parameters except $0"".  Note that in that case we have to pass something to be used as $0 as well; I\'ve chosen ""bash"" since that\'s what $0 would normally be, but anything else would work.', 'As for the reason it\'s done this way, instead of just passing any arguments you give directly to the command you list:  note that the documentation says ""commands are read from string"", plural.  In other words, this scheme allows you to do:', 'But, note that a better way to meet your original goal might be to use env rather than bash:', ""If you don't need any of the features that a shell is providing, there's no reason to use it - using env in this case will be faster, simpler, and less typing.  And you don't have to think as hard to make sure it will safely handle filenames containing shell metacharacters or whitespace.""]","[<code>--</code>, <code>-c</code>, <code>--</code>, <code>/bin/bash -c 'echo ""$0"" ""$1""' foo bar
/bin/bash -c 'echo ""$@""' bash foo bar
</code>, <code>$0</code>, <code>$1</code>, <code>""$@""</code>, <code>$0</code>, <code>$0</code>, <code>/bin/bash -c 'mkdir ""$1""; cd ""$1""; touch ""$2""' bash dir file
</code>, <code>env</code>, <code>bash</code>, <code>/usr/bin/env -- ""ls"" ""-l""
</code>, <code>env</code>]"
419,https://unix.stackexchange.com/questions/117501/,"In bash script, how to capture stdout line by line","['Just pipe the command into a while loop. There are a number of nuances to this, but basically (in bash or any POSIX shell):', ""The other main gotcha with this (other than the IFS stuff below) is when you try to use variables from inside the loop once it has finished. This is because the loop is actually executed in a sub-shell (just another shell process) which you can't access variables from (also it finishes when the loop does, at which point the variables are completely gone. To get around this, you can do:"", ""Hauke's example of setting lastpipe in bash is another solution."", ""To make sure you are processing the output of the command 'as it happens', you can use stdbuf to set the process' stdout to be line buffered."", 'This will configure the process to write one line at a time into the pipe instead of internally buffering its output into blocks. Beware that the program can change this setting itself internally. A similar effect can be achieved with unbuffer (part of expect) or script.', 'stdbuf is available on GNU and FreeBSD systems, it only affects the stdio buffering and only works for non-setuid, non-setgid applications that are dynamically linked (as it uses a LD_PRELOAD trick).']","[<code>while</code>, <code>bash</code>, <code>longcommand |
  while IFS= read -r line
  do
    whatever ""$line""
  done
</code>, <code>IFS</code>, <code>longcommand | {
  while IFS= read -r line
  do
    whatever ""$line""
    lastline=""$line""
  done

  # This won't work without the braces.
  echo ""The last line was: $lastline""
}
</code>, <code>lastpipe</code>, <code>bash</code>, <code>stdbuf</code>, <code>stdout</code>, <code>stdbuf -oL longcommand |
  while IFS= read -r line
  do
    whatever ""$line""
  done
</code>, <code>unbuffer</code>, <code>expect</code>, <code>script</code>, <code>stdbuf</code>, <code>stdio</code>]"
420,https://unix.stackexchange.com/questions/11044/,Changing parent directory (../) with symlinks,"['Bash (as well as ksh, zsh, and even ash) track directory changes so that cd /foo/bar && cd .. always takes you to /foo even if bar is a symlink. Pass the -P option to cd to ignore the tracked change and follow the “physical” directory structure:', 'See help cd or man builtins for documentation about the bash builtin cd.\nIf you really dislike the directory tracking feature, you can turn it off with set -P in bash (set -o no_chase_link in zsh).']","[<code>cd /foo/bar &amp;&amp; cd ..</code>, <code>/foo</code>, <code>bar</code>, <code>-P</code>, <code>cd</code>, <code>cd -P ..
</code>, <code>help cd</code>, <code>man builtins</code>, <code>cd</code>, <code>set -P</code>, <code>set -o no_chase_link</code>]"
421,https://unix.stackexchange.com/questions/47793/,Bash commands inside vi,"['Yes, e.g if you want to do ls, try:', ':!ls', 'To spawn a shell, use', ':shell']","[<code>ls</code>, <code>:!ls</code>, <code>:shell</code>]"
422,https://unix.stackexchange.com/questions/140610/,Using variables to store terminal color codes for PS1?,"[""The solution is to get the shell to substitute the color variables when defining the prompt, but not the functions. To do this, use the double quotes as you had originally tried, but escape the commands so they aren't evaluated until the prompt is drawn."", 'Notice the \\ before the $() on each command.', 'If we echo this out, we see:', 'As you can see, the color variables got substituted, but not the commands.']","[<code>PS1=""\u@\h:\w${YELLOW}\$(virtual_env)${GREEN}\$(git_branch)${RESET}$ ""
</code>, <code>\</code>, <code>$()</code>, <code>echo ""$PS1""
\u@\h:\w\[\033[33m\]$(virtual_env)\[\033[32m\]$(git_branch)\[\033[0m\]$ 
</code>]"
423,https://unix.stackexchange.com/questions/208615/,Is 'cat' a shell built-in or an external program?,"['type tells you what the shell would use.  For example:', 'That means that if, at the bash prompt, you type echo, you will get the built-in.  If you specify the path, as in /bin/echo, you will get the external command.', 'which, by contrast is an external program that has no special knowledge of what the shell will do.  On debian-like systems, which is a shell script which searches the PATH for the executable.  Thus, it will give you the name of the external executable even if the shell would use a built-in.', 'If a command is only available as a built-in, which will return nothing:', 'Now, let;s look at cat:', 'cat is an external executable, not a shell builtin.']","[<code>type</code>, <code>$ type echo
echo is a shell builtin
$ type /bin/echo
/bin/echo is /bin/echo
</code>, <code>echo</code>, <code>/bin/echo</code>, <code>which</code>, <code>which</code>, <code>which</code>, <code>$ type help
help is a shell builtin
$ which help
$ 
</code>, <code>cat</code>, <code>$ type cat
cat is hashed (/bin/cat)
$ which cat
/bin/cat
</code>, <code>cat</code>]"
424,https://unix.stackexchange.com/questions/38072/,How can I save the last command to a file?,"['If you are using bash, you can use the fc command to display your history in the way you want:', 'That will print out your last command. -l means list, -n means not to prefix lines with command numbers and -1 says to show just the last command. If the whitespace at the start of the line (only the first line on multi-line commands) is bothersome, you can get rid of that easily enough with sed. Make that into a shell function, and you have a solution as requested (getlast >> LOGBOOK):', 'That should function as you have asked in your question.', 'I have added a slight variation by adding ""$1"" ""$1"" to the fc command. This will allow you to say, for example, getlast mycommand to print out the last command line invoking mycommand, so if you forgot to save before running another command, you can still easily save the last instance of a command. If you do not pass an argument to getlast (i.e. invoke fc as fc -ln """" """", it prints out just the last command only).', ""[Note: Answer edited to account for @Bram's comment and the issue mentioned in @glenn jackman's answer.]""]","[<code>bash</code>, <code>fc</code>, <code>fc -ln -1
</code>, <code>-l</code>, <code>-n</code>, <code>-1</code>, <code>sed</code>, <code>getlast &gt;&gt; LOGBOOK</code>, <code>getlast() {
    fc -ln ""$1"" ""$1"" | sed '1s/^[[:space:]]*//'
}
</code>, <code>""$1"" ""$1""</code>, <code>fc</code>, <code>getlast mycommand</code>, <code>mycommand</code>, <code>getlast</code>, <code>fc</code>, <code>fc -ln """" """"</code>]"
425,https://unix.stackexchange.com/questions/253518/,Where are bash line continuations after && and || documented?,"['A newline is ignored in a few contexts where there is manifestly an unterminated command. These contexts include after a control operator (&&, ||, |, &, ;, ;;, but not !).', ""I don't see this documented in the bash manual."", ""In POSIX, it's specified via the grammar rules. Wherever the rules have linebreak, you can have zero or more line breaks.""]","[<code>&amp;&amp;</code>, <code>||</code>, <code>|</code>, <code>&amp;</code>, <code>;</code>, <code>;;</code>, <code>!</code>, <code>linebreak</code>]"
426,https://unix.stackexchange.com/questions/377979/,How to make a for loop in command line?,"['The syntax of a for loop from the bash manual page is', 'The semicolons may be replaced with carriage returns, as noted elsewhere in the bash manual page: ""A sequence of one or more newlines may appear in a list instead of a semicolon to delimit commands.""', 'However, the reverse is not true; you cannot arbitrarily replace newlines with semicolons.  Your multiline script can be converted to a single line as long as you observe the above syntax rules and do not insert an extra semicolon after the do:']","[<code>for</code>, <code>bash</code>, <code>for name [ [ in [ word ... ] ] ; ] do list ; done
</code>, <code>bash</code>, <code>do</code>, <code>for i in `seq 1 10`; do echo $i; done
</code>]"
427,https://unix.stackexchange.com/questions/177777/,Drawing a histogram from a bash command output,['Try this in perl :'],"[<code>perl -lane 'print $F[0], ""\t"", ""="" x ($F[1] / 5)' file
</code>, <code>-a</code>, <code>split()</code>, <code>@F</code>, <code>$F[n]</code>, <code>x</code>, <code>($F[1] / 5)</code>]"
428,https://unix.stackexchange.com/questions/460836/,Running a loop precisely once per second,"['To stay a bit closer to the original code, what I do is:', ""This changes the semantics a little: if your stuff took less than a second, it will simply wait for the full second to pass. However, if your stuff takes longer than a second for any reason, it won't keep spawning even more subprocesses with never any end to it."", 'So your stuff never runs in parallel, and not in the background, so variables work as expected too.', ""Note that if you do start additional background tasks as well, you'll have to change the wait instruction to only wait for the sleep process specifically."", ""If you need it to be even more accurate, you'll probably just have to sync it to the system clock and sleep ms instead of full seconds."", 'How to sync to system clock? No idea really, stupid attempt:', 'Default:', 'Output: 003511461 010510925 016081282 021643477 028504349 03... (keeps growing)', 'Synced:', 'Output: 002648691 001098397 002514348 001293023 001679137 00... (stays same)']","[<code>while true; do
  sleep 1 &amp;
  ...your stuff here...
  wait # for sleep
done
</code>, <code>wait</code>, <code>sleep</code>, <code>while sleep 1
do
    date +%N
done
</code>, <code> while sleep 0.$((1999999999 - 1$(date +%N)))
 do
     date +%N
 done
</code>]"
429,https://unix.stackexchange.com/questions/144718/,sudo: unable to execute ./script.sh: no such file or directory,"['This usually happens when the shebang (#!) line in your script is broken.', 'The shebang is what tells the kernel the file needs to be executed using an interpreter. When run without sudo, the message is a little more meaningful. But with sudo you get the message you got.', 'For example:', ""The bad interpreter message clearly indicates that it's the shebang which is faulty.""]","[<code>#!</code>, <code>sudo</code>, <code>sudo</code>, <code>$ cat test.sh
#!/bin/foo
echo bar

$ ./test.sh
bash: ./test.sh: /bin/foo: bad interpreter: No such file or directory

$ bash test.sh
bar

$ sudo ./test.sh
sudo: unable to execute ./test.sh: No such file or directory

$ sudo bash ./test.sh
bar
</code>, <code>bad interpreter</code>]"
430,https://unix.stackexchange.com/questions/35088/,Reading passwords without showing on screen in Bash Scripts,['From help read:'],"[<code>help read</code>, <code>-s        do not echo input coming from a terminal
</code>]"
431,https://unix.stackexchange.com/questions/18077/,How can I use two bash commands in -exec of find command?,"['As for the find command, you can also just add more -exec commands in a row:', 'Note that this command is, in its result, equivalent of using', 'chgrp -v new_group file && chmod -v 770 file', 'on each file.', ""All the find's parameters such as -name, -exec, -size and so on, are actually tests: find will continue to run them one by one as long as the entire chain so far has evaluated to true. So each consecutive -exec command is executed only if the previous ones returned true (i.e. 0 exit status of the commands). But find also understands logic operators such as or (-o) and not (!). Therefore, to use a chain of -exec tests regardless of the previous results, one would need to use something like this:""]","[<code>find</code>, <code>-exec</code>, <code>find . -name ""*"" -exec chgrp -v new_group '{}' \; -exec chmod -v 770 '{}' \;
</code>, <code>find</code>, <code>-name</code>, <code>-exec</code>, <code>-size</code>, <code>find</code>, <code>-exec</code>, <code>0</code>, <code>find</code>, <code>-o</code>, <code>!</code>, <code>-exec</code>, <code>find . -name ""*"" \( -exec chgrp -v new_group {} \; -o -true \) -exec chmod -v 770 {} \; 
</code>]"
432,https://unix.stackexchange.com/questions/145150/,Verify the length of a variable,"['More elegant? No', 'Shorter? Yes :)', 'And if you have no problem on trading more elegance in favor of being shorter, you can have a script with 2 lines less:', 'You could use double brackets if you think it is safer. Explanation here.']","[<code>#!/bin/bash
read string
if [ ${#string} -ge 5 ]; then echo ""error"" ; exit
else echo ""done""
fi
</code>, <code>#!/bin/bash
read string
[ ${#string} -ge 5 ] &amp;&amp; echo ""error"" || echo ""done""
</code>]"
433,https://unix.stackexchange.com/questions/59249/,print output to 3 separate columns,"[""You can use the shell command 'column' for that, check: column MAN page."", ""Combine this with a loop and you're in business, e.g.:""]","[<code>column</code>, <code>#!/bin/sh

MYPATH=/
TOTALFILE=$(ls $MYPATH/* | wc -l)
FILE=$(ls -1tcr $MYPATH/* | head -5 | rev | cut -d/ -f1 | rev)

declare -a FILES
declare -a FILETIME

OUTPUT=""FILENAME CREATED TIME ERROR_HEADER\n\n------------------------------ ----------------------------- ----------------------------------- ------$

for i in $MYPATH/*;
do
    FILES[${#FILES[@]}]=""$i""
    FILETIME[${#FILETIME[@]}]=$(stat --format=%y $i | head -5 | cut -d'.' -f1)
    TOPLINE=$(head -1 $i | grep -Po '"".*?""' | head -5)

    OUTPUT=""$OUTPUT\n${FILES[${#FILES[@]}-1]} ${FILETIME[${#FILETIME[@]}-1]} $TOPLINE\n""
done

echo -ne $OUTPUT | column -t
</code>]"
434,https://unix.stackexchange.com/questions/3831/,"In Bash, are if [ -z ""$1"" ] and if [ ""$1"" = """" ] the same?","['[ ""$1"" = """" ] and [ -z ""$1"" ] are exactly equivalent in bash and other POSIX-compliant shells. (Note that there must be a space on each side of the brackets, unless there is a non-word-constituent character like ;.)', '[ is a shell built-in like any other; in fact it can also be spelled test (the only difference between the two is that [ requires a ] as the last argument). So if you run [ ""$1"" = """" ] with $1 expanding to -z, the test operator sees three arguments: -z, = and the empty string. Some older Bourne shells sometimes threw parse errors when an operand looked like an operator in this way, even if there was no ambiguity in the complete expression. I don\'t know if any version did in fact have trouble with this particular expression, but more complex expressions could throw them off. There may also have been versions that had trouble with empty words; these would not have supported [ -z ""$1"" ] either. A common shell idiom is [ x""$1"" = x"""" ]. It avoids any risk of having operands parsed as operators because no operator starts with a letter.', ""In ksh, bash and zsh, you can use the double bracket syntax, [[ -z $1 ]]. This newer syntax (it's from the late 1980s rather than the mid-1970s) eliminates the risk of having operands parsed as operators by using a special syntactic construct rather than an ordinary built-in. Operators must appear literally, unquoted within the double brackets, and you don't need to double quote variable expansions.""]","[<code>[ ""$1"" = """" ]</code>, <code>[ -z ""$1"" ]</code>, <code>;</code>, <code>[</code>, <code>test</code>, <code>[</code>, <code>]</code>, <code>[ ""$1"" = """" ]</code>, <code>$1</code>, <code>-z</code>, <code>-z</code>, <code>=</code>, <code>[ -z ""$1"" ]</code>, <code>[ x""$1"" = x"""" ]</code>, <code>[[ -z $1 ]]</code>]"
435,https://unix.stackexchange.com/questions/118856/,Check if $REPLY is in a range of numbers,"['The [ command/shell builtin has comparison tests, so you can just do', ""where -ge means greater-or-equal-to (and so on). The [ command is just a command, not special syntax (it's actually the same as test: check out man test), so it NEEDS the space after it. If you write [$REPLY it will try to find a command named [$REPLY and execute it, which won't work. The same goes for closing ]."", ""Here, we're using the && shell operator to run the second command only if the first is successful. [ also supports -a to and two tests, but it's deprecated and its usage should be discouraged as it causes arguments not to be parseable reliably."", 'Edit: to test if the number is integer (if that can happen in your code), first do the test', 'Of course all these bracket expressions return 0 (true) or 1 (false) and can be combined. Not only you can put everything in the same bracket, you can also do', 'or something similar.']","[<code>[</code>, <code>if [ ""$REPLY"" -ge 1 ] &amp;&amp; [ ""$REPLY"" -le 32 ]; then REPLY=-2;
elif [ ""$REPLY"" -ge 33 ] &amp;&amp; [ ""$REPLY"" -le 48 ]; then REPLY=-1; fi
</code>, <code>-ge</code>, <code>[</code>, <code>test</code>, <code>man test</code>, <code>[$REPLY</code>, <code>[$REPLY</code>, <code>]</code>, <code>&amp;&amp;</code>, <code>[</code>, <code>-a</code>, <code>if [[ ""$REPLY"" =~ ^[0-9]+$ ]]; then
   existing code
else echo ""$REPLY is not an integer"" &gt;&amp;2 &amp;&amp; exit 1; fi
</code>, <code>if [[ ""$REPLY"" =~ ^[0-9]+$ ]] &amp;&amp; [ ""$REPLY"" -ge 1 ] &amp;&amp; [ ""$REPLY"" -le 32 ]; then ...
</code>]"
436,https://unix.stackexchange.com/questions/206350/,"What is the difference if I start bash with ""/bin/bash"" or ""/usr/bin/env bash""?","['In one sense, using env could be considered ""portable"" in that the path to bash is not relevant (/bin/bash, /usr/bin/bash, /usr/local/bin/bash, ~/bin/bash, or whatever path) because it is specified in the environment. In this way, a script author could make his script easier to run on many different systems.', 'In another sense, using env to find bash or any other shell or command  interpreter is considered a security risk because an unknown binary (malware) might be used to execute the script. In these environments, and sometimes by managerial policy, the path is specified explicitly with a full path: #!/bin/bash.', 'In general, use env unless you know you are writing in one of these environments that scrutinize the minute details of risk.', 'When Ubuntu first started using dash, some time in 2011, many scripts were broken by that action. There was discussion about it on askubuntu.com. Most scripts were written #!/bin/sh which was a link to /bin/bash. The consensus was this: the script writer is responsible for specifying the interpreter. Therefore, if your script should always be invoked with BASH, specify it from the environment. This saves you having to guess the path, which is different on various Unix/Linux systems. In addition, it will work if tomorrow /bin/sh becomes a link to some other shell like /bin/newsh.', ""Another difference is that the env method won't allow the passing of arguments to the interpreter.""]","[<code>env</code>, <code>bash</code>, <code>/bin/bash</code>, <code>/usr/bin/bash</code>, <code>/usr/local/bin/bash</code>, <code>~/bin/bash</code>, <code>env</code>, <code>bash</code>, <code>#!/bin/bash</code>, <code>env</code>, <code>dash</code>, <code>#!/bin/sh</code>, <code>/bin/bash</code>, <code>/bin/sh</code>, <code>/bin/newsh</code>, <code>env</code>]"
437,https://unix.stackexchange.com/questions/118462/,How can a bash script detect if it is running in the background?,"['Quoting man ps:', 'So you could perform a simple check:']","[<code>man ps</code>, <code>   Here are the different values that the s, stat and state output
   specifiers (header ""STAT"" or ""S"") will display to describe the state of
   a process.
   ...
   +    is in the foreground process group
</code>, <code>case $(ps -o stat= -p $$) in
  *+*) echo ""Running in foreground"" ;;
  *) echo ""Running in background"" ;;
esac
</code>]"
438,https://unix.stackexchange.com/questions/173708/,How do I force a user to change a password at the first time login using ssh?,"['change the age of password to 0 day ', 'syntax chage -d 0 {user-name}', 'In this case ', 'chage -d0 foo ', 'This works for me over ssh also ']","[<code>chage -d 0 {user-name}</code>, <code>chage -d0 foo </code>]"
439,https://unix.stackexchange.com/questions/115276/,"If I sudo execute a Bash script file, will all commands inside the Bash script be executed as sudo as well?","['Q#1: Will I only be prompted for a sudo password once, or will I need to enter the sudo password on each invocation of a command inside the script, that needs sudo permission? ', 'Yes, once, for the duration of the running of your script. ', 'NOTE: When you provide credentials to sudo, the authentication is typically good for 5 minutes within the shell where you typed the password. Additionally any child processes that get executed from this shell, or any script that runs in the shell (your case) will also run at the elevated level.', 'Q#2: is there still a possibility that the sudo permissions will time out (if, for instance, a particular command takes long enough to exceed the sudo timeout)? Or will the initial sudo password entrance last for the complete duration of whole script?', 'No they will not timeout within the script. Only if you interactively were typing them within the shell where the credentials were provided. Every time sudo is executed within this shell, the timeout is reset. But in your case they credentials will remain so long as the script is executing and running commands from within it.', 'This limit is policy-specific; the default password prompt timeout for the sudoers security policy is 5 minutes.']","[<code>sudo</code>, <code>sudo</code>]"
440,https://unix.stackexchange.com/questions/38317/,Glob with Numerical Order,"['Depending on your environment you can use ls -v with GNU coreutils, e.g.:', 'Or if you are on recent versions of FreeBSD or OpenBSD:']","[<code>ls -v</code>, <code>gs -q -sPAPERSIZE=a4 -dNOPAUSE -dBATCH -sDEVICE=pdfwrite \
   -sOutputFile=out.pdf $(ls -v)
</code>, <code>gs -q -sPAPERSIZE=a4 -dNOPAUSE -dBATCH -sDEVICE=pdfwrite \
   -sOutputFile=out.pdf $(ls | sort -V)
</code>]"
441,https://unix.stackexchange.com/questions/157250/,"How to efficiently generate large, uniformly distributed, random integers in bash?","['Thank you all for all your great answers. I ended up with the following solution, that I would like to share.', ""Before I go into any more detail about the whys and hows, here's the tl;dr: my shiny new script :-)"", 'Save that to ~/bin/rand and you have at your availability a sweet random function in bash that can sample an integer in a given arbitrary range. The range may contain negative and positive integers and can be up to 260-1 in length:', 'All ideas by the other answerers were great. The answers by terdon, J.F. Sebastian, and jimmij used external tools to do the task in a simple and efficient manner. However, I preferred a true bash solution for maximum portability, and maybe a little bit, simply out of love for bash ;)', ""Ramesh's and l0b0's answers used /dev/urandom or /dev/random in combination with od. That's good, however, their approaches had the disadvantage of only being able to sample random integers in the range 0 to 28n-1 for some n, since this method samples bytes, i.e., bitstrings of length 8. These are quite big jumps with increasing n."", ""Finally, Falco's answer describes the general idea how this could be done for arbitrary ranges (not only powers of two). Basically, for a given range {0..max}, we can determine what the next power of two is, i.e., exactly how many bits are required to represent max as a bitstring. Then we can sample just that many bits and see whether this bistring, as an integer, is greater than max. If so, repeat. Since we sample just as many bits as are required to represent max, each iteration has a probability greater or equal than 50% of succeeding (50% in the worst case, 100% in the best case). So this is very efficient."", ""My script is basically a concrete implementation of Falco's answer, written in pure bash and highly efficient since it uses bash's built-in bitwise operations to sample bitstrings of the desired length. It additionally honors an idea by Eliah Kagan that suggests to use the built-in $RANDOM variable by concatening bitstrings resulting from repeated invocations of $RANDOM. I actually implemented both the possibilities to use /dev/urandom and $RANDOM. By default the above script uses $RANDOM. (And ok, if using /dev/urandom we need od and tr, but these are backed by POSIX.)"", 'Before I get into this, two observations:', ""It turns out bash can't handle integers larger than 263-1. See for yourself:"", 'It would appear that bash internally uses signed 64-bit integers to store integers. So, at 263 it ""wraps around"" and we get a negative integer. So we can\'t hope to get any range larger than 263-1 with whatever random function we use. Bash simply can\'t handle it.', 'Whenever we want to sample a value in an arbitrary range between min and max with possibly min != 0, we can simply sample a value between 0 and max-min instead and then add min to the final result. This works even if min and possibly also max are negative, but we need to be careful to sample a value between 0 and the absolute value of max-min. So then, we can focus on how to sample a random value between 0 and an arbitrary positive integer max. The rest is easy.', 'Step 1: Determine how many bits are needed to represent an integer (the logarithm)', 'So for a given value max, we want to know just how many bits are needed to represent it as a bitstring. This is so that later we can randomly sample only just as many bits as are needed, which makes the script so efficient.', ""Let's see. Since with n bits, we can represent up to the value 2n-1, then the number n of bits needed to represent an arbitrary value x is ceiling(log2(x+1)). So, we need a function to compute the ceiling of a logarithm to the base 2. It is rather self-explanatory:"", 'We need the condition n>0 so if it grows too great, wraps around and becomes negative, the loop is guaranteed to terminate.', 'Step 2: Sample a random a bitstring of length n', ""The most portable ideas are to either use /dev/urandom (or even /dev/random if there is a strong reason) or bash's built-in $RANDOM variable. Let's look at how to do it with $RANDOM first."", 'Option A: Using $RANDOM', ""This uses the idea mentioned by Eliah Kagan. Basically, since $RANDOM samples a 15-bit integer, we can use $((RANDOM<<15|RANDOM)) to sample a 30-bit integer. That means, shift a first invocation of $RANDOM by 15 bits to the left, and apply a bitwise or with a second invocation of $RANDOM, effectively concatening two independently sampled bitstrings (or at least as independent as bash's built-in $RANDOM goes)."", ""We can repeat this to obtain a 45-bit or 60-bit integer. After that bash can't handle it anymore, but this means we can easily sample a random value between 0 and 260-1. So, to sample an n-bit integer, we repeat the procedure until our random bitstring, whose length grows in 15-bit steps, has a length greater or equal than n. Finally, we cut off the bits that are too much by appropriately bitwise shifting to the right, and we end up with a n-bit random integer."", 'Option B: Using /dev/urandom', 'Alternatively, we can use od and /dev/urandom to sample an n-bit integer. od will read bytes, i.e., bitstrings of length 8. Similarly as in the previous method, we sample just so many bytes that the equivalent number of sampled bits is greater or equal than n, and cut off the bits that are too much.', 'The lowest number of bytes needed to get at least n bits is the lowest multiple of 8 that is greater or equal than n, i.e., floor((n+7)/8).', ""This only works up to 56-bit integers. Sampling one more byte would get us an 64-bit integer, i.e., a value up to 264-1, which bash can't handle."", 'Putting the pieces together: Get random integers in arbitrary ranges', ""We can sample n-bit bitstrings now, but we want to sample integers in a range from 0 to max, uniformly at random, where max may be arbitrary, not necessarily a power of two. (We can't use modulo as that creates a bias.)"", 'The whole point why we tried so hard to sample just as many bits as are needed to represent the value max, is that we can now safely (and efficiently) use a loop to repeatedly sample an n-bit bitstring until we sample a value that is lower or equal to max. In the worst case (max is a power of two), each iteration terminates with a probability of 50%, and in the best case (max is a power of two minus one), the first iteration terminates with certainty.', 'Wrapping things up', 'Finally, we want to sample integers between min and max, where min and max can be arbitrary, even negative. As previously mentioned, this is now trivial.', ""Let's put it all in a bash script. Do some argument parsing stuff... We want two arguments min and max, or only one argument max, where min defaults to 0."", '...and, finally, to sample uniformly at random a value between min and max, we sample a random integer between 0 and the absolute value of max-min, and add min to the final result. :-)', 'Inspired by this, I might try to use dieharder to test and benchmark this PRNG, and put my findings in here. :-)']","[<code>#!/usr/bin/env bash
#
# Generates a random integer in a given range

# computes the ceiling of log2
# i.e., for parameter x returns the lowest integer l such that 2**l &gt;= x
log2() {
  local x=$1 n=1 l=0
  while (( x&gt;n &amp;&amp; n&gt;0 ))
  do
    let n*=2 l++
  done
  echo $l
}

# uses $RANDOM to generate an n-bit random bitstring uniformly at random
#  (if we assume $RANDOM is uniformly distributed)
# takes the length n of the bitstring as parameter, n can be up to 60 bits
get_n_rand_bits() {
  local n=$1 rnd=$RANDOM rnd_bitlen=15
  while (( rnd_bitlen &lt; n ))
  do
    rnd=$(( rnd&lt;&lt;15|$RANDOM ))
    let rnd_bitlen+=15
  done
  echo $(( rnd&gt;&gt;(rnd_bitlen-n) ))
}

# alternative implementation of get_n_rand_bits:
# uses /dev/urandom to generate an n-bit random bitstring uniformly at random
#  (if we assume /dev/urandom is uniformly distributed)
# takes the length n of the bitstring as parameter, n can be up to 56 bits
get_n_rand_bits_alt() {
  local n=$1
  local nb_bytes=$(( (n+7)/8 ))
  local rnd=$(od --read-bytes=$nb_bytes --address-radix=n --format=uL /dev/urandom | tr --delete "" "")
  echo $(( rnd&gt;&gt;(nb_bytes*8-n) ))
}

# for parameter max, generates an integer in the range {0..max} uniformly at random
# max can be an arbitrary integer, needs not be a power of 2
rand() {
  local rnd max=$1
  # get number of bits needed to represent $max
  local bitlen=$(log2 $((max+1)))
  while
    # could use get_n_rand_bits_alt instead if /dev/urandom is preferred over $RANDOM
    rnd=$(get_n_rand_bits $bitlen)
    (( rnd &gt; max ))
  do :
  done
  echo $rnd
}

# MAIN SCRIPT

# check number of parameters
if (( $# != 1 &amp;&amp; $# != 2 ))
then
  cat &lt;&lt;EOF 1&gt;&amp;2
Usage: $(basename $0) [min] max

Returns an integer distributed uniformly at random in the range {min..max}
min defaults to 0
(max - min) can be up to 2**60-1  
EOF
  exit 1
fi

# If we have one parameter, set min to 0 and max to $1
# If we have two parameters, set min to $1 and max to $2
max=0
while (( $# &gt; 0 ))
do
  min=$max
  max=$1
  shift
done

# ensure that min &lt;= max
if (( min &gt; max ))
then
  echo ""$(basename $0): error: min is greater than max"" 1&gt;&amp;2
  exit 1
fi

# need absolute value of diff since min (and also max) may be negative
diff=$((max-min)) &amp;&amp; diff=${diff#-}

echo $(( $(rand $diff) + min ))
</code>, <code>~/bin/rand</code>, <code>$ rand 
Usage: rand [min] max

Returns an integer distributed uniformly at random in the range {min..max}
min defaults to 0
(max - min) can be up to 2**60-1  
$ rand 1 10
9
$ rand -43543 -124
-15757
$ rand -3 3
1
$ for i in {0..9}; do rand $((2**60-1)); done
777148045699177620
456074454250332606
95080022501817128
993412753202315192
527158971491831964
336543936737015986
1034537273675883580
127413814010621078
758532158881427336
924637728863691573
</code>, <code>/dev/urandom</code>, <code>/dev/random</code>, <code>od</code>, <code>{0..max}</code>, <code>max</code>, <code>max</code>, <code>max</code>, <code>$RANDOM</code>, <code>$RANDOM</code>, <code>/dev/urandom</code>, <code>$RANDOM</code>, <code>$RANDOM</code>, <code>/dev/urandom</code>, <code>$ echo $((2**63-1))
9223372036854775807
$ echo $((2**63))
-9223372036854775808
</code>, <code>min</code>, <code>max</code>, <code>min != 0</code>, <code>0</code>, <code>max-min</code>, <code>min</code>, <code>min</code>, <code>max</code>, <code>0</code>, <code>max-min</code>, <code>0</code>, <code>max</code>, <code>max</code>, <code>n</code>, <code>n</code>, <code>x</code>, <code>log2() {
  local x=$1 n=1 l=0
  while (( x&gt;n &amp;&amp; n&gt;0 ))
  do
    let n*=2 l++
  done
  echo $l
}
</code>, <code>n&gt;0</code>, <code>n</code>, <code>/dev/urandom</code>, <code>/dev/random</code>, <code>$RANDOM</code>, <code>$RANDOM</code>, <code>$RANDOM</code>, <code>$RANDOM</code>, <code>$((RANDOM&lt;&lt;15|RANDOM))</code>, <code>$RANDOM</code>, <code>$RANDOM</code>, <code>$RANDOM</code>, <code>get_n_rand_bits() {
  local n=$1 rnd=$RANDOM rnd_bitlen=15
  while (( rnd_bitlen &lt; n ))
  do
    rnd=$(( rnd&lt;&lt;15|$RANDOM ))
    let rnd_bitlen+=15
  done
  echo $(( rnd&gt;&gt;(rnd_bitlen-n) ))
}
</code>, <code>/dev/urandom</code>, <code>od</code>, <code>/dev/urandom</code>, <code>od</code>, <code>get_n_rand_bits_alt() {
  local n=$1
  local nb_bytes=$(( (n+7)/8 ))
  local rnd=$(od --read-bytes=$nb_bytes --address-radix=n --format=uL /dev/urandom | tr --delete "" "")
  echo $(( rnd&gt;&gt;(nb_bytes*8-n) ))
}
</code>, <code>n</code>, <code>0</code>, <code>max</code>, <code>max</code>, <code>max</code>, <code>n</code>, <code>max</code>, <code>max</code>, <code>max</code>, <code>rand() {
  local rnd max=$1
  # get number of bits needed to represent $max
  local bitlen=$(log2 $((max+1)))
  while
    # could use get_n_rand_bits_alt instead if /dev/urandom is preferred over $RANDOM
    rnd=$(get_n_rand_bits $bitlen)
    (( rnd &gt; max ))
  do :
  done
  echo $rnd
}
</code>, <code>min</code>, <code>max</code>, <code>min</code>, <code>max</code>, <code>min</code>, <code>max</code>, <code>max</code>, <code>min</code>, <code>0</code>, <code># check number of parameters
if (( $# != 1 &amp;&amp; $# != 2 ))
then
  cat &lt;&lt;EOF 1&gt;&amp;2
Usage: $(basename $0) [min] max

Returns an integer distributed uniformly at random in the range {min..max}
min defaults to 0
(max - min) can be up to 2**60-1  
EOF
  exit 1
fi

# If we have one parameter, set min to 0 and max to $1
# If we have two parameters, set min to $1 and max to $2
max=0
while (( $# &gt; 0 ))
do
  min=$max
  max=$1
  shift
done

# ensure that min &lt;= max
if (( min &gt; max ))
then
  echo ""$(basename $0): error: min is greater than max"" 1&gt;&amp;2
  exit 1
fi
</code>, <code>min</code>, <code>max</code>, <code>0</code>, <code>max-min</code>, <code>min</code>, <code>diff=$((max-min)) &amp;&amp; diff=${diff#-}

echo $(( $(rand $diff) + min ))
</code>]"
442,https://unix.stackexchange.com/questions/198794/,Where does the TERM environment variable default get set?,"['On virtual terminals and real terminals, the TERM environment variable is set by the program that chains to login, and is inherited all of the way along to the interactive shell that executes once one has logged on.  Where, precisely, this happens varies from system to system, and according to the kind of terminal.', ""Real, serial, terminals can vary in type, according to what's at the other end of the wire.  So conventionally the getty program is invoked with an argument that specifies the terminal type, or is passed the TERM program from a service manager's service configuration data."", 'S0:3:respawn:/sbin/agetty ttyS0 9600 vt100-nav The last argument to agetty in that line, vt100-nav, is the terminal type set for /dev/ttyS0.  So /etc/inittab is where to change the terminal type for real terminals on such systems.', 'Environment=TERM=vt100 setting the TERM variable in the environment passed to agetty.', 'The serial-getty@.service service unit file, or drop-in files that apply thereto, is where to change the terminal type for real terminals on systemd systems.  Note that such a change applies to all terminal login services that employ this service unit template.  (To change it for only individual terminals, one has to manually instantiate the template, or add drop-ins that only apply to instantiations.)', 'systemd has had at least four mechanisms during its lifetime for picking up the value of the TERM environment variable.  At the time of first writing this answer, as can be seen, there was an Environment=TERM=something line in the template service unit files.  At other times, the types linux and vt102 were hard-wired into the getty and serial-getty service unit files respectively.  More recently, the environment variable has been inherited from process #1, which has set it in various ways.', ""As of 2020, the way that systemd decides what terminal type to specify in a service's TERM environment variable is quite complex, and not documented at all.  The way to change it remains a drop-in configuration file with Environment=TERM=something.  But where the default value originates from is quite variable.  Subject to some fairly complex to explain rules that involve the TTYPath= settings of individual service units, it can be one of three values: a hardwired linux, a hardwired vt220 (no longer vt102), or the value of the TERM environment variable that process #1 inherited, usually from the kernel/bootstrap loader."", '(Ironically, the getttyent() mechanism still exists in the GNU C library, and systemd could have re-used the /etc/ttys mechanism.)', ""Kernel virtual terminals, as you have noted, have a fixed type.  Unlike NetBSD, which can vary the kernel virtual terminal type on the fly, Linux and the other BSDs have a single fixed terminal type implemented in the kernel's built-in terminal emulation program.  On Linux, that type matches linux from the terminfo database.  (FreeBSD's kernel terminal emulation since version 9 has been teken.  Prior to version 9 it was cons25  OpenBSD's is pccon.)"", 'Environment=TERM=linux setting the TERM variable in the environment passed to agetty.', ""For kernel virtual terminals, one does not change the terminal type.  The terminal emulator program in the kernel doesn't change, after all.  It is incorrect to change the type.  In particular, this will screw up cursor/editing key CSI sequence recognition.  The linux CSI sequences sent by the Linux kernel terminal emulator are different to the xterm or vt100 CSI sequences sent by GUI terminal emulator programs in DEC VT mode.  (In fact, they are highly idiosyncratic and non-standard, and different both to all real terminals that I know of, and to pretty much all other software terminal emulators apart from the one built into Linux.)"", 'Your GUI terminal emulator is one of many programs, from the SSH dæmon to screen, that uses pseudo-terminals.  What the terminal type is depends from what terminal emulator program is running on the master side of the pseudo-terminal, and how it is configured.  Most GUI terminal emulators will start the program on the slave side with a TERM variable whose value matches their terminal emulation on the master side.  Programs like the SSH server will attempt to ""pass through"" the terminal type that is on the client end of the connection.  Usually there is some menu or configuration option to choose amongst terminal emulations.', 'The right way to detect colour capability is not to hardwire a list of terminal types in your script.  There are an awful lot of terminal types that support colour.', 'The right way is to look at what termcap/terminfo says about your terminal type.colour=0\nif tput Co > /dev/null 2>&1\nthen\n    test ""`tput Co`"" -gt 2 && colour=1\nelif tput colors > /dev/null 2>&1\nthen\n    test ""`tput colors`"" -gt 2 && colour=1\nfi']","[<code>TERM</code>, <code>login</code>, <code>getty</code>, <code>TERM</code>, <code>init</code>, <code>/etc/inittab</code>, <code>agetty</code>, <code>vt100-nav</code>, <code>/dev/ttyS0</code>, <code>/etc/inittab</code>, <code>/usr/lib/systemd/system/serial-getty@.service</code>, <code>/lib/systemd/system/serial-getty@.service</code>, <code>TERM</code>, <code>agetty</code>, <code>init</code>, <code>/etc/ttys</code>, <code>TERM</code>, <code>getty</code>, <code>/etc/ttys</code>, <code>serial-getty@.service</code>, <code>TERM</code>, <code>Environment=TERM=<i>something</i></code>, <code>linux</code>, <code>vt102</code>, <code>getty</code>, <code>serial-getty</code>, <code>TERM</code>, <code>Environment=TERM=<i>something</i></code>, <code>TTYPath=</code>, <code>linux</code>, <code>vt220</code>, <code>vt102</code>, <code>TERM</code>, <code>getttyent()</code>, <code>/etc/ttys</code>, <code>linux</code>, <code>teken</code>, <code>cons25</code>, <code>pccon</code>, <code>mingetty</code>, <code>vc-get-tty</code>, <code>/usr/lib/systemd/system/getty@.service</code>, <code>/lib/systemd/system/getty@.service</code>, <code>TERM</code>, <code>agetty</code>, <code>linux</code>, <code>xterm</code>, <code>vt100</code>, <code>screen</code>, <code>TERM</code>, <code>TERM</code>]"
443,https://unix.stackexchange.com/questions/260125/,ESC + { : What is it and where I can know more about it?,"['To find out about a key binding.', 'Or with info:', '(or info bash and use the index with completion (i key))', ""However note that the pre-built info page that comes with bash-4.3 sources at least is missing some index entries including that for complete-into-braces, so unless your OS rebuilds the info page from the texinfo sources, the above command won't work."", 'Or with man assuming the less pager like for bash:', 'zsh also has a describe-key-briefly which you can bind on a key or key sequence, like Ctrl+XCtrl+H below:', 'Then you type Ctrl+XCtrl+H followed by the key or key combination to describe. For instance, typing that Ctrl+XCtrl+H twice would display below the prompt:', ""That's basically the same as zsh except that tcsh doesn't have an info page."", 'Which should start your preferred web browser. And search for capitalize-word in there. ']","[<code>bash</code>, <code>$ bind -p | grep -a '{'
""\e{"": complete-into-braces
""{"": self-insert

$ LESS='+/complete-into-braces' man  bash
   complete-into-braces (M-{)
          Perform filename completion and insert the list of possible com‐
          pletions  enclosed within braces so the list is available to the
          shell (see Brace Expansion above).
</code>, <code>info</code>, <code>info bash --index-search=complete-into-braces
</code>, <code>info bash</code>, <code>i</code>, <code>complete-into-braces</code>, <code>zsh</code>, <code>$ bindkey| grep W
""^W"" backward-kill-word
""^[W"" copy-region-as-kill
$ info --index-search=copy-region-as-kill zsh
copy-region-as-kill (ESC-W ESC-w) (unbound) (unbound)
 Copy the area from the cursor to the mark to the kill buffer.

 If called from a ZLE widget function in the form 'zle
 copy-region-as-kill STRING' then STRING will be taken as the text
 to copy to the kill buffer.  The cursor, the mark and the text on
 the command line are not used in this case.
</code>, <code>man</code>, <code>less</code>, <code>bash</code>, <code>LESS='+/copy-region-as-kill' man zshall
</code>, <code>zsh</code>, <code>describe-key-briefly</code>, <code>bindkey '^X^H' describe-key-briefly
</code>, <code>""^X^H"" is describe-key-briefly
</code>, <code>tcsh</code>, <code>zsh</code>, <code>tcsh</code>, <code>&gt; bindkey | grep -a P
""^P""           -&gt;  up-history
""^[P""          -&gt; history-search-backward
&gt; env LESS=+/history-search-backward man tcsh
[...]
</code>, <code>fish</code>, <code>&gt; bind | grep -F '\ec'
bind \ec capitalize-word
&gt; help commands
</code>, <code>capitalize-word</code>]"
444,https://unix.stackexchange.com/questions/55203/,Bash autocomplete: first list files then cycle through them,['This seems close to what you want:'],"[<code>bind ""TAB:menu-complete""
bind ""set show-all-if-ambiguous on""
</code>]"
445,https://unix.stackexchange.com/questions/210158/,How can I list bash'es options for the current shell?,"['Will list the single letter options in a single string.', 'That parameter can also be used like:', 'To first disable shell -filename expansion while simultaneously saving a value for $- - if any - in $1. Next, no globs occur, and last +filename expansion is once again enabled, and possibly also disabled.', 'For example, if -filename expansion was already disabled when the value for $- was first saved, then its saved value would be (at least):', 'And so when set is run again, it works out to:', 'Which just puts you right back where you started.', ""Will list all settable shell options (see Jason's answer for the shoptable - is that a word? - options) in a form that is safe for shell reentry.  In that way, you can also do:"", ""To save, change, and restore the shell options' state respectively."", 'To handle shoptions and settable options in one go:', 'You can also call set without any arguments to add a list of all of the shell\'s currently set variables - also quoted for reentry to the shell. And you can - in bash - additionally add the command typeset -fp to also include all currently declared shell functions. You can lump it all together and eval when ready. You can even call alias without arguments for more of the same. That... might cover it, though. I guess there is ""$@"" - which you\'d have to put in a bash array first, I suppose, before doing set. ', ""Nope, there's also trap. This one's a little funny. Usually:"", ""...will just print this is my subshell because the subshell is a new process and gets its own set of traps - and so doesn't inherit any traps but those which its parent has explicitly ignored - (like trap '' INT)."", 'However:', ""trap behaves specially when it is the first and only command run in a command substitution subshell in that it will reproduce a list of the parent shell's currently set traps in a format which is quoted for safe reentry to the shell. And so you can do the save_traps, then set without arguments - and all of the rest already mentioned - to pretty much get a lock on all shell state. You might want to explicitly add export -p and readonly -p to restore original shell var attributes, though. "", ""Anyway, that's enough.""]","[<code>printf %s\\n ""$-""
</code>, <code>set -f -- ${-:+""-$-""}
echo *don\'t* *glob* *this*
set +f ""$@""
</code>, <code>-f</code>, <code>$-</code>, <code>$1</code>, <code>+f</code>, <code>-f</code>, <code>$-</code>, <code>f
</code>, <code>set</code>, <code>set +f -f
</code>, <code>set +o
</code>, <code>set</code>, <code>shopt</code>, <code>state=$(set +o)
set -some -crazy -options
eval ""$state""
</code>, <code>shopt</code>, <code>set</code>, <code>state=$(set +o;shopt)
#do what you want with options here
eval ""$state""
</code>, <code>set</code>, <code>typeset -fp</code>, <code>eval</code>, <code>alias</code>, <code>""$@""</code>, <code>bash</code>, <code>set</code>, <code>trap</code>, <code>trap 'echo this is my trap' 0
(echo this is my subshell; trap)
</code>, <code>trap</code>, <code>trap</code>, <code>trap '' INT</code>, <code>trap 'echo this is my trap' 0
save_traps=$(trap)
</code>, <code>trap</code>, <code>traps</code>, <code>save_traps</code>, <code>set</code>, <code>export -p</code>, <code>readonly -p</code>]"
446,https://unix.stackexchange.com/questions/379181/,Escape a variable for use as content of another script,"[""I guess I didn't RTFM. It can be done like so:"", 'Then echo ""$foo_esc"" gives the expected \'bar\'\\\'\'baz\'', ""How I'm actually using it is with a function:"", ""Modifying this to use the printf built-in from Dejay's solution:""]","[<code>q_mid=\'\\\'\'
foo_esc=""'${foo//\'/$q_mid}'""
</code>, <code>echo ""$foo_esc""</code>, <code>'bar'\''baz'</code>, <code>function esc_var {
    local mid_q=\'\\\'\'
    printf '%s' ""'${1//\'/$mid_q}'""
}

...

foo_esc=""`esc_var ""$foo""`""
</code>, <code>printf</code>, <code>function esc_vars {
    printf ' %q' ""$@"" | cut -b 2-
}
</code>]"
447,https://unix.stackexchange.com/questions/180943/,Terminal vs bash?,"['When you launch a terminal it will always run some program inside it. That program will generally by default be your shell. On OS X, the default shell is Bash. In combination that means that when you launch Terminal you get a terminal emulator window with bash running inside it (by default).', 'You can change the default shell to something else if you like, although OS X only ships with bash and tcsh. You can choose to launch a custom command in a new terminal with the open command:', ""In that case, your shell isn't running in it, and when your custom command terminates that's the end of things."", ""If you run bash inside your terminal that is already running bash, you get exactly that: one shell running another. You can exit the inner shell with Ctrl-D or exit and you'll drop back to the shell you started in. That can sometimes be useful if you want to test out configuration changes or customise your environment temporarily — when you exit the inner shell, the changes you made go away with it. You can nest them arbitrarily deeply. If you're not doing that, there's no real point in launching another one, but a command like bash some-script.sh will run just that script and then exit, which is often useful."", ""The differences between interactive and non-interactive shells are a bit subtle and mostly deal with which configuration files are loaded, which error behaviours there are, and whether aliases and similar are enabled. The rough principle is that an interactive shell gives you the settings you'd want for sitting in front of it, while a non-interactive shell gives you what you'd want for a standalone script. All of the differences are documented explicitly in the Bash Reference Manual, and also in a dedicated question on this site."", ""For the most part, you don't need to care. There's not often a reason to launch another shell, and when you do you'll have a specific purpose in mind and know what to do with it.""]","[<code>bash</code>, <code>bash</code>, <code>tcsh</code>, <code>open</code>, <code>open -b com.apple.terminal somecommand
</code>, <code>bash</code>, <code>bash</code>, <code>exit</code>, <code>bash some-script.sh</code>]"
448,https://unix.stackexchange.com/questions/229022/,Why does `sort <(ls -l)` work but `sort < (ls -l)` fail?,"[""Because that's not an <, it's a <() which is completely different. This is called process substitution, it is a feature of certain shells that allows you to use the output of one process as input for another. "", 'The > and < operators redirect output to and input from files. The <() operator deals with commands (processes), not files. When you run ', ""You are attempting to run the command ls in a subshell (that's what the parentheses mean), then to pass that subshell as an input file to sort. This, however, is not accepted syntax and you get the error you saw. ""]","[<code>&lt;</code>, <code>&lt;()</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&lt;()</code>, <code>sort &lt; (ls)
</code>, <code>ls</code>, <code>sort</code>]"
449,https://unix.stackexchange.com/questions/159010/,How can I see the exact command line being executed inside some bash instance?,"['I knew I was grasping at straws, but UNIX never fails!', ""Here's how I managed it:"", 'Then at the (gdb) prompt I ran the command, call write_history(""/tmp/foo"") which will write this history to the file /tmp/foo.', 'I then detach from the process.', 'And quit gdb.', 'And sure enough...', 'For easy future re-use, I wrote a bash script, automating the process.']","[<code>bash$ gdb --pid 8909
...
Loaded symbols for /lib/i386-linux-gnu/i686/cmov/libnss_files.so.2
0xb76e7424 in __kernel_vsyscall ()
</code>, <code>(gdb)</code>, <code>call write_history(""/tmp/foo"")</code>, <code>/tmp/foo</code>, <code>(gdb) call write_history(""/tmp/foo"")
$1 = 0
</code>, <code>(gdb) detach
Detaching from program: /bin/bash, process 8909
</code>, <code>gdb</code>, <code>(gdb) q
</code>, <code>bash$ tail -1 /tmp/foo
while true ; do echo 1 ; echo 2&gt;/dev/null ; sleep 30 ; done
</code>]"
450,https://unix.stackexchange.com/questions/97705/,Pipe to multiple files in the shell,"['If you have tee', '(from here)', '(about process substitution)']","[<code>./app | tee &gt;(grep A &gt; A.out) &gt;(grep B &gt; B.out) &gt;(grep C &gt; C.out) &gt; /dev/null
</code>]"
451,https://unix.stackexchange.com/questions/168221/,"Are there problems with hyphens in functions, aliases, and executables?","['According to the POSIX standard, a function name must be a valid name and a name can consist of:', '3.231 Name\n  In the shell command language, a word consisting solely of\n  underscores, digits, and alphabetics from the portable character set.\n  The first character of a name is not a digit.', 'Additionally, an alias must be a valid alias name, which can consist of:', ""3.10 Alias Name\n  In the shell command language, a word consisting solely of underscores,\n  digits, and alphabetics from the portable character set and any of the\n  following characters: '!', '%', ',', '@'."", 'Implementations may allow other characters within alias names as an\n  extension. (Emphasis mine.)', 'A hyphen is not listed among the characters that must be allowed in either case. So, if they are used, portability is not guaranteed.', 'dash is the default shell (/bin/sh) on the debian-ubuntu family and it does not support hyphens in function names:', 'Interestingly enough, it does support hyphens in aliases, though, as noted above, this is an implementation characteristic, not a requirement:', 'The busybox shell (Almquist shell) also does not support hyphens in function names:', 'The following shells are known to support hyphens in function names:', 'The following shells are known not to support hyphens in function names:']","[<code>dash</code>, <code>/bin/sh</code>, <code>$ a-b() { date; }
dash: 1: Syntax error: Bad function name
</code>, <code>$ a_b() { printf ""hello %s\n"" ""$1""; }
$ alias a-b='a_b'
$ a-b world
hello world
</code>, <code>$ a-b() { date; }
-sh: Syntax error: Bad function name
</code>]"
452,https://unix.stackexchange.com/questions/39473/,Command substitution: splitting on newline but not space,"['Looks like the canonical way to do this in bash is something like', 'or, if your version of bash has mapfile:', 'The only difference I can find between the mapfile and the while-read loop versus the one-liner', ""is that the former will convert a blank line to an empty argument, while the one-liner will ignore a blank line.  In this case the one-liner behavior is what I'd prefer anyway, so double bonus on it being compact."", ""I would use IFS=$'\\n' cmd $(<file) but it doesn't work, because $(<file) is interpreted to form the command line before IFS=$'\\n' takes effect."", ""Though it doesn't work in my case, I've now learned that a lot of tools support terminating lines with null (\\000) instead of newline (\\n) which does make a lot of this easier when dealing with, say, file names, which are common sources of these situations:"", 'feeds a list of fully-qualified file names as arguments to md5 without any globbing or interpolating or whatever. That leads to the non-built-in solution', 'although this, too, ignores empty lines, though it does capture lines that have only whitespace.']","[<code>bash</code>, <code>unset args
while IFS= read -r line; do 
    args+=(""$line"") 
done &lt; file

cmd ""${args[@]}""
</code>, <code>mapfile</code>, <code>mapfile -t args &lt; filename
cmd ""${args[@]}""
</code>, <code>(set -f; IFS=$'\n'; cmd $(&lt;file))
</code>, <code>IFS=$'\n' cmd $(&lt;file)</code>, <code>$(&lt;file)</code>, <code>IFS=$'\n'</code>, <code>null (\000)</code>, <code>newline (\n)</code>, <code>find / -name '*.config' -print0 | xargs -0 md5
</code>, <code>tr ""\n"" ""\000"" &lt;file | xargs -0 cmd
</code>]"
453,https://unix.stackexchange.com/questions/969/,Which shell should I use - tcsh vs bash?,"[""After learning bash I find that tcsh is a bit of a step backwards. For instance what I could easily do in bash I'm finding it difficult to do in tcsh. My question on tcsh.  The Internet support and documentation is also much better for bash and very limited for tcsh.  The number of O'Reilly books on bash are great but I have found nothing similar for tcsh.""]",[]
454,https://unix.stackexchange.com/questions/1800/,How to specify a custom autocomplete for specific commands?,"['The easiest way of doing this is to include a shell script in /etc/bash_completion.d/.  The basic structure of this file is a simple function that performs the completion and then invocation of complete which is a bash builtin.  Rather than go into detail on how to use complete, I suggest you read An Introduction to Bash Completion.  Part 1 covers the basics and Part 2 gets into how you would go about writing a completion script.', 'A denser description of bash completion can be found in the ""Programmable Completion"" section of man bash (you can type ""/Programmable Completion"" and then press \'n\' a few times to get there quickly.  Or, if you are feeling luck, ""g 2140 RETURN"").']","[<code>/etc/bash_completion.d/</code>, <code>complete</code>, <code>complete</code>, <code>man bash</code>]"
455,https://unix.stackexchange.com/questions/478590/,What's going to be new in bash 5,"['The changes made to bash between release 4.4 and 5.0 (released 2019-01-07) may be found in the NEWS file in the bash source distribution.', 'Here is a link to it (the changes are too numerous to list here).']","[<code>bash</code>, <code>NEWS</code>, <code>bash</code>]"
456,https://unix.stackexchange.com/questions/364156/,How can I time a pipe?,"['It is working.', 'The different parts of a pipeline are executed concurrently.  The only thing that synchronises/serialises the processes in the pipeline is IO, i.e. one process writing to the next process in the pipeline and the next process reading what the first one writes. Apart from that, they are executing independently of each other.', 'Since there is no reading or writing happening between the processes in your pipeline, the time take to execute the pipeline is that of the longest sleep call.', 'You might as well have written', 'Terdon posted a couple of slightly modified example scripts in the chat:', 'and', 'The query was ""why does time ( sh foo.sh | sh bar.sh ) return 4 seconds rather than 3+3 = 6 seconds?""', ""To see what's happening, including the approximate time each command is executed, one may do this (the output contains my annotations):"", 'So, to conclude, the pipeline takes 4 seconds, not 6, due to the buffering of the output of the first two calls to echo in foo.sh.']","[<code>sleep</code>, <code>time ( foo.sh &amp; bar.sh &amp;; wait )
</code>, <code>#!/bin/sh
# This is ""foo.sh""
echo 1; sleep 1
echo 2; sleep 1
echo 3; sleep 1
echo 4
</code>, <code>#!/bin/sh
# This is ""bar.sh""
sleep 2
while read line; do
  echo ""LL $line""
done
sleep 1
</code>, <code>time ( sh foo.sh | sh bar.sh )</code>, <code>$ time ( env PS4='$SECONDS foo: ' sh -x foo.sh | PS4='$SECONDS bar: ' sh -x bar.sh )
0 bar: sleep 2
0 foo: echo 1     ; The output is buffered
0 foo: sleep 1
1 foo: echo 2     ; The output is buffered
1 foo: sleep 1
2 bar: read line  ; ""bar"" wakes up and reads the two first echoes
2 bar: echo LL 1
LL 1
2 bar: read line
2 bar: echo LL 2
LL 2
2 bar: read line  ; ""bar"" waits for more
2 foo: echo 3     ; ""foo"" wakes up from its second sleep
2 bar: echo LL 3
LL 3
2 bar: read line
2 foo: sleep 1
3 foo: echo 4     ; ""foo"" does the last echo and exits
3 bar: echo LL 4
LL 4
3 bar: read line  ; ""bar"" fails to read more
3 bar: sleep 1    ; ... and goes to sleep for one second

real    0m4.14s
user    0m0.00s
sys     0m0.10s
</code>, <code>echo</code>, <code>foo.sh</code>]"
457,https://unix.stackexchange.com/questions/164107/,Why does BASH process substitution not work with some commands?,"['Process substitution results in a special file (like /dev/fd/63 in your example) that behaves like the read end of a named pipe. This file can be opened and read, but not written, not seeked.', ""Commands that treat their arguments as pure streams work while commands that expect to seek in files they are given (or write to them) won't work. The kind of command that will work is what is usually considered a filter: cat, grep, sed, gzip, awk, etc... An example of a command that won't work is an editor like vi or a file operation like mv."", ""gcc wants to be able to perform random access on its input files to detect what language they are written in. If you instead give gcc a hint about the input file's language, it's happy to stream the file:"", 'The simpler more straightforward form without process substitution also works:', 'Note that this is not specific to bash. All shells that support process substitution behave the same way.']","[<code>/dev/fd/63</code>, <code>cat</code>, <code>grep</code>, <code>sed</code>, <code>gzip</code>, <code>awk</code>, <code>vi</code>, <code>mv</code>, <code>gcc</code>, <code>gcc</code>, <code>gcc -x c &lt;(echo 'int main(){return 0;}')
</code>, <code>echo 'int main(){return 0;}' | gcc -x c -
</code>, <code>bash</code>]"
458,https://unix.stackexchange.com/questions/325490/,How to get last part of http link in Bash?,"[""Using awk for this would work, but it's kind of deer hunting with a howitzer.  If you already have your URL bare, it's pretty simple to do what you want if you put it into a shell variable and use bash's built-in parameter substitution:"", ""The way this works is by removing a prefix that greedily matches '*/', which is what the ## operator does:""]","[<code>awk</code>, <code>bash</code>, <code>$ myurl='http://www.example.com/long/path/to/example/file.ext'
$ echo ${myurl##*/}
file.ext
</code>, <code>##</code>, <code>${haystack##needle} # removes any matching 'needle' from the
                    # beginning of the variable 'haystack'
</code>]"
459,https://unix.stackexchange.com/questions/239479/,How do I get the total size of everything in a directory in one line?,"['Add the --max-depth parameter with a value of 0:', 'Or, use the -s (summary) option:', 'Either of those should give you what you want. For future reference, man du is very helpful.']","[<code>--max-depth</code>, <code>du -h --max-depth=0 /root/test
</code>, <code>-s</code>, <code>du -sh /root/test
</code>, <code>man du</code>]"
460,https://unix.stackexchange.com/questions/208112/,Correct behavior of EXIT and ERR traps when using `set -eu`,"['From man bash:', 'POSIX states that, in the event of an expansion error, a non-interactive shell shall exit when the expansion is associated with either a shell special builtin (which is a distinction bash regularly ignores anyway, and so maybe is irrelevant) or any other utility besides.', 'Also from man bash:', ""Note above that the ERR trap is all about the evaluation of some other command's return. But when an expansion error occurs, there is no command run to return anything. In your example, echo never happens - because while the shell evaluates and expands its arguments it encounters an -unset variable, which has been specified by explicit shell option to cause an immediate exit from the current, scripted shell."", 'And so the EXIT trap, if any, is executed, and the shell exits with a diagnostic message and exit status other than 0 - exactly as it should do.', ""As for the rc: 0 thing, I expect that is a version specific bug of some kind - probably to do with the two triggers for the EXIT occurring at the same time and the one getting the other's exit code (which should not occur). And anyway, with an up-to-date bash binary as installed by pacman:"", ""I added the first line so you can see that the shell's conditions are those of a scripted shell - it is not interactive. The output is:"", 'Here are some relevant notes from recent changelogs:', 'I think it is either the last or the first that is most relevant - or possibly a combination of the two. A trap handler is by its very nature asynchronous because its whole job is to wait for and handle asynchronous signals. And you trigger two simultaneously with -eu and $UNSET_VAR.', ""And so maybe you should just update, but if you like yourself, you'll do it with a different shell altogether. ""]","[<code>man bash</code>, <code>set -u</code>, <code>""@""</code>, <code>""*""</code>, <code>-i</code>, <code>bash</code>, <code>""${x!y}""</code>, <code>!</code>, <code>man bash</code>, <code>trap ... ERR</code>, <code>while</code>, <code>until</code>, <code>if</code>, <code>&amp;&amp;</code>, <code>||</code>, <code>&amp;&amp;</code>, <code>||</code>, <code>!</code>, <code>-e</code>, <code>echo</code>, <code>-u</code>, <code>bash</code>, <code>pacman</code>, <code>bash &lt;&lt;\IN
    printf ""shell options:\t$-\n""
    trap 'echo ""EXIT (rc: $?)""' EXIT
    set -eu
    echo ${UNSET_VAR}
IN
</code>, <code>shell options:  hB
bash: line 4: UNSET_VAR: unbound variable
EXIT (rc: 1)
</code>, <code>$?</code>, <code>for</code>, <code>trap</code>, <code>trap</code>, <code>trap</code>, <code>trap</code>, <code>trap</code>, <code>trap</code>, <code>-eu</code>, <code>$UNSET_VAR</code>]"
461,https://unix.stackexchange.com/questions/279024/,reason for exec in wrapper scripts,"[""Using exec makes the wrapper more transparent, i.e. it makes it less likely that the user or application that calls the script needs to be aware that it's a relay that in turns launches the “real” program."", ""In particular, if the caller wants to kill the program, they'll just kill the process they just launched. If the wrapper script runs a child process, the caller would need to know that they should find out the child of the wrapper and kill that instead. The wrapper script could set a trap to relay some signals, but that wouldn't work with SIGSTOP or SIGKILL which can't be caught."", ""Calling exec also saves a bit of memory (and other resources such as PIDs etc.) since it there's no need to keep an extra shell around with nothing left to do."", 'If there are multiple wrappers, the problems add up (difficulty in finding the right process to kill, memory overhead, etc.).', ""Some shells (e.g. the Korn shell) automatically detect when a command is the last one and there's no active trap and put an implicit exec, but not all do (e.g. not bash).""]","[<code>exec</code>, <code>exec</code>, <code>exec</code>]"
462,https://unix.stackexchange.com/questions/63480/,What's the equivalent to && when writing a bash script?,"['You can do it like this: ', 'I hope I understood what you asked correctly. ']","[<code>#!/bin/sh
ls -lh &amp;&amp;
    # This is a comment
    echo 'Wicked, it works!'
</code>]"
463,https://unix.stackexchange.com/questions/303605/,What is the purpose of delayed suspend (Ctrl-Y) in Bash?,"['From the 4BSD manual for csh:', 'A ^Z takes effect immediately and is like an interrupt in that pending output and unread input are discarded when it is typed.  There is another special key ^Y which does not generate a STOP signal until a program attempts to read(2) it.  This can usefully be typed ahead when you have prepared some commands for a job which you wish to stop after it has read them.', 'So, the purpose is to type multiple inputs while the first one is being processed, and have the job stop after they are done.']","[<code>^Z</code>, <code>^Y</code>]"
464,https://unix.stackexchange.com/questions/305358/,Do functions run as subprocesses in Bash?,"['The Advanced Bash-Scripting Guide is not always reliable and its example scripts contain out-dated practices such as using the effectively deprecated backticks for command substitution, i.e., `command` rather than $(command).', 'In this particular case, it’s blatantly incorrect.', 'The section on Shell Functions in the (canonical) Bash manual definitively states that', 'Shell functions are executed in the current shell context; no new process is created to interpret them.']","[<code>`command`</code>, <code>$(command)</code>]"
465,https://unix.stackexchange.com/questions/76821/,Is there a way to refer to multiple files in a directory without retyping the whole path?,"[""You're close:"", 'or even', 'Related, and supported by other shells, is a pattern like', 'The first two are expanded to two explicit file name arguments; the third is a pattern against which all files in /some/path are matched.']","[<code>rm /some/path/{file1,file2}
</code>, <code>rm /some/path/file{1,2}
</code>, <code>rm /some/path/file[12]
</code>, <code>/some/path</code>]"
466,https://unix.stackexchange.com/questions/269078/,Executing a Bash Script Function with Sudo,"[""I will admit that there's no simple, intuitive way to do this, and this is a bit hackey. But, you can do it like this:"", 'Or more simply:', 'It works for me:', 'Basically, declare -f will return the contents of the function, which you then pass to bash -c inline.', 'If you want to export all functions from the outer instance of bash, change FUNC=$(declare -f hello) to FUNC=$(declare -f).', 'Edit', 'To address the comments about quoting, see this example:']","[<code>function hello()
{
    echo ""Hello!""
}

# Test that it works.
hello

FUNC=$(declare -f hello)
sudo bash -c ""$FUNC; hello""
</code>, <code>sudo bash -c ""$(declare -f hello); hello""
</code>, <code>$ bash --version
GNU bash, version 4.3.42(1)-release (x86_64-apple-darwin14.5.0)
$ hello
Hello!
$
$ FUNC=$(declare -f hello)
$ sudo bash -c ""$FUNC; hello""
Hello!
</code>, <code>declare -f</code>, <code>bash -c</code>, <code>FUNC=$(declare -f hello)</code>, <code>FUNC=$(declare -f)</code>, <code>$ hello()
&gt; {
&gt; echo ""This 'is a' test.""
&gt; }
$ declare -f hello
hello ()
{
    echo ""This 'is a' test.""
}
$ FUNC=$(declare -f hello)
$ sudo bash -c ""$FUNC; hello""
Password:
This 'is a' test.
</code>]"
467,https://unix.stackexchange.com/questions/70885/,How to debug and fix slow autocomplete in bash?,"[""I don't know about fixing —\xa0there are all kinds of things that could go cause delays. But I can offer a few tips to investigate."", ""Just as a guess, maybe there's a directory somewhere in a search path ($PATH, or some place where bash looks for completion data) that's on a filesystem which is slow to respond. Usually it's remote filesystems that are slow, but it could also be a failing hard disk, a hung FUSE driver, etc."", 'The first step to investigate is to run set -x to get a trace of the commands that the shell executes to generate the completions. Watch where it pauses.', ""If that doesn't give enough information, bring in the big guns. Note the shell's process ID (echo $$). In another terminal, run strace -f -s9999 -p$$ (or the equivalent of strace if running on another unix flavor). Strace lists the system calls performed by the process. See if it seems to be accessing files that it shouldn't, or if access to some files is slow. Adding the option -T to the strace command line makes it show the time spent in each system call.""]","[<code>$PATH</code>, <code>set -x</code>, <code>echo $$</code>, <code>strace -f -s9999 -p$$</code>, <code>-T</code>, <code>strace</code>]"
468,https://unix.stackexchange.com/questions/1469/,bash directory shortcuts,"['The way I used to do this is to create a directory that contains symlinks to the directories you want shortcuts do, and add that directory to your CDPATH. CDPATH controls where cd will search when you switch directories, so if that directory of symlinks is in your CDPATH you can cd to any of the symlinked directories instantly:', 'The downside of course is it won\'t work if there\'s a directory in your current directory named ""b"" -- that takes precedence over the CDPATH', 'I normally dislike answers that say ""first you need to switch shells"", but this exact feature exists in ZSH, if you\'re willing to use that instead; it\'s called named directories. You export a variable foo, and when you refer to ~foo it resolves to the value of $foo. This is especially convenient because it works in commands besides cd:']","[<code>cd</code>, <code>cd</code>, <code>mkdir ~/symlinks
ln -s /usr/bin ~/symlinks/b
export CDPATH=~/symlinks
cd b   # Switches to /usr/bin
</code>, <code>foo</code>, <code>~foo</code>, <code>$foo</code>, <code>cd</code>, <code>echo hi &gt; /tmp/test
export t=/tmp
cat ~t/test   # Outputs ""hi""
</code>]"
469,https://unix.stackexchange.com/questions/251013/,Bash regex capture group,"[""It's a shame that you can't do global matching in bash. You can do this:"", ""This works by chopping the matched prefix off the string so the next part can be matched. It destroys the string, but in the function it's a local variable, so who cares."", 'I would actually use that function to populate an array:']","[<code>global_rematch() { 
    local s=$1 regex=$2 
    while [[ $s =~ $regex ]]; do 
        echo ""${BASH_REMATCH[1]}""
        s=${s#*""${BASH_REMATCH[1]}""}
    done
}
global_rematch ""$mystring1"" ""$regex"" 
</code>, <code>1BBBBBB
2AAAAAAA
</code>, <code>$ mapfile -t matches &lt; &lt;( global_rematch ""$mystring1"" ""$regex"" )
$ printf ""%s\n"" ""${matches[@]}""
1BBBBBB
2AAAAAAA
</code>]"
470,https://unix.stackexchange.com/questions/6435/,How to check if $PWD is a subdirectory of a given path,"[""If you want to reliably test whether a directory is a subdirectory of another, you'll need more than just a string prefix check.  Gilles' answer describes in detail how to do this test properly."", ""But if you do want a simple string prefix check (maybe you've already normalized your paths?), this is a good one:"", 'If $PWD starts with ""/home/"", it gets stripped off in the left side, which means it won\'t match the right side, so ""!="" returns true.']","[<code>test ""${PWD##/home/}"" != ""${PWD}""
</code>, <code>$PWD</code>]"
471,https://unix.stackexchange.com/questions/65315/,How to do a continous 'wc -l' with gnu texttools?,"['Maybe:', 'Beware that it would output a number for every line of input (though overriding the previous value if sent to a  terminal).', 'Or you can implement the tail -f by hand in shell:', ""(note that it runs up to one wc and one sleep command per second which not all shells have built in. With ksh93 while sleep is builtin, to get a built in wc (at least on Debian), you need to add /opt/ast/bin at the front of $PATH (regardless of whether  that directory exists or not) or use command /opt/ast/bin/wc (don't ask...))."", 'You could use pv, as in:', ""But beware that it adds k, M... suffixes when the number is over 1000 (and there doesn't seem to be a way around that).""]","[<code>tail -n +1 -f file | awk '{printf ""\r%lu"", NR}'
</code>, <code>tail -f</code>, <code>n=0
while :; do 
  n=$(($n + $(wc -l)))
  printf '\r%s' ""$n""
  sleep 1
done &lt; file
</code>, <code>wc</code>, <code>sleep</code>, <code>ksh93</code>, <code>sleep</code>, <code>wc</code>, <code>/opt/ast/bin</code>, <code>$PATH</code>, <code>command /opt/ast/bin/wc</code>, <code>pv</code>, <code>tail -n +1 -f file | pv -bl &gt; /dev/null
</code>, <code>k</code>, <code>M</code>]"
472,https://unix.stackexchange.com/questions/463034/,"Bash throws error, line 8: $1: unbound variable","['set -u will abort exactly as you describe if you reference a variable which has not been set.  You are invoking your script with no arguments, so get_percent is being invoked with no arguments, causing $1 to be unset.', 'Either check for this before invoking your function, or use default expansions (${1-default} will expand to default if not already set to something else).']","[<code>set -u</code>, <code>get_percent</code>, <code>$1</code>, <code>${1-default}</code>, <code>default</code>]"
473,https://unix.stackexchange.com/questions/101080/,realpath command not found,"['Is realpath a actual command or a script? I would check to see where it is coming from.', ""I'm not familiar with this tool, and so it's likely not part of your normal distribution, perhaps it's installed in a non-standard location which isn't present on Bash's $PATH but is within your login environment's $PATH."", ""In any event, the above type command will show you where the command is coming from, at which point you can alter the method you're calling it in your script like so:"", ""Or amend your script's $PATH so that it also includes this non-standard location."", ""Much of your environment does not get called when you invoke a shell script. If you think about this, this makes a lot of sense, since you generally don't want scripts to have all the additional baggage that a user's environment may have."", 'You can either determine which source file is providing this function and either source it, or simply instruct Bash to incorporate your login environment.']","[<code>$ type -a realpath
</code>, <code>$PATH</code>, <code>$PATH</code>, <code>type</code>, <code>echo $(/path/to/realpath test.sh)
</code>, <code>$PATH</code>, <code>#!/bin/bash -l
echo $(realpath ""$1"")
</code>]"
474,https://unix.stackexchange.com/questions/4569/,Storing output of command in shell variable,"[""You'll want to modify your assignment to read:"", 'The $(…) construct is known as command susbtitution.']","[<code>var4=""$(echo ztemp.xml | cut -f1 -d '.')""
</code>, <code>$(…)</code>]"
475,https://unix.stackexchange.com/questions/25639/,How to automatically record all your terminal sessions with script utility,"['If someone wants to record their terminal sessions automatically--including SSH sessions(!)--using the script utility, here is how.', ""Add the following line at the end of .bashrc in your home directory, or otherwise /etc/bash.bashrc if you only want to record all users' sessions. We test for shell's parent process not being script and then run script."", 'For Linux:', 'For BSD and macOS, change script -f to script -F:', ""That's all!"", ""Now when you open a new terminal you'll see:"", 'script will write your sessions to a file in your home directory naming them something like 30-Nov-11_00-11-12_shell.log as a result.', 'More customization:', 'This answer assumes that you have script installed, of course. On Debian-based distributions, script is part of the bsdutils package.']","[<code>script</code>, <code>.bashrc</code>, <code>/etc/bash.bashrc</code>, <code>script</code>, <code>script</code>, <code>test ""$(ps -ocommand= -p $PPID | awk '{print $1}')"" == 'script' || (script -f $HOME/$(date +""%d-%b-%y_%H-%M-%S"")_shell.log)
</code>, <code>script -f</code>, <code>script -F</code>, <code>test ""$(ps -ocommand= -p $PPID | awk '{print $1}')"" == 'script' || (script -F $HOME/$(date +""%d-%b-%y_%H-%M-%S"")_shell.log)
</code>, <code>Script started, file is /home/username/file_name.log
</code>, <code>script</code>, <code>30-Nov-11_00-11-12_shell.log</code>, <code>script -a /path/to/single_log_file</code>, <code>script -f</code>, <code>script -F</code>, <code>script</code>, <code>script</code>, <code>bsdutils</code>]"
476,https://unix.stackexchange.com/questions/158564/,How to use defined function with xargs,"['Try exporting function, then calling it in a subshell:']","[<code>showword() {
  echo $1
}

export -f showword
echo This is a sample message | xargs -d' ' -t -n1 -P2 bash -c 'showword ""$@""' _
</code>]"
477,https://unix.stackexchange.com/questions/24500/,Invert boolean variable,"['There are two errors in your script. The first is that you need a space between ! and $flag, otherwise the shell looks for a command called !$flag. The second error is that -eq is for integer comparisons, but you\'re using it on a string. Depending on your shell, either you\'ll see an error message and the loop will continue forever because the condition [ ""$x"" -eq ""true"" ] cannot be true, or every non-integer value will be treated as 0 and the loop will exit if you enter any string (including false) other than a number different from 0.', ""While ! $flag is correct, it's a bad idea to treat a string as a command. It would work, but it would be very sensitive to changes in your script, since you'd need to make sure that $flag can never be anything but true or false. It would be better to use a string comparison here, like in the test below."", ""There's probably a better way to express the logic you're after. For example, you could make an infinite loop and break it when you detect the termination condition.""]","[<code>!</code>, <code>$flag</code>, <code>!$flag</code>, <code>-eq</code>, <code>[ ""$x"" -eq ""true"" ]</code>, <code>false</code>, <code>! $flag</code>, <code>$flag</code>, <code>true</code>, <code>false</code>, <code>flag=false
while [ ""$flag"" != ""true"" ]
do
   read x
   if [ ""$x"" = ""true"" ]
   then
     flag=true
   fi
   echo ""${x} : ${flag}""
done
</code>, <code>while true; do
  read -r x
  if [ ""$x"" = ""true"" ]; then break; fi
  echo ""$x: false""
done
</code>]"
478,https://unix.stackexchange.com/questions/135077/,ctrl c vs. ctrl z with foreground job,"['I think you may be confused about the job control notation. Notably ""Stopped"" means that a job is still alive but that its ability to process anything has been held (it is not given any time on the CPU to process anything). This is effectively a ""Pause"" or ""Suspended"" state, although that is not the correct technical term.', 'CtrlC does not ""stop"" a job, it cancels or kills it. Technically it causes an interrupt signal to be sent to the program telling it to abort what it is doing and exit immediately. Some programs will hear this signal and do some emergency clean up work on themselves before exiting. Others will not respond to the signal and are subsequently just aborted.', 'CtrlZ, on the other hand, ""stops"" a job. Again this is done with a signal, but this time it is a \'stop\' instead of an \'interrupt\' signal. This effectively puts it on hold and returns control to the shell, but does not actually kill the job. If you would like such a job to keep running, you can then issue a bg command to send the last stopped job to the background. It will then continue running as a background job as if you had run it with & in the first place. You may also use fg to resume the last stopped job in the foreground (allowing it to continue where it left off, and allowing you to interact with it again).']","[<code>bg</code>, <code>&amp;</code>, <code>fg</code>]"
479,https://unix.stackexchange.com/questions/524506/,How can I detect if I'm in a subshell?,"['In bash, you can compare $BASHPID to $$', ""If you're not in bash, $$ should remain the same in a subshell, so you'd need some other way of getting your actual process ID."", ""One way to get your actual pid is sh -c 'echo $PPID'. If you just put that in a plain ( … ) it may appear not to work, as your shell has optimized away the fork. Try extra no-op commands ( : ; sh -c 'echo $PPID'; : ) to make it think the subshell is too complicated to optimize away. Credit goes to John1024 on Stack Overflow for that approach.""]","[<code>$BASHPID</code>, <code>$$</code>, <code>$ ( if [ ""$$"" -eq ""$BASHPID"" ]; then echo not subshell; else echo subshell; fi )
subshell
$   if [ ""$$"" -eq ""$BASHPID"" ]; then echo not subshell; else echo subshell; fi
not subshell
</code>, <code>$$</code>, <code>sh -c 'echo $PPID'</code>, <code>( … )</code>, <code>( : ; sh -c 'echo $PPID'; : )</code>]"
480,https://unix.stackexchange.com/questions/42544/,Does redirecting output to a file apply a lock on the file?,"[""Since you're using >>, which means append, each line of output from each instance will be appended in the order it occurred."", ""If your script output prints 1\\n through 5\\n with a one second delay between each and instance two is started 2.5 seconds later you'll get this:"", 'So to answer your question: No.']","[<code>&gt;&gt;</code>, <code>1\n</code>, <code>5\n</code>, <code>1
2
1
3
2
4
3
5
4
5
</code>]"
481,https://unix.stackexchange.com/questions/303157/,Is there something wrong with my script or is Bash much slower than Python?,"['This is a known bug in bash; see the man page and search for ""BUGS"":', ';)', 'For an excellent primer on the conceptual differences between shell scripting and other programming languages, I highly recommend reading:', 'The most pertinent excerpts:', ""Shells are a higher level language. One may say it's not even a language. They're before all command line interpreters. The job is done by those commands you run and the shell is only meant to orchestrate them."", '...', 'IOW, in shells, especially to process text, you invoke as few utilities as possible and have them cooperate to the task, not run thousands of tools in sequence waiting for each one to start, run, clean up before running the next one.', '...', 'As said earlier, running one command has a cost. A huge cost if that command is not builtin, but even if they are builtin, the cost is big.', ""And shells have not been designed to run like that, they have no pretension to being performant programming languages. They are not, they're just command line interpreters. So, little optimisation has been done on this front."", ""Don't use big loops in shell scripting.""]","[<code>BUGS
       It's too big and too slow.
</code>]"
482,https://unix.stackexchange.com/questions/278502/,Accessing array index variable from bash shell script loop?,"['You can do this using List of array keys. From the bash man page:', '${!name[@]}\n${!name[*]}', 'List of array keys.  If name is an array variable, expands to the list of array indices (keys) assigned in  name.  If name is not an array, expands to 0 if name is set and null otherwise.  When @ is used and the expansion appears within double quotes, each key expands to a separate word.', 'For your example:', 'This results in:', 'Note that this also work for non-successive indexes:', 'This results in:']","[<code>bash</code>, <code>${!name[@]}</code>, <code>${!name[*]}</code>, <code>0</code>, <code>@</code>, <code>#!/bin/bash
AR=('foo' 'bar' 'baz' 'bat')
for i in ""${!AR[@]}""; do
  printf '${AR[%s]}=%s\n' ""$i"" ""${AR[i]}""
done
</code>, <code>${AR[0]}=foo
${AR[1]}=bar
${AR[2]}=baz
${AR[3]}=bat
</code>, <code>#!/bin/bash
AR=([3]='foo' [5]='bar' [25]='baz' [7]='bat')
for i in ""${!AR[@]}""; do
  printf '${AR[%s]}=%s\n' ""$i"" ""${AR[i]}""
done
</code>, <code>${AR[3]}=foo
${AR[5]}=bar
${AR[7]}=bat
${AR[25]}=baz
</code>]"
483,https://unix.stackexchange.com/questions/320465/,New tmux sessions do not source bashrc file,"['As far as I know, by default tmux runs a login shell. When bash is invoked as an interactive login shell, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile. So you have to put source ~/.bashrc in one of those files.', 'Another way to solve this issue is to put in your file .tmux.conf the line: ']","[<code>tmux</code>, <code>bash</code>, <code>~/.bash_profile</code>, <code>~/.bash_login</code>, <code>~/.profile</code>, <code>source ~/.bashrc</code>, <code>.tmux.conf</code>, <code>set-option -g default-shell ""/bin/bash""
</code>]"
484,https://unix.stackexchange.com/questions/98007/,How do I set permissions recursively on a dir (with ACL enabled)?,"['setfacl has a recursive option (-R) just like chmod:', 'it also allows for the use of the capital-x X permission, which means:', 'so doing the following should work:', '(all quotes are from man setfacl for acl-2.2.52 as shipped with Debian)']","[<code>setfacl</code>, <code>-R</code>, <code>chmod</code>, <code>  -R, --recursive
      Apply operations to all files and directories recursively. This
      option cannot be mixed with `--restore'.
</code>, <code>X</code>, <code>  execute only if the file is a directory or already has
  execute permission for some user (X)
</code>, <code>setfacl -R -m u:colleague:rwX .
</code>, <code>man setfacl</code>]"
485,https://unix.stackexchange.com/questions/26601/,How to read from two input files using while loop,"['If you know for sure that some character will never occur in the first file then you can use paste.', 'Example of paste using default delimiter tab:', 'Example of paste using @:', 'Note that it is enough if the character is guaranteed to not occur in the first file. This is because read will ignore IFS when filling the last variable. So even if @ occurs in the second file it will not be split.', 'Example of paste using some bash features for arguably cleaner code:', ""Bash features used: ansi c string ($'\\t') and process substitution (<(...)) to avoid the while loop in a subshell problem."", 'If you cannot be certain that any character will never occur in both files then you can use file descriptors.', 'Not tested much. Might break on empty lines.', 'File descriptors number 0, 1, and 2 are already used for stdin, stdout, and stderr, respectively. File descriptors from 3 and up are (usually) free. The bash manual warns from using file descriptors greater than 9, because they are ""used internally"".', 'Note that open file descriptors are inherited to shell functions and external programs. Functions and programs inheriting an open file descriptor can read from (and write to) the file descriptor. You should take care to close all file descriptors which are not required before calling a function or external program.', 'Here is the same program as above with the actual work (the printing) separated from the meta-work (reading line by line from two files in parallel).', 'Now we pretend that we have no control over the work code and that code, for whatever reason, tries to read from file descriptor 3.', 'Here is an example output. Note that the second line from the first file is ""stolen"" from the loop.', 'Here is how you should close the file descriptors before calling external code (or any code for that matter).']","[<code>paste file1 file2 | while IFS=""$(printf '\t')"" read -r f1 f2
do
  printf 'f1: %s\n' ""$f1""
  printf 'f2: %s\n' ""$f2""
done
</code>, <code>@</code>, <code>paste -d@ file1 file2 | while IFS=""@"" read -r f1 f2
do
  printf 'f1: %s\n' ""$f1""
  printf 'f2: %s\n' ""$f2""
done
</code>, <code>read</code>, <code>IFS</code>, <code>@</code>, <code>while IFS=$'\t' read -r f1 f2
do
  printf 'f1: %s\n' ""$f1""
  printf 'f2: %s\n' ""$f2""
done &lt; &lt;(paste file1 file2)
</code>, <code>$'\t'</code>, <code>&lt;(...)</code>, <code>while true
do
  read -r f1 &lt;&amp;3 || break
  read -r f2 &lt;&amp;4 || break
  printf 'f1: %s\n' ""$f1""
  printf 'f2: %s\n' ""$f2""
done 3&lt;file1 4&lt;file2
</code>, <code>work() {
  printf 'f1: %s\n' ""$1""
  printf 'f2: %s\n' ""$2""
}

while true
do
  read -r f1 &lt;&amp;3 || break
  read -r f2 &lt;&amp;4 || break
  work ""$f1"" ""$f2""
done 3&lt;file1 4&lt;file2
</code>, <code>unknowncode() {
  printf 'f1: %s\n' ""$1""
  printf 'f2: %s\n' ""$2""
  read -r yoink &lt;&amp;3 &amp;&amp; printf 'yoink: %s\n' ""$yoink""
}

while true
do
  read -r f1 &lt;&amp;3 || break
  read -r f2 &lt;&amp;4 || break
  unknowncode ""$f1"" ""$f2""
done 3&lt;file1 4&lt;file2
</code>, <code>f1: file1 line1
f2: file2 line1
yoink: file1 line2
f1: file1 line3
f2: file2 line2
</code>, <code>while true
do
  read -r f1 &lt;&amp;3 || break
  read -r f2 &lt;&amp;4 || break
  # this will close fd3 and fd4 before executing anycode
  anycode ""$f1"" ""$f2"" 3&lt;&amp;- 4&lt;&amp;-
  # note that fd3 and fd4 are still open in the loop
done 3&lt;file1 4&lt;file2
</code>]"
486,https://unix.stackexchange.com/questions/48862/,How can I create an alias for a git [action] command (which includes spaces)?,"['Not a direct answer to your question (since aliases can only be one word), but you should be using git-config instead:', 'This creates a git alias so that git civ runs git commit -v.  Unfortunately, AFAIK there is no way to override existing git commands with aliases.  However, you can always pick a suitable alias name to live with as an alternative.']","[<code>git-config</code>, <code>git config --global alias.civ commit -v
</code>, <code>git civ</code>, <code>git commit -v</code>]"
487,https://unix.stackexchange.com/questions/462156/,How do I find the line number in Bash when an error occured?,"[""Rather than use your function, I'd use this method instead:"", 'This works by trapping on ERR and then calling the failure() function with the current line number + bash command that was executed.', ""Here I've not taken any care to create the files, f1, f2, f3, or f4. When I run the above script:"", 'It fails, reporting the line number plus command that was executed.']","[<code>$ cat yael.bash
#!/bin/bash

set -eE -o functrace

file1=f1
file2=f2
file3=f3
file4=f4

failure() {
  local lineno=$1
  local msg=$2
  echo ""Failed at $lineno: $msg""
}
trap 'failure ${LINENO} ""$BASH_COMMAND""' ERR

cp -- ""$file1"" ""$file2""
cp -- ""$file3"" ""$file4""
</code>, <code>failure()</code>, <code>f1</code>, <code>f2</code>, <code>f3</code>, <code>f4</code>, <code>$ ./yael.bash
cp: cannot stat ‘f1’: No such file or directory
Failed at 17: cp -- ""$file1"" ""$file2""
</code>]"
488,https://unix.stackexchange.com/questions/138504/,Setting PATH vs. exporting PATH in ~/.bash_profile,"['To answer your questions specifically:', 'export does set the $PATH explicitly.', ""No. export sets environment for child processes, but $PATH is already set for the current environment. So, in the second example, when the command is read-in - and before export is executed - the current environment's value for $PATH is expanded into the $PATH word."", 'You should use whichever is necessary and/or comfortable for you. Neither makes any difference functionally, so this is primarily a question of style.', 'POSIX defines the export builtin so:', 'The shell shall give the export attribute to the variables corresponding to the specified names, which shall cause them to be in the environment of subsequently executed commands. If the name of a variable is followed by = word, then the value of that variable shall be set to word.', 'From another of my answers:', ""There is little difference between declaring a shell variable and an environment variable. Because export is a builtin it declares an environment variable for the process next invoked, but if you don't invoke one that process remains the shell, and so your variable is twice evaluated."", ""You can remove all exports without any effect at all on exported variables so long as you don't use export to twice evaluate. By twice evaluate I mean:"", 'Instead just use:', '...at the top of the script. All variables defined thereafter will be automatically exported - which would include variables you might not have previously exported. Alternatively you could only set -a for a portion of the script and later set +a to unset it - it could also work as function.', 'But subshells automatically inherit variable values anyway, so:', 'export makes no difference in that case.', ""But if your script calls another script, or any other executable that interprets values you've exported and you cease to export them, then those values will no longer be available in their environment. In the following example I use the shell variable $PS1 - which defines the contents of an interactive shell's prompt - to demonstrate how variations on exported variables affect child processes."", 'But ...', 'But then again, if you explicitly declare environment variables while invoking a process...', 'Any of the ENV files first invoked by a shell such as .bashrc or .profile will set variable values for the life of that shell. So any variables that are set and exported within those files will maintain that export characteristic and be exported to all child processes invoked by that shell for the life of the shell or until they are unset. ', 'It is notable, though, that bash extends the export builtin somewhat to include the -n option - which enables you to remove the export attribute from a variable without unsetting it, but this is not portable behavior.']","[<code>export</code>, <code>$PATH</code>, <code>export</code>, <code>$PATH</code>, <code>export</code>, <code>$PATH</code>, <code>$PATH</code>, <code>export</code>, <code>export</code>, <code>export</code>, <code>var1=var2 
export ""${var1}=var3""
echo ""$var2""
var3
</code>, <code>set -a 
</code>, <code>exported</code>, <code>export</code>, <code>set -a</code>, <code>set +a</code>, <code>var1=value
( echo ""$(echo ""$var1"")"" )
value
</code>, <code>export</code>, <code>export</code>, <code>export</code>, <code>$PS1</code>, <code>export</code>, <code>export PS1=""$(printf ""this is another executable\n &gt; "")""
echo exit | sh -i

###OUTPUT###

this is another executable
 &gt; exit
exit
</code>, <code>PS1=""$(printf ""this is another executable\n &gt; "")""
echo exit | sh -i

###OUTPUT###

sh-4.3$ exit
exit
</code>, <code>PS1=""$(printf ""this is another executable\n &gt; "")""
{
echo exit | PS1=$PS1 sh -i
echo exit | sh -i
}

###OUTPUT###

this is another executable
 &gt; exit
exit
sh-4.3$ exit
exit
</code>, <code>ENV</code>, <code>.bashrc</code>, <code>.profile</code>, <code>export</code>, <code>export</code>, <code>export</code>, <code>unset</code>, <code>bash</code>, <code>export</code>, <code>-n</code>, <code>export</code>, <code>unset</code>]"
489,https://unix.stackexchange.com/questions/157286/,Copying files with multiple extensions,"['Brace expansion will get the job done.  man bash and search for Brace Expansion.', 'EDIT: ', ""In keeping with the OP's request, the command above was missing the verbose option:""]","[<code>man bash</code>, <code>Brace Expansion</code>, <code>cp *.{txt,jpg,png} destination/
</code>, <code>cp -v *.{txt,jpg,png} destination/
</code>]"
490,https://unix.stackexchange.com/questions/64374/,Difference between >> and >\> operators?,"['To append text to a file you use >>. To overwrite the data currently in that file, you use >. In general, in bash and other shells, you escape special characters using \\. ', 'So, when you use echo foo >\\> what you are saying is ""redirect to a file called >"", but that is because you are escaping the second >. It is equivalent to using echo foo > \\> which is the same as echo foo > \'>\'.', 'So, yes, as Sirex said, that is likely a typo in your book. ']","[<code>&gt;&gt;</code>, <code>&gt;</code>, <code>\</code>, <code>echo foo &gt;\&gt;</code>, <code>&gt;</code>, <code>&gt;</code>, <code>echo foo &gt; \&gt;</code>, <code>echo foo &gt; '&gt;'</code>]"
491,https://unix.stackexchange.com/questions/32508/,How can I open a new terminal in the same directory of the last used one from a window manager keybind?,"['I see three solutions using .last_dir. You can place the echo $PWD > ~/.last_dir either:', 'In a special function that would be a wrapper for cd:', 'Place this in your ~/.bashrc and then use cd_ instead of cd every time you want your new working directory to be stored.', 'In your $PROMPT_COMMAND (not recommended):', 'You can test this directly from the terminal or place it in ~/.bashrc. This solution, however, triggers a disk write each time the prompt appears, which might cause trouble - but on the other hand, .last_dir would contain the current directory no matter how you got there.', ""In a custom perl extension script for rxvt. I've never created one myself, but you can find quite a few examples on the web.""]","[<code>.last_dir</code>, <code>echo $PWD &gt; ~/.last_dir</code>, <code>cd</code>, <code>function cd_
{
  [[ -d ""$@"" ]] || return 1
  echo ""$@"" &gt; ~/.last_dir
  cd ""$@""
}
</code>, <code>~/.bashrc</code>, <code>cd_</code>, <code>$PROMPT_COMMAND</code>, <code>PROMPT_COMMAND=""$PROMPT_COMMAND; pwd &gt; ~/.last_dir""
</code>, <code>~/.bashrc</code>, <code>.last_dir</code>, <code>rxvt</code>]"
492,https://unix.stackexchange.com/questions/162922/,Is there a way to flatten a .pdf image from the command line?,"['I found these 2 method via Google, in this thread titled: Re: Flattening PDF Files at the UNIX Command Line.', 'NOTE: The quality is reported to be so so with this approach.', 'NOTE: This method is reported to retain the image quality.']","[<code>$ convert -density 300 orig.pdf flattened.pdf 
</code>, <code>$ pdf2ps orig.pdf - | ps2pdf - flattened.pdf
</code>]"
493,https://unix.stackexchange.com/questions/394490/,How to cut till first delimiter and get remaining part of strings?,"['Simply with cut command:', ""-d'/' - field delimiter"", '-f2- - a range of fields to output (-f<from>-<to> ; in our case: from 2 to the last)']","[<code>cut</code>, <code>echo ""pandi/sha/Dev/bin/boot"" | cut -d'/' -f2-
sha/Dev/bin/boot
</code>, <code>-d'/'</code>, <code>-f2-</code>, <code>-f&lt;from&gt;-&lt;to&gt;</code>, <code>2</code>]"
494,https://unix.stackexchange.com/questions/247187/,bash if not multiple conditions without subshell?,"['You need to use { list;} instead of (list):', 'Both of them are Grouping Commands, but { list;} executes commands in current shell environment.', 'Note that, the ; in { list;} is needed to delimit the list from } reverse word, you can use other delimiter as well. The space (or other delimiter) after { is also required.']","[<code>{ list;}</code>, <code>(list)</code>, <code>if ! { [ -f file1 ] &amp;&amp; [ -f file2 ] &amp;&amp; [ -f file3 ]; }; then
  : do something
fi
</code>, <code>{ list;}</code>, <code>;</code>, <code>{ list;}</code>, <code>}</code>, <code>{</code>]"
495,https://unix.stackexchange.com/questions/91943/,is there a way to list all 'indexes IDs' (keys) on a bash associative array variable?,"['You can get the list of ""keys"" for the associative array like so:', 'You can iterate over the ""keys"" like so:']","[<code>$ echo ""${!astr[@]}""
elemB elemA
</code>, <code>for i in ""${!astr[@]}""
do   
  echo ""key  : $i""
  echo ""value: ${astr[$i]}""
done
</code>, <code>$ for i in ""${!astr[@]}""; do echo ""key  : $i""; echo ""value: ${astr[$i]}""; done
key  : elemB
value: 199
key  : elemA
value: 123
</code>]"
496,https://unix.stackexchange.com/questions/236382/,What does !#:3 mean in a shell command,"['This is a special syntax, expanded by bash. It also works for zsh.', 'According to the bash man page (section HISTORY EXPANSION), the pattern\nexpands as following:', 'The final command line (usually displayed before executed) is:\ncurl http://beyondgrep.com/ack-2.14-single-file > ~/bin/ack && chmod 0755 ~/bin/ack.', 'For details, see the bash manual or very similar the zsh manual']","[<code>!#</code>, <code>curl http://beyondgrep.com/ack-2.14-single-file &gt; ~/bin/ack &amp;&amp; chmod 0755</code>, <code>:</code>, <code>3</code>, <code>~/bin/ack</code>, <code>curl http://beyondgrep.com/ack-2.14-single-file &gt; ~/bin/ack &amp;&amp; chmod 0755 ~/bin/ack</code>]"
497,https://unix.stackexchange.com/questions/4840/,Adding numbers from the result of a grep,"[""That doesn't print the list but does print the sum. If you want both the list and the sum, you can do:""]","[<code>grep -o ""[0-9] errors"" verification_report_3.txt | awk '{ SUM += $1} END { print SUM }'
</code>, <code>grep -o ""[0-9] errors"" verification_report_3.txt | awk '{ SUM += $1; print $1} END { print SUM }'
</code>]"
498,https://unix.stackexchange.com/questions/46541/,How can I use bash's if test and find commands together?,"[""[ and test are synonyms (except [ requires ]), so you don't want to use [ test:"", 'test returns a zero exit status if the condition is true, otherwise nonzero. This can actually be replaced by any program to check its exit status, where 0 indicates success and non-zero indicates failure:', ""However, all of the above examples only test against the program's exit status, and ignore the program's output."", 'For find, you will need to test if any output was generated. -n tests for a non-empty string:', 'A full list of test arguments is available by invoking help test at the bash commandline.', ""If you are using bash (and not sh), you can use [[ condition ]], which behaves more predictably when there are spaces or other special cases in your condition. Otherwise it is generally the same as using [ condition ]. I've used [[ condition ]] in this example, as I do whenever possible."", 'I also changed `command` to $(command), which also generally behaves similarly, but is nicer with nested commands.']","[<code>[</code>, <code>test</code>, <code>[</code>, <code>]</code>, <code>[ test</code>, <code>[ -x /bin/cat ] &amp;&amp; echo 'cat is executable'
test -x /bin/cat &amp;&amp; echo 'cat is executable'
</code>, <code>test</code>, <code># echoes ""command succeeded"" because echo rarely fails
if /bin/echo hi; then echo 'command succeeded'; else echo 'command failed'; fi

# echoes ""command failed"" because rmdir requires an argument
if /bin/rmdir; then echo 'command succeeded'; else echo 'command failed'; fi
</code>, <code>find</code>, <code>-n</code>, <code>if [[ -n $(find /var/log/crashes -name ""app-*.log"" -mmin -5) ]]
then
    service myapp restart
fi
</code>, <code>help test</code>, <code>bash</code>, <code>bash</code>, <code>sh</code>, <code>[[ condition ]]</code>, <code>[ condition ]</code>, <code>[[ condition ]]</code>, <code>`command`</code>, <code>$(command)</code>]"
499,https://unix.stackexchange.com/questions/125132/,ln -s with a path relative to pwd,"['The easiest way to link to the current directory as an absolute path, without typing the whole path string would be', ""The target (first) argument for the ln -s command works relative to the symbolic link's location, not your current directory. It helps to know that, essentially, the created symlink (the second argument) simply holds the text you provide for the first argument."", 'Therefore, if you do the following:', 'and then move that link around', 'you will see that foo_link tries to point to foo in the directory it is residing in. This also works with symbolic links pointing to relative paths. If you do the following:', ""and then move yet_another_link to another directory and check where it points to, you'll see that it always points to ../foo. This is the intended behaviour, since many times symbolic links might be part of a directory structure that can reside in various absolute paths."", 'In your case, when you create the link by typing', ""foo_link just holds a link to foo, relative to its location. Putting $(pwd) in front of the target argument's name simply adds the current working directory's absolute path, so that the link is created with an absolute target.""]","[<code>ln -s ""$(pwd)/foo"" ~/bin/foo_link
</code>, <code>target</code>, <code>ln -s</code>, <code>cd some_directory
ln -s foo foo_link
</code>, <code>mv foo_link ../some_other_directory
ls -l ../some_other_directory
</code>, <code>foo_link</code>, <code>foo</code>, <code>ln -s ../foo yet_another_link
</code>, <code>yet_another_link</code>, <code>../foo</code>, <code>ln -s foo ~/bin/foo_link
</code>, <code>foo_link</code>, <code>foo</code>, <code>$(pwd)</code>]"
